{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afro-content-ai/Afro-Content_Multilang_MVP/blob/main/Another_copy_of_ai_content_multilang_mvp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create project folders and basic files\n",
        "!rm -rf afro_content_ai\n",
        "!mkdir -p afro_content_ai/{backend,frontend,assets}\n",
        "\n",
        "# create a sample asset used as fallback image\n",
        "!wget -q -O afro_content_ai/assets/sample.jpg https://images.unsplash.com/photo-1507525428034-b723cf961d3e?w=1200\n",
        "\n",
        "# Define the content for .gitignore\n",
        "gitignore_content = \"\"\"node_modules/\n",
        "outputs/\n",
        "downloaded_images/\n",
        "__pycache__/\n",
        ".env\n",
        "*.pyc\n",
        ".vscode/\n",
        "\"\"\"\n",
        "\n",
        "# Create .gitignore using Python file writing\n",
        "with open(\"afro_content_ai/.gitignore\", \"w\") as f:\n",
        "    f.write(gitignore_content)\n",
        "\n",
        "# Define the content for README.md\n",
        "readme_content = \"\"\"# Afro Content AI\n",
        "\n",
        "Backend: Flask (in /backend)\n",
        "Frontend: React + Vite (in /frontend)\n",
        "\n",
        "ENV vars needed:\n",
        "- GOOGLE_CLIENT_ID\n",
        "- GEMINI_API_KEY\n",
        "- UNSPLASH_ACCESS_KEY\n",
        "\n",
        "Run backend: python3 backend/app.py\n",
        "\"\"\"\n",
        "\n",
        "# Create README stub using Python file writing\n",
        "with open(\"afro_content_ai/README.md\", \"w\") as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"Created project folders and basic files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlbyIOwU226b",
        "outputId": "5784bc6c-0dfa-43fa-f233-8ab0eb4a98d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created project folders and basic files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > afro_content_ai/backend/app.py <<'PY'\n",
        "from flask import Flask, request, jsonify, send_from_directory\n",
        "from flask_cors import CORS\n",
        "import os, json, re, requests\n",
        "from gtts import gTTS\n",
        "\n",
        "# moviepy imports are optional at import-time - we'll import inside function to avoid heavy startup\n",
        "app = Flask(__name__, static_folder=None)\n",
        "CORS(app)\n",
        "\n",
        "GOOGLE_CLIENT_ID = os.getenv(\"GOOGLE_CLIENT_ID\", \"\")\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
        "UNSPLASH_ACCESS_KEY = os.getenv(\"UNSPLASH_ACCESS_KEY\", \"\")\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return \"âœ… Afro Content AI backend running\"\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt','').strip()\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\":\"Prompt missing\"}), 400\n",
        "\n",
        "    print(\"Received prompt:\", prompt)\n",
        "\n",
        "    # 1) Generate multilingual text using Gemini (if GEMINI_API_KEY set)\n",
        "    text_data = {\"en\": f\"Inspiration: {prompt}\", \"ar\": \"\", \"am\": \"\"}\n",
        "    if GEMINI_API_KEY:\n",
        "        try:\n",
        "            from google import genai\n",
        "            client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "            text_prompt = f'''\n",
        "You are a multilingual social media writer.\n",
        "Create a short Instagram caption in English, Arabic and Amharic about: \"{prompt}\"\n",
        "Return only valid JSON object with keys \"en\",\"ar\",\"am\".\n",
        "'''\n",
        "            resp = client.models.generate_content(model=\"models/gemini-2.5-flash\", contents=text_prompt)\n",
        "            raw = resp.text.strip()\n",
        "            m = re.search(r'(\\{[\\s\\S]*\\})', raw)\n",
        "            json_text = m.group(1) if m else raw\n",
        "            parsed = json.loads(json_text)\n",
        "            text_data = {\n",
        "                \"en\": parsed.get(\"en\", text_data[\"en\"]),\n",
        "                \"ar\": parsed.get(\"ar\", \"\"),\n",
        "                \"am\": parsed.get(\"am\", \"\")\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(\"Gemini error:\", e)\n",
        "\n",
        "    # 2) Create a short TTS audio file for English (safe fallback if gTTS fails)\n",
        "    os.makedirs(\"/content/afro_content_ai/backend/outputs\", exist_ok=True)\n",
        "    audio_path = None\n",
        "    try:\n",
        "        en_text = text_data.get(\"en\",\"\")\n",
        "        if en_text:\n",
        "            fname = f\"/content/afro_content_ai/backend/outputs/tts_en_{os.urandom(4).hex()}.mp3\"\n",
        "            tts = gTTS(en_text, lang=\"en\")\n",
        "            tts.save(fname)\n",
        "            audio_path = fname\n",
        "    except Exception as e:\n",
        "        print(\"gTTS error:\", e)\n",
        "        audio_path = None\n",
        "\n",
        "    # 3) Fetch images from Unsplash (or fallback to asset)\n",
        "    image_dir = \"/content/afro_content_ai/backend/downloaded_images\"\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "    image_files = []\n",
        "    if UNSPLASH_ACCESS_KEY:\n",
        "        try:\n",
        "            r = requests.get(\"https://api.unsplash.com/search/photos\",\n",
        "                             params={\"query\": prompt, \"per_page\": 3, \"orientation\":\"landscape\"},\n",
        "                             headers={\"Authorization\": f\"Client-ID {UNSPLASH_ACCESS_KEY}\"}, timeout=20)\n",
        "            for i, item in enumerate(r.json().get(\"results\",[])[:3]):\n",
        "                url = item.get(\"urls\",{}).get(\"regular\")\n",
        "                if url:\n",
        "                    path = f\"{image_dir}/img_{i}_{os.urandom(3).hex()}.jpg\"\n",
        "                    with requests.get(url, stream=True, timeout=30) as rr:\n",
        "                        rr.raise_for_status()\n",
        "                        with open(path, \"wb\") as f:\n",
        "                            for chunk in rr.iter_content(8192):\n",
        "                                f.write(chunk)\n",
        "                    image_files.append(path)\n",
        "        except Exception as e:\n",
        "            print(\"Unsplash fetch error:\", e)\n",
        "\n",
        "    if not image_files:\n",
        "        image_files = [\"/content/afro_content_ai/assets/sample.jpg\"]\n",
        "\n",
        "    # 4) Create a short video using moviepy (import inside try)\n",
        "    video_path = None\n",
        "    try:\n",
        "        from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
        "        clips = []\n",
        "        duration = 4\n",
        "        for p in image_files:\n",
        "            clips.append(ImageClip(p).set_duration(duration))\n",
        "        final = concatenate_videoclips(clips, method=\"compose\")\n",
        "        # attach audio if exists\n",
        "        if audio_path:\n",
        "            audio = AudioFileClip(audio_path)\n",
        "            if audio.duration < final.duration:\n",
        "                # loop or just set shorter audio - we'll set audio to the clip duration by repeating\n",
        "                from moviepy.audio.io.AudioFileClip import AudioFileClip as AFC\n",
        "                # simple approach: trim/pad audio to video duration\n",
        "                if audio.duration < final.duration:\n",
        "                    # repeat audio until duration reached\n",
        "                    times = int(final.duration // audio.duration) + 1\n",
        "                    from moviepy.editor import concatenate_audioclips\n",
        "                    audio = concatenate_audioclips([audio]*times).subclip(0, final.duration)\n",
        "            else:\n",
        "                audio = audio.subclip(0, final.duration)\n",
        "            final = final.set_audio(audio)\n",
        "        # write file\n",
        "        out = f\"/content/afro_content_ai/backend/outputs/video_{os.urandom(4).hex()}.mp4\"\n",
        "        final.write_videofile(out, fps=24, codec=\"libx264\", audio_codec=\"aac\", verbose=False, logger=None)\n",
        "        video_path = out\n",
        "    except Exception as e:\n",
        "        print(\"Video creation error:\", e)\n",
        "\n",
        "    return jsonify({\n",
        "        \"status\":\"success\",\n",
        "        \"text\": text_data,\n",
        "        \"audio\": audio_path,\n",
        "        \"video\": video_path\n",
        "    })\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # when running under Colab + cloudflared, run on host 0.0.0.0\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "PY"
      ],
      "metadata": {
        "id": "hJcHB5u73gC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create frontend using Vite (this may take a minute)\n",
        "!rm -rf afro_content_ai/frontend\n",
        "!yes | npx create-vite@latest afro_content_ai/frontend -- --template react\n",
        "!cd afro_content_ai/frontend && npm install axios\n",
        "\n",
        "# overwrite src/App.jsx to a simple UI that calls your backend\n",
        "app_jsx_content = \"\"\"\n",
        "import { useState } from \"react\";\n",
        "import axios from \"axios\";\n",
        "\n",
        "export default function App(){\n",
        "  const [prompt,setPrompt] = useState(\"\");\n",
        "  const [resp,setResp] = useState(null);\n",
        "  const [loading,setLoading] = useState(false);\n",
        "\n",
        "  const handle = async ()=>{\n",
        "    setLoading(true);\n",
        "    setResp(null);\n",
        "    try{\n",
        "      // Replace with your actual Cloudflare Tunnel URL obtained from running the backend cell\n",
        "      const backendUrl = \"https://sep-temp-mega-ips.trycloudflare.com\";\n",
        "      const r = await axios.post(`${backendUrl}/api/generate-content`, { prompt });\n",
        "      setResp(r.data);\n",
        "    }catch(e){\n",
        "      setResp({error: e.message});\n",
        "    }finally{ setLoading(false); }\n",
        "  };\n",
        "\n",
        "  return (\n",
        "    <div style={{padding:20, fontFamily:\"sans-serif\"}}>\n",
        "      <h2>Afro Content AI</h2>\n",
        "      <textarea value={prompt} onChange={(e)=>setPrompt(e.target.value)} rows={4} cols={50} placeholder=\"Enter idea...\"/>\n",
        "      <br/>\n",
        "      <button onClick={handle} style={{marginTop:10}}>Generate</button>\n",
        "      {loading && <p>Generating...</p>}\n",
        "      {resp && (\n",
        "        <div style={{marginTop:10, textAlign:\"left\"}}>\n",
        "          <h3>Response (JSON)</h3>\n",
        "          <pre>{JSON.stringify(resp, null, 2)}</pre>\n",
        "          {resp.video && <video src={resp.video} controls width=\"400\" style={{display:\"block\",marginTop:10}} />}\n",
        "          {resp.audio && <audio src={resp.audio} controls style={{display:\"block\",marginTop:10}} />}\n",
        "        </div>\n",
        "      )}\n",
        "    </div>\n",
        "  );\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"afro_content_ai/frontend/src/App.jsx\", \"w\") as f:\n",
        "    f.write(app_jsx_content)\n",
        "\n",
        "print(\"Created afro_content_ai/frontend/src/App.jsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "druHl4nD3srh",
        "outputId": "aad2c32e-c23d-48a3-8648-ef1d521f3d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\u001b[90mâ”‚\u001b[39m\n",
            "\u001b[32mâ—‡\u001b[39m  Scaffolding project in /content/afro_content_ai/frontend...\n",
            "\u001b[90mâ”‚\u001b[39m\n",
            "\u001b[90mâ””\u001b[39m  Done. Now run:\n",
            "\n",
            "  cd afro_content_ai/frontend\n",
            "  npm install\n",
            "  npm run dev\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K\n",
            "added 37 packages, and audited 38 packages in 10s\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K11 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0K\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n",
            "\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0KCreated afro_content_ai/frontend/src/App.jsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa3af77e"
      },
      "source": [
        "## Run the Frontend Application\n",
        "\n",
        "Now that the frontend files are created, you can run the development server to see the application in your browser.\n",
        "\n",
        "1. Navigate to the `afro_content_ai/frontend` directory.\n",
        "2. Run `npm install` (if you haven't already in the previous step).\n",
        "3. Run `npm run dev` to start the Vite development server.\n",
        "\n",
        "This will typically provide a local URL (like `http://localhost:5173`) and potentially a network URL that you can open in your web browser to see the frontend."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean and rebuild folders\n",
        "!rm -rf afro_content_ai\n",
        "!mkdir -p afro_content_ai/{backend,frontend}\n",
        "\n",
        "# Create basic backend files\n",
        "requirements_content = \"\"\"Flask\n",
        "flask-cors\n",
        "google-auth\n",
        "requests\n",
        "google-generativeai\n",
        "gTTS\n",
        "moviepy\n",
        "cloudflared\n",
        "\"\"\"\n",
        "\n",
        "app_content = \"\"\"from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import os, json, re, requests\n",
        "from gtts import gTTS\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
        "from moviepy.video.fx.all import fadein, fadeout\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "GOOGLE_CLIENT_ID = os.getenv(\"GOOGLE_CLIENT_ID\", \"\")\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
        "UNSPLASH_ACCESS_KEY = os.getenv(\"UNSPLASH_ACCESS_KEY\", \"\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"âœ… Afro Content AI backend running\"\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token: return jsonify({\"error\":\"ID token missing\"}),400\n",
        "    try:\n",
        "        info = id_token.verify_oauth2_token(token, google_requests.Request(), GOOGLE_CLIENT_ID)\n",
        "        return jsonify({\"status\":\"success\",\"user\":info})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\":str(e)}),401\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt','')\n",
        "    if not prompt: return jsonify({\"error\":\"Prompt missing\"}),400\n",
        "    print(\"Prompt:\",prompt)\n",
        "    # Dummy reply (replace later with Gemini API call)\n",
        "    return jsonify({\n",
        "        \"status\":\"success\",\n",
        "        \"text\":{\"en\":f\"Generated caption for: {prompt}\"},\n",
        "        \"video_path\":\"/outputs/sample.mp4\"\n",
        "    })\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"afro_content_ai/backend/requirements.txt\", \"w\") as f:\n",
        "    f.write(requirements_content)\n",
        "\n",
        "with open(\"afro_content_ai/backend/app.py\", \"w\") as f:\n",
        "    f.write(app_content)\n",
        "\n",
        "print(\"Created backend files: requirements.txt and app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuv9z1YEdUDk",
        "outputId": "4445149b-9927-4468-d698-a371b54dbfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created backend files: requirements.txt and app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Remove direct assignment of sensitive information\n",
        "# os.environ[\"GOOGLE_CLIENT_ID\"] = \"http://1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\"\n",
        "# os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCeBoO_SSjf_FNkFDLsWmKGuGY5YImJS14\"\n",
        "# os.environ[\"UNSPLASH_ACCESS_KEY\"] = \"HCyqtDQ_2UhK7pY3zZ8ap9bFcUi8aC1Y2PSJ7fVtADk\"\n",
        "\n",
        "# It's best to set these as environment variables outside the notebook\n",
        "# or use Colab's Secrets feature (recommended in Colab).\n",
        "\n",
        "# You can still access them using os.environ.get() or userdata.get()\n",
        "# For demonstration in Colab, we'll show how to get them (assuming they are set elsewhere,\n",
        "# e.g., via Colab Secrets or a parent process/shell).\n",
        "# If you were running this locally, you might load them from a .env file.\n",
        "\n",
        "# Example of how to access them (assuming they are set):\n",
        "google_client_id = os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "unsplash_access_key = os.environ.get(\"UNSPLASH_ACCESS_KEY\")\n",
        "\n",
        "print(\"Environment variables GOOGLE_CLIENT_ID, GEMINI_API_KEY, UNSPLASH_ACCESS_KEY should be set securely outside the notebook.\")\n",
        "print(\"Accessing them using os.environ.get().\")\n",
        "\n",
        "# You can print a confirmation (without showing the actual values)\n",
        "if google_client_id:\n",
        "    print(\"GOOGLE_CLIENT_ID is accessible.\")\n",
        "else:\n",
        "    print(\"GOOGLE_CLIENT_ID is NOT accessible.\")\n",
        "\n",
        "if gemini_api_key:\n",
        "    print(\"GEMINI_API_KEY is accessible.\")\n",
        "else:\n",
        "    print(\"GEMINI_API_KEY is NOT accessible.\")\n",
        "\n",
        "if unsplash_access_key:\n",
        "    print(\"UNSPLASH_ACCESS_KEY is accessible.\")\n",
        "else:\n",
        "    print(\"UNSPLASH_ACCESS_KEY is NOT accessible.\")"
      ],
      "metadata": {
        "id": "p7FIBN8EdXM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and install cloudflared manually\n",
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!sudo dpkg -i cloudflared-linux-amd64.deb\n",
        "!cloudflared --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IBMd9yggBWJ",
        "outputId": "74799100-53f8-4837-db48-8bbd0d1a089c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 125083 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.10.1) over (2025.10.1) ...\n",
            "Setting up cloudflared (2025.10.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "cloudflared version 2025.10.1 (built 2025-10-30-18:35 UTC)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install cloudflared -y\n",
        "!cloudflared --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlKtQJT7f1OH",
        "outputId": "53261356-d31e-4aed-8446-3cf5bd7ec7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cloudflared is already the newest version (2025.10.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "cloudflared version 2025.10.1 (built 2025-10-30-18:35 UTC)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > afro_content_ai/backend/app.py <<'PY'\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import os, json, re, requests\n",
        "from gtts import gTTS\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return \"âœ… Afro Content AI backend running\"\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt','')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\":\"Prompt missing\"}), 400\n",
        "    return jsonify({\"status\":\"success\",\"text\":{\"en\":f\"Inspiring caption about {prompt}\"}})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "PY"
      ],
      "metadata": {
        "id": "egmq0zAG1mof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-cors -q\n",
        "import threading, subprocess, re, time, os\n",
        "\n",
        "# Kill any leftovers from previous tries\n",
        "!pkill -f cloudflared || echo \"no tunnels running\"\n",
        "!pkill -f flask || echo \"no flask running\"\n",
        "\n",
        "def run_flask():\n",
        "    os.system(\"python3 afro_content_ai/backend/app.py\")\n",
        "\n",
        "def run_tunnel():\n",
        "    time.sleep(3)\n",
        "    proc = subprocess.Popen(\n",
        "        [\"cloudflared\", \"tunnel\", \"--url\", \"http://localhost:5000\", \"--no-autoupdate\"],\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        "    )\n",
        "    for line in iter(proc.stdout.readline, \"\"):\n",
        "        print(line, end=\"\")\n",
        "        if \"trycloudflare.com\" in line:\n",
        "            m = re.search(r\"https://[0-9a-z\\-]+\\.trycloudflare\\.com\", line)\n",
        "            if m:\n",
        "                print(\"\\nðŸŒ PUBLIC URL:\", m.group(0))\n",
        "                print(\"ðŸ”— Copy this link â€” paste it into your frontend.\\n\")\n",
        "\n",
        "# Start Flask and Cloudflared in background threads\n",
        "t1 = threading.Thread(target=run_flask, daemon=True)\n",
        "t2 = threading.Thread(target=run_tunnel, daemon=True)\n",
        "t1.start(); t2.start()\n",
        "\n",
        "# Keep the cell alive so the tunnel stays open\n",
        "while True:\n",
        "    time.sleep(60)"
      ],
      "metadata": {
        "id": "NPJyRMVG0G3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c4e7b24",
        "outputId": "8746b56f-ee17-4cd2-94c2-7dc7b0845905"
      },
      "source": [
        "# Navigate to the frontend directory and run the development server\n",
        "# Note: This command will block the Colab cell execution while the server is running.\n",
        "# You may need to open the provided URL in a new browser tab.\n",
        "!cd afro_content_ai/frontend && npm run dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "> frontend@0.0.0 dev\n",
            "> vite\n",
            "\n",
            "\u001b[1G\u001b[0K\n",
            "\u001b[1;1H\u001b[0J\n",
            "  \u001b[32m\u001b[1mVITE\u001b[22m v7.1.12\u001b[39m  \u001b[2mready in \u001b[0m\u001b[1m300\u001b[22m\u001b[2m\u001b[0m ms\u001b[22m\n",
            "\n",
            "  \u001b[32mâžœ\u001b[39m  \u001b[1mLocal\u001b[22m:   \u001b[36mhttp://localhost:\u001b[1m5173\u001b[22m/\u001b[39m\n",
            "\u001b[2m  \u001b[32mâžœ\u001b[39m  \u001b[1mNetwork\u001b[22m\u001b[2m: use \u001b[22m\u001b[1m--host\u001b[22m\u001b[2m to expose\u001b[22m\n",
            "\u001b[2m\u001b[32m  âžœ\u001b[39m\u001b[22m\u001b[2m  press \u001b[22m\u001b[1mh + enter\u001b[22m\u001b[2m to show help\u001b[22m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b812b3e",
        "outputId": "c4adcf39-a9e2-4818-b59c-1c09c537315e"
      },
      "source": [
        "# Cell 3: Safely get API key using getpass (Good for interactive input in Colab, not for GitHub)\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Using getpass for demonstration in Colab is fine, but for production/sharing,\n",
        "# rely on environment variables set outside the code.\n",
        "\n",
        "# You can still use this cell to set the key interactively if needed for testing in THIS Colab session,\n",
        "# but for a shareable notebook, prefer reading from environment variables.\n",
        "# os.environ[\"GEMINI_API_KEY\"] = getpass(\"Paste GEMINI API key: \")\n",
        "\n",
        "# Instead, get the key from environment variables (e.g., set via Colab Secrets)\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    print(\"GEMINI_API_KEY environment variable not found. Gemini API calls will likely fail.\")\n",
        "    # You might prompt for it interactively here if needed for this session:\n",
        "    # API_KEY = getpass(\"Paste GEMINI API key (for this session only): \")\n",
        "    # os.environ[\"GEMINI_API_KEY\"] = API_KEY # Optionally set it as an env var for this session\n",
        "\n",
        "# Example: using the API key in your request\n",
        "import requests\n",
        "\n",
        "if API_KEY:\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={API_KEY}\"\n",
        "\n",
        "    data = {\n",
        "        \"contents\": [\n",
        "            {\"parts\": [{\"text\": \"Write a short poem about sunrise\"}]}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, json=data)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "        print(\"--- Gemini API Test Response ---\")\n",
        "        print(response.json())\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error calling Gemini API: {e}\")\n",
        "else:\n",
        "    print(\"Skipping Gemini API test as API_KEY is not set.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI_API_KEY environment variable not found. Gemini API calls will likely fail.\n",
            "Skipping Gemini API test as API_KEY is not set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c036097f",
        "outputId": "e62a2a43-4e9f-4554-9ff1-bda1ee8d3ee9"
      },
      "source": [
        "# Cell 4: Minimal Gemini test (single-language) using environment variable\n",
        "from google import genai\n",
        "import os\n",
        "\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "     print(\"GEMINI_API_KEY environment variable not found. Skipping Gemini test.\")\n",
        "else:\n",
        "    try:\n",
        "        client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "        # Quick test - simple English prompt\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"models/gemini-2.5-flash\",   # Changed model to gemini-2.5-flash\n",
        "            contents=\"Write a short (30-40 word) Instagram caption about greed and money.\"\n",
        "        )\n",
        "\n",
        "        print(\"--- Raw response text ---\")\n",
        "        print(resp.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Gemini test: {e}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI_API_KEY environment variable not found. Skipping Gemini test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f2bcd09",
        "outputId": "4d396647-5799-403b-beee-6d99dd566d1f"
      },
      "source": [
        "# Cell 5: Structured multilingual generation using environment variable\n",
        "from google import genai\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if not API_KEY:\n",
        "    print(\"GEMINI_API_KEY environment variable not found. Skipping multilingual generation test.\")\n",
        "    data = None # Ensure 'data' is None if skipping\n",
        "else:\n",
        "    try:\n",
        "        client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "        prompt = \"\"\"\n",
        "        You are a professional multilingual social media writer.\n",
        "        Produce a short motivational Instagram caption about greed and money.\n",
        "        Return EXACTLY a JSON object (no extra text) with keys:\n",
        "        {\n",
        "          \"en\": \"<English caption (30-40 words)>\",\n",
        "          \"ar\": \"<Arabic caption>\",\n",
        "          \"am\": \"<Amharic caption>\"\n",
        "        }\n",
        "        Make sure the values are plain strings and the entire response is valid JSON only.\n",
        "        \"\"\"\n",
        "\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"models/gemini-2.5-flash\", # Changed model to models/gemini-2.5-flash\n",
        "            contents=prompt,\n",
        "            # optional: adjust token budget (max_output_tokens) if needed:\n",
        "            # max_output_tokens=300\n",
        "        )\n",
        "\n",
        "        raw = resp.text.strip()\n",
        "        print(\"---- raw output ----\")\n",
        "        print(raw[:800])\n",
        "\n",
        "        # Try to extract JSON from the response robustly:\n",
        "        json_text = None\n",
        "        try:\n",
        "            json_text = raw\n",
        "            data = json.loads(json_text)\n",
        "        except Exception:\n",
        "            # fallback: try to locate JSON block inside the text\n",
        "            m = re.search(r\"(\\{[\\s\\S]*\\})\", raw)\n",
        "            if m:\n",
        "                try:\n",
        "                    data = json.loads(m.group(1))\n",
        "                    json_text = m.group(1)\n",
        "                except Exception as e:\n",
        "                    print(\"Failed to parse JSON fallback:\", e)\n",
        "                    data = None\n",
        "            else:\n",
        "                print(\"No JSON block detected in model output.\")\n",
        "                data = None\n",
        "\n",
        "        print(\"\\n=== Parsed data ===\")\n",
        "        display(data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during multilingual generation test: {e}\")\n",
        "        data = None # Ensure data is None on error"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI_API_KEY environment variable not found. Skipping multilingual generation test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42447983",
        "outputId": "03d385d1-e0db-4c18-98af-6046f2bce0b0"
      },
      "source": [
        "# Cell 7: Create a short reel (image + audio) - Ensure audio file exists\n",
        "# This cell assumes outputs/tts_en.mp3 and assets/sample.jpg exist from previous steps.\n",
        "# If running independently, ensure those files are created first.\n",
        "\n",
        "# Install required packages if running this cell independently\n",
        "# !pip install -q moviepy==1.0.3 gTTS==2.5.0\n",
        "\n",
        "import os\n",
        "from moviepy.editor import ImageClip, AudioFileClip\n",
        "\n",
        "# Ensure outputs directory exists\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "audio_file = \"outputs/tts_en.mp3\"\n",
        "img_file = \"assets/sample.jpg\" # Assuming sample.jpg is already downloaded\n",
        "\n",
        "if not os.path.exists(audio_file):\n",
        "    print(f\"Warning: Audio file not found at {audio_file}. Skipping video creation.\")\n",
        "elif not os.path.exists(img_file):\n",
        "    print(f\"Warning: Sample image not found at {img_file}. Skipping video creation.\")\n",
        "else:\n",
        "    try:\n",
        "        # Check if data and English text are available (from Cell 5)\n",
        "        if 'data' in globals() and data and 'en' in data and data['en']:\n",
        "             # Use the generated English caption from the `data` variable\n",
        "             # Although gTTS is already used in Cell 6 to create the file,\n",
        "             # this check ensures we have the source text if needed.\n",
        "             print(\"Using existing audio and sample image for reel creation.\")\n",
        "\n",
        "             # Create the video clip from the sample image\n",
        "             clip = ImageClip(img_file, duration=8).set_fps(24)\n",
        "\n",
        "             # Load the audio clip\n",
        "             audio = AudioFileClip(audio_file).subclip(0,min(8, AudioFileClip(audio_file).duration)) # Trim audio to 8 seconds or less\n",
        "\n",
        "             # Set the audio of the video clip\n",
        "             video = clip.set_audio(audio)\n",
        "\n",
        "             # Define output path\n",
        "             out_path = \"outputs/reel_en.mp4\"\n",
        "\n",
        "             # Write the video file\n",
        "             video.write_videofile(out_path, codec=\"libx264\", audio_codec=\"aac\", fps=24, verbose=False, logger=None) # Reduced verbosity\n",
        "\n",
        "             print(\"Saved reel:\", out_path)\n",
        "        else:\n",
        "            print(\"Warning: Generated text data ('data' from Cell 5) or English caption is missing. Skipping reel creation.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating reel: {e}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Generated text data ('data' from Cell 5) or English caption is missing. Skipping reel creation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21fd9ff6",
        "outputId": "465f3b93-d6ae-4d22-e168-95de95ed767a"
      },
      "source": [
        "# Cell 8: Save metadata and optionally mount Drive - Ensure 'data' exists\n",
        "import json, time\n",
        "import os # Ensure os is imported\n",
        "\n",
        "# Ensure outputs directory exists\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "# Check if 'data' variable is available from Cell 5\n",
        "if 'data' in globals() and data:\n",
        "    meta = {\n",
        "        \"generated\": data,\n",
        "        \"files\": {\n",
        "            # Check if audio and video files exist before adding to metadata\n",
        "            \"tts_en\": \"outputs/tts_en.mp3\" if os.path.exists(\"outputs/tts_en.mp3\") else None,\n",
        "            \"tts_ar\": \"outputs/tts_ar.mp3\" if os.path.exists(\"outputs/tts_ar.mp3\") else None,\n",
        "            \"video_en\": \"outputs/reel_en.mp4\" if os.path.exists(\"outputs/reel_en.mp4\") else None,\n",
        "            # Add the path to the video created in Cell cd7de905 if it exists\n",
        "             \"video_creative\": \"outputs/reel_creative.mp4\" if os.path.exists(\"outputs/reel_creative.mp4\") else None\n",
        "        },\n",
        "        \"created_at\": time.time()\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with open(\"outputs/draft_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(\"Saved outputs/draft_meta.json\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving metadata: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"Warning: 'data' variable not found. Skipping metadata saving.\")\n",
        "\n",
        "\n",
        "# To persist to Drive (uncomment if you want):\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r outputs /content/drive/MyDrive/AI_Content_MVP_outputs"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 'data' variable not found. Skipping metadata saving.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5804590e",
        "outputId": "28b51f0a-31fe-45f0-994e-5dde44916daf"
      },
      "source": [
        "# Cell 3: Set the GOOGLE_CLIENT_ID environment variable using %env (for Colab session)\n",
        "# This is suitable for demonstration in Colab, but for local development or production,\n",
        "# you would set this variable outside your code (e.g., in a .env file or deployment config).\n",
        "\n",
        "# Replace \"YOUR_GOOGLE_CLIENT_ID\" with your actual Google Client ID\n",
        "# %env GOOGLE_CLIENT_ID=\"1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\"\n",
        "\n",
        "# In your Python code, access it using os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "import os\n",
        "google_client_id = os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "\n",
        "if google_client_id:\n",
        "    print(\"GOOGLE_CLIENT_ID environment variable is set.\")\n",
        "else:\n",
        "    print(\"GOOGLE_CLIENT_ID environment variable is NOT set. Google Sign-In verification will fail if attempted.\")\n",
        "\n",
        "# You can verify it's set by running:\n",
        "# import os\n",
        "# print(os.environ.get(\"GOOGLE_CLIENT_ID\"))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOOGLE_CLIENT_ID environment variable is NOT set. Google Sign-In verification will fail if attempted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a435b11",
        "outputId": "b726941d-ca10-4615-fb4b-d424fa062ec8"
      },
      "source": [
        "# Cell 6: Integrate the content generation logic into the /api/generate-content endpoint.\n",
        "# This code block replaces the previous definition of the generate_content route\n",
        "# and includes the necessary imports and initialization for the Flask app.\n",
        "\n",
        "from flask import Flask, request, jsonify, send_from_directory # Import send_from_directory\n",
        "from flask_cors import CORS # Import CORS\n",
        "import os\n",
        "# from flask_ngrok import run_with_ngrok # Removed flask_ngrok as we are using cloudflared\n",
        "import json, re, requests\n",
        "from gtts import gTTS\n",
        "\n",
        "# Import libraries for MoviePy (handle imports inside the function for potentially faster startup if not all features are used)\n",
        "# from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, TextClip, CompositeVideoClip, concatenate_audioclips\n",
        "# from moviepy.video.fx.all import fadein, fadeout\n",
        "# import moviepy.config as mp_config\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__, static_folder=None) # Set static_folder to None for explicit serving\n",
        "CORS(app) # Enable CORS for the app\n",
        "\n",
        "# Set environment variables (should be set outside the notebook for production)\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\", \"\")\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\", \"\")\n",
        "UNSPLASH_ACCESS_KEY = os.environ.get(\"UNSPLASH_ACCESS_KEY\", \"\")\n",
        "\n",
        "# Initialize GenAI client only if GEMINI_API_KEY is available\n",
        "genai_client = None\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        from google import genai # Import genai here to avoid import errors if package is not installed\n",
        "        genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "        print(\"GenAI client initialized.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing GenAI client: {e}\")\n",
        "\n",
        "# Set ImageMagick path (needed for TextClip, but potentially problematic as seen)\n",
        "# This setting is still here as part of the original integration attempt.\n",
        "# Text overlay functionality remains commented out due to previous issues.\n",
        "IMAGEMAGICK_PATH = '/usr/bin/convert' # Or the path found in your environment\n",
        "if os.path.exists(IMAGEMAGICK_PATH):\n",
        "    try:\n",
        "        import moviepy.config as mp_config # Import moviepy.config here\n",
        "        mp_config.change_settings({\"IMAGEMAGICK_BINARY\": IMAGEMAGICK_PATH})\n",
        "        print(f\"Set ImageMagick binary path to: {IMAGEMAGICK_PATH}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting ImageMagick path with MoviePy: {e}\")\n",
        "else:\n",
        "    print(f\"Warning: ImageMagick binary not found at {IMAGEMAGICK_PATH}. Text overlay might fail.\")\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return 'âœ… Flask backend is running via Cloudflare Tunnel!'\n",
        "\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Specify the CLIENT_ID of the app that accesses the backend:\n",
        "        if not GOOGLE_CLIENT_ID:\n",
        "             return jsonify({\"error\": \"GOOGLE_CLIENT_ID is not set on the backend\"}), 500\n",
        "\n",
        "        from google.oauth2 import id_token # Import here to avoid import errors\n",
        "        from google.auth.transport import requests as google_requests # Import here\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), GOOGLE_CLIENT_ID)\n",
        "\n",
        "        # ID token is valid. Get the user's Google Account ID from the decoded token.\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '')\n",
        "\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\n",
        "                \"id\": userid,\n",
        "                \"email\": email,\n",
        "                \"name\": name\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except ValueError:\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "\n",
        "    print(f\"Received prompt from frontend: {prompt}\")\n",
        "\n",
        "    # --- 1. Generate Multilingual Text (Gemini API) ---\n",
        "    text_data = {\"en\": f\"Inspiration: {prompt}\", \"ar\": \"\", \"am\": \"\"} # Default/fallback text\n",
        "    if not genai_client:\n",
        "         print(\"Warning: Gemini API client not initialized. Skipping text generation.\")\n",
        "    else:\n",
        "        text_prompt = f\"\"\"\n",
        "        You are a professional multilingual social media writer.\n",
        "        Create a short Instagram caption in English, Arabic and Amharic about: \"{prompt}\"\n",
        "        Return only valid JSON object with keys \"en\",\"ar\",\"am\".\n",
        "        \"\"\"\n",
        "        try:\n",
        "            text_resp = genai_client.models.generate_content(\n",
        "                model=\"models/gemini-2.5-flash\",\n",
        "                contents=text_prompt\n",
        "            )\n",
        "            raw_text = text_resp.text.strip()\n",
        "\n",
        "            # Robustly parse JSON from the model output\n",
        "            parsed_text_data = None\n",
        "            try:\n",
        "                parsed_text_data = json.loads(raw_text)\n",
        "            except Exception:\n",
        "                m = re.search(r\"(\\{[\\s\\S]*\\})\", raw_text)\n",
        "                if m:\n",
        "                    try:\n",
        "                        parsed_text_data = json.loads(m.group(1))\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                if not parsed_text_data:\n",
        "                     print(\"Warning: Failed to parse JSON from model output.\")\n",
        "                     print(\"Raw model output:\", raw_text)\n",
        "\n",
        "            if parsed_text_data:\n",
        "                 text_data = {\n",
        "                     \"en\": parsed_text_data.get(\"en\", text_data[\"en\"]),\n",
        "                     \"ar\": parsed_text_data.get(\"ar\", \"\"),\n",
        "                     \"am\": parsed_text_data.get(\"am\", \"\")\n",
        "                 }\n",
        "                 print(\"Generated text data:\", text_data)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating text content: {e}\")\n",
        "\n",
        "\n",
        "    # --- 2. Generate Audio (gTTS) ---\n",
        "    os.makedirs(\"/content/afro_content_ai/backend/outputs\", exist_ok=True) # Ensure outputs dir exists relative to backend\n",
        "    audio_path = None\n",
        "    en_text = text_data.get(\"en\", \"\")\n",
        "    if en_text:\n",
        "        try:\n",
        "            # Generate a unique filename for the audio\n",
        "            audio_filename = f\"tts_en_{os.urandom(4).hex()}.mp3\"\n",
        "            # Save audio to a location accessible by the backend and potentially served later\n",
        "            # We'll save it inside the afro_content_ai/backend/outputs directory\n",
        "            audio_file_path_backend = os.path.join(\"/content/afro_content_ai/backend/outputs\", audio_filename)\n",
        "\n",
        "            tts = gTTS(en_text, lang='en')\n",
        "            tts.save(audio_file_path_backend)\n",
        "            print(\"Saved audio:\", audio_file_path_backend)\n",
        "            # Store the path relative to the outputs directory for the response\n",
        "            audio_path = f\"/outputs/{audio_filename}\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating audio: {e}\")\n",
        "\n",
        "\n",
        "    # --- 3. Fetch Images (Unsplash API) ---\n",
        "    IMAGE_COUNT = 5\n",
        "    VIDEO_DURATION_PER_IMAGE = 8\n",
        "    image_dir = \"/content/afro_content_ai/backend/downloaded_images\" # Save images relative to backend\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "    image_files = []\n",
        "\n",
        "    # Use the English caption as a search query\n",
        "    img_search_query = en_text if en_text else prompt\n",
        "\n",
        "    if not UNSPLASH_ACCESS_KEY:\n",
        "        print(\"Warning: Unsplash Access Key is not set. Skipping image fetching.\")\n",
        "    else:\n",
        "        try:\n",
        "            unsplash_url = \"https://api.unsplash.com/search/photos\"\n",
        "            headers = {\"Authorization\": f\"Client-ID {UNSPLASH_ACCESS_KEY}\"}\n",
        "            params = {\"query\": img_search_query, \"per_page\": IMAGE_COUNT, \"orientation\": \"landscape\"}\n",
        "\n",
        "            r = requests.get(unsplash_url, headers=headers, params=params, timeout=20)\n",
        "            r.raise_for_status()\n",
        "            image_results = r.json().get(\"results\", [])\n",
        "\n",
        "            if image_results:\n",
        "                print(f\"Found {len(image_results)} images. Downloading...\")\n",
        "                for i, item in enumerate(image_results[:IMAGE_COUNT]):\n",
        "                    url = item.get(\"urls\", {}).get(\"regular\")\n",
        "                    if url:\n",
        "                        # Generate a unique filename for each image\n",
        "                        img_filename = f\"img_{i+1}_{os.urandom(4).hex()}.jpg\"\n",
        "                        path = os.path.join(image_dir, img_filename)\n",
        "                        try:\n",
        "                            with requests.get(url, stream=True, timeout=30) as rr:\n",
        "                                rr.raise_for_status()\n",
        "                                with open(path, \"wb\") as f:\n",
        "                                    for chunk in rr.iter_content(8192):\n",
        "                                        f.write(chunk)\n",
        "                            image_files.append(path)\n",
        "                            print(f\"Downloaded: {path}\")\n",
        "                        except requests.exceptions.RequestException as e:\n",
        "                            print(f\"Error downloading image {url}: {e}\")\n",
        "\n",
        "            else:\n",
        "                print(\"No images found from Unsplash search.\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Unsplash fetch error: {e}\")\n",
        "\n",
        "\n",
        "    # Fallback to sample image if no images were downloaded\n",
        "    if not image_files:\n",
        "        sample_img_path = \"/content/afro_content_ai/assets/sample.jpg\" # Path to the sample image\n",
        "        if os.path.exists(sample_img_path):\n",
        "             image_files.extend([sample_img_path] * IMAGE_COUNT) # Use sample image multiple times\n",
        "             print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "        else:\n",
        "            print(f\"Error: Sample image not found at {sample_img_path}. Cannot create video without images.\")\n",
        "            return jsonify({\"error\": \"No images available to create video\"}), 500\n",
        "\n",
        "\n",
        "    # --- 4. Create Video (MoviePy) ---\n",
        "    video_path = None\n",
        "    if image_files:\n",
        "        try:\n",
        "            # Import moviepy components inside the try block\n",
        "            from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, concatenate_audioclips\n",
        "            from moviepy.video.fx.all import fadein, fadeout\n",
        "\n",
        "            print(\"Creating video with downloaded images and transitions...\")\n",
        "            image_clips = [ImageClip(img_path).set_duration(VIDEO_DURATION_PER_IMAGE) for img_path in image_files]\n",
        "\n",
        "            # Apply fade transitions (if more than one image)\n",
        "            if len(image_clips) > 1:\n",
        "                FADE_DURATION = 1.5 # Define fade duration\n",
        "                clips_to_concat_with_transitions = []\n",
        "                for i in range(len(image_clips)):\n",
        "                    clip = image_clips[i]\n",
        "                    if i > 0:\n",
        "                        clip = clip.fx(fadein, duration=FADE_DURATION)\n",
        "                    if i < len(image_clips) - 1:\n",
        "                        clip = clip.fx(fadeout, duration=FADE_DURATION)\n",
        "                    clips_to_concat_with_transitions.append(clip)\n",
        "\n",
        "                final_video_clip = concatenate_videoclips(clips_to_concat_with_transitions, method=\"compose\")\n",
        "            else:\n",
        "                 final_video_clip = image_clips[0] # Only one clip\n",
        "\n",
        "            # Add Audio to Video\n",
        "            if audio_path: # Check if audio was successfully generated\n",
        "                 audio_clip = AudioFileClip(os.path.join(\"/content/afro_content_ai/backend\", audio_path)) # Load audio from its saved path\n",
        "\n",
        "                 # Adjust audio duration to match the total video duration\n",
        "                 if audio_clip.duration < final_video_clip.duration:\n",
        "                     num_loops = int(final_video_clip.duration / audio_clip.duration) + 1\n",
        "                     looped_audio = concatenate_audioclips([audio_clip] * num_loops)\n",
        "                     audio_clip = looped_audio.subclip(0, final_video_clip.duration)\n",
        "\n",
        "                 elif audio_clip.duration > final_video_clip.duration:\n",
        "                      audio_clip = audio_clip.subclip(0, final_video_clip.duration)\n",
        "\n",
        "                 video_final = final_video_clip.set_audio(audio_clip)\n",
        "            else:\n",
        "                video_final = final_video_clip # Video without audio\n",
        "\n",
        "\n",
        "            # Generate a unique filename for the output video\n",
        "            video_filename = f\"generated_reel_{os.urandom(4).hex()}.mp4\"\n",
        "            # Save video inside the afro_content_ai/backend/outputs directory\n",
        "            out_path_backend = os.path.join(\"/content/afro_content_ai/backend/outputs\", video_filename)\n",
        "            os.makedirs(\"/content/afro_content_ai/backend/outputs\", exist_ok=True)\n",
        "\n",
        "            video_final.write_videofile(\n",
        "                out_path_backend,\n",
        "                codec=\"libx264\",\n",
        "                audio_codec=\"aac\",\n",
        "                fps=24,\n",
        "                preset=\"medium\",\n",
        "                verbose=False, # Reduce verbosity\n",
        "                logger=None # Suppress logger messages\n",
        "            )\n",
        "            print(\"Saved generated reel:\", out_path_backend)\n",
        "            # Store the path relative to the outputs directory for the response\n",
        "            video_path = f\"/outputs/{video_filename}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Video creation error: {e}\")\n",
        "            video_path = None # Ensure video_path is None on error\n",
        "\n",
        "    else:\n",
        "        print(\"No images available to create video.\")\n",
        "\n",
        "\n",
        "    # --- 5. Return Response ---\n",
        "    # Return the generated text content, and the paths to the audio and video files\n",
        "    # relative to the outputs directory.\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Content generation process completed\",\n",
        "        \"text\": text_data,\n",
        "        \"audio\": audio_path, # Path to the generated audio file (relative to outputs)\n",
        "        \"video\": video_path # Path to the generated video file (relative to outputs)\n",
        "    })\n",
        "\n",
        "\n",
        "# Add a route to serve static files from the outputs directory\n",
        "# This is necessary for the frontend to access the generated audio and video files\n",
        "@app.route('/outputs/<filename>')\n",
        "def serve_output_file(filename):\n",
        "    # Serve files from the outputs directory within the backend project structure\n",
        "    output_dir = \"/content/afro_content_ai/backend/outputs\"\n",
        "    return send_from_directory(output_dir, filename)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This block is for running the Flask app directly (e.g., for local development).\n",
        "    # When using the Colab setup with cloudflared in a separate thread (as in cell nzGsqP3kfnfS or Rjxt-wpIMNd8),\n",
        "    # the app is started by that cell, so app.run() here is not needed.\n",
        "    pass"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ImageMagick binary not found at /usr/bin/convert. Text overlay might fail.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa763213",
        "outputId": "f015d420-0761-4912-ab9d-cd8a0f614ed7"
      },
      "source": [
        "# Cell 4: Run Flask + Cloudflared - Ensure GOOGLE_CLIENT_ID is set before running\n",
        "import os\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import re\n",
        "from flask import Flask, request, jsonify\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "from flask_cors import CORS # Import CORS\n",
        "\n",
        "# Kill any existing Flask process (optional, but good for cleanup)\n",
        "!kill -9 $(lsof -t -i:5000) 2>/dev/null || echo \"No previous Flask process running.\"\n",
        "\n",
        "# Google Client ID - Get from environment variable\n",
        "# os.environ[\"GOOGLE_CLIENT_ID\"] = \"1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\" # Remove hardcoded value\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "\n",
        "# Flask app - Ensure CORS is applied here too if not in the app definition itself\n",
        "# If the app is defined in a separate file (like backend/app.py), import and use that app instance.\n",
        "# from backend.app import app # Uncomment if app is in backend/app.py\n",
        "\n",
        "# If app is defined in this cell (as in Rjxt-wpIMNd8), ensure CORS is initialized.\n",
        "app = Flask(__name__)\n",
        "CORS(app) # Apply CORS\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return 'âœ… Flask backend is running via Cloudflare Tunnel!'\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    if not GOOGLE_CLIENT_ID:\n",
        "        return jsonify({\"error\": \"GOOGLE_CLIENT_ID not set on the backend\"}), 500\n",
        "\n",
        "    try:\n",
        "        idinfo = id_token.verify_oauth2_token(\n",
        "            token, google_requests.Request(), GOOGLE_CLIENT_ID\n",
        "        )\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '')\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\"id\": userid, \"email\": email, \"name\": name}\n",
        "        })\n",
        "    except ValueError:\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "# NOTE: The /api/generate-content route implementation with content generation logic\n",
        "# is expected to be in the 'app' instance being run. If 'app' is defined in backend/app.py\n",
        "# and imported, the logic from backend/app.py will be used.\n",
        "# If 'app' is defined directly in this cell, you need to include the generate_content\n",
        "# route definition here.\n",
        "\n",
        "# Assuming 'app' is imported from backend/app.py which contains the generate_content logic:\n",
        "# from backend.app import app\n",
        "\n",
        "# If app is defined in this cell, add the route here (example - replace with full logic):\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "    # This is a placeholder. The actual content generation logic should be here\n",
        "    # or in the imported 'app' instance if using backend/app.py.\n",
        "    print(f\"Received prompt: {prompt}\")\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Prompt received successfully by the tunneling script's app instance\",\n",
        "        \"received_prompt\": prompt\n",
        "    })\n",
        "\n",
        "\n",
        "# Function to run Flask\n",
        "def run_flask():\n",
        "    # If importing app from backend/app.py, run that app instance.\n",
        "    # If defining app in this cell, run this cell's app instance.\n",
        "    # Ensure debug=False and use_reloader=False for background thread.\n",
        "    app.run(host=\"0.0.0.0\", port=5000, debug=False, use_reloader=False) # Use host=\"0.0.0.0\" for Colab\n",
        "\n",
        "\n",
        "# Function to run Cloudflared and print public URL\n",
        "def start_cloudflared():\n",
        "    # Wait for Flask to start\n",
        "    time.sleep(3)\n",
        "    proc = subprocess.Popen(\n",
        "        [\"cloudflared\", \"tunnel\", \"--url\", \"http://localhost:5000\", \"--no-autoupdate\"],\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        "    )\n",
        "    for line in iter(proc.stdout.readline, \"\"):\n",
        "        print(line, end=\"\")\n",
        "        # Find the public URL in the output\n",
        "        if \"trycloudflare.com\" in line:\n",
        "            match = re.search(r\"https://[0-9a-z\\-]+\\.trycloudflare\\.com\", line)\n",
        "            if match:\n",
        "                print(\"\\nðŸŒ PUBLIC URL:\", match.group(0))\n",
        "                print(\"ðŸ”— You can now use this URL in your front-end or Postman tests.\\n\")\n",
        "\n",
        "\n",
        "# Run both Flask and Cloudflared in parallel\n",
        "# Ensure GOOGLE_CLIENT_ID is set before starting Flask.\n",
        "if GOOGLE_CLIENT_ID:\n",
        "    print(\"Starting Flask app and Cloudflare tunnel...\")\n",
        "    flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
        "    cloudflared_thread = threading.Thread(target=start_cloudflared, daemon=True)\n",
        "\n",
        "    flask_thread.start()\n",
        "    cloudflared_thread.start()\n",
        "\n",
        "    # Keep the cell alive so the threads continue running\n",
        "    try:\n",
        "        while True:\n",
        "            time.sleep(1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nStopping Flask and Cloudflared...\")\n",
        "        # Threads are daemon, so they will exit when the main program exits.\n",
        "else:\n",
        "    print(\"GOOGLE_CLIENT_ID not set. Skipping Flask and Cloudflare tunnel startup.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No previous Flask process running.\n",
            "GOOGLE_CLIENT_ID not set. Skipping Flask and Cloudflare tunnel startup.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28963486",
        "outputId": "b24789f7-2e32-40d7-c76d-26c826f898f1"
      },
      "source": [
        "# Step 1 â€” Install dependencies (Combined cell 1 and 15 logic)\n",
        "# Ensure all necessary packages for both backend and content generation are installed.\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q Flask Flask-Cors google-auth requests google-generativeai==1.43.0 gTTS==2.5.0 moviepy==1.0.3 cloudflared\n",
        "\n",
        "print(\"\\nâœ… All required packages are installed.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.0rc2\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement google-generativeai==1.43.0 (from versions: 0.1.0rc1, 0.1.0rc3, 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.3.0, 0.3.1, 0.3.2, 0.4.0, 0.4.1, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.6.0, 0.7.0, 0.7.1, 0.7.2, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.8.4, 0.8.5)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for google-generativeai==1.43.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "âœ… All required packages are installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d81bc5b2",
        "outputId": "21f7f964-2b79-42a1-902c-25473b7e4adb"
      },
      "source": [
        "# Step 2 â€” Configure environment (Combined cell 16 logic)\n",
        "# Set environment variables for Google Client ID, Gemini API Key, Unsplash Access Key.\n",
        "# IMPORTANT: For security, set these as Colab Secrets (ðŸ”‘ icon on the left panel)\n",
        "# and access them using `userdata.get()`. Avoid hardcoding or setting directly\n",
        "# in environment variables within a notebook you share.\n",
        "\n",
        "import os\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# Get secrets from Colab Secrets\n",
        "# Replace the key names below if you used different names in Colab Secrets\n",
        "# Fix: userdata.get() now only takes one argument (the key name)\n",
        "google_client_id = userdata.get(\"GOOGLE_CLIENT_ID\") # Get from Colab Secrets\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")     # Get from Colab Secrets\n",
        "unsplash_access_key = userdata.get(\"UNSPLASH_ACCESS_KEY\") # Get from Colab Secrets\n",
        "\n",
        "# Set environment variables from secrets (optional, but useful if your code expects them in os.environ)\n",
        "# Add checks to ensure the secrets were retrieved before setting environment variables\n",
        "if google_client_id:\n",
        "    os.environ[\"GOOGLE_CLIENT_ID\"] = google_client_id\n",
        "else:\n",
        "    print(\"Warning: GOOGLE_CLIENT_ID not found in Colab Secrets.\")\n",
        "\n",
        "if gemini_api_key:\n",
        "    os.environ[\"GEMINI_API_KEY\"] = gemini_api_key\n",
        "else:\n",
        "     print(\"Warning: GEMINI_API_KEY not found in Colab Secrets.\")\n",
        "\n",
        "if unsplash_access_key:\n",
        "    os.environ[\"UNSPLASH_ACCESS_KEY\"] = unsplash_access_key\n",
        "else:\n",
        "    print(\"Warning: UNSPLASH_ACCESS_KEY not found in Colab Secrets.\")\n",
        "\n",
        "\n",
        "print(\"Attempting to set environment variables from Colab Secrets.\")\n",
        "print(\"Ensure your secrets are named GOOGLE_CLIENT_ID, GEMINI_API_KEY, and UNSPLASH_ACCESS_KEY in Colab Secrets.\")\n",
        "\n",
        "# Verify if variables are set (without printing values)\n",
        "if os.environ.get(\"GOOGLE_CLIENT_ID\"):\n",
        "    print(\"GOOGLE_CLIENT_ID environment variable is set (from secrets).\")\n",
        "else:\n",
        "    print(\"GOOGLE_CLIENT_ID environment variable is NOT set (check Colab Secrets).\")\n",
        "\n",
        "if os.environ.get(\"GEMINI_API_KEY\"):\n",
        "    print(\"GEMINI_API_KEY environment variable is set (from secrets).\")\n",
        "else:\n",
        "    print(\"GEMINI_API_KEY environment variable is NOT set (check Colab Secrets).\")\n",
        "\n",
        "if os.environ.get(\"UNSPLASH_ACCESS_KEY\"):\n",
        "    print(\"UNSPLASH_ACCESS_KEY environment variable is set (from secrets).\")\n",
        "else:\n",
        "    print(\"UNSPLASH_ACCESS_KEY environment variable is NOT set (check Colab Secrets).\")\n",
        "\n",
        "# The actual Flask app and generation logic will read these using os.environ.get()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret GOOGLE_CLIENT_ID does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-547866832.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Replace the key names below if you used different names in Colab Secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Fix: userdata.get() now only takes one argument (the key name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgoogle_client_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GOOGLE_CLIENT_ID\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get from Colab Secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mgemini_api_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GEMINI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Get from Colab Secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0munsplash_access_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNSPLASH_ACCESS_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get from Colab Secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret GOOGLE_CLIENT_ID does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53cd90c8",
        "outputId": "288f707e-4621-4bdf-9077-be99954ac760"
      },
      "source": [
        "# Step 5: Implement the basic frontend UI and connect to the backend.\n",
        "# This involves creating React components (App.jsx) that include:\n",
        "# - Input field for prompt\n",
        "# - Button to trigger generation\n",
        "# - Display area for response (text, audio, video)\n",
        "# - Using axios to send POST request to the backend /api/generate-content endpoint.\n",
        "\n",
        "# This is primarily a conceptual step for the frontend code.\n",
        "# We will overwrite afro_content_ai/frontend/src/App.jsx with the updated code.\n",
        "\n",
        "# Define the content for the updated App.jsx\n",
        "app_jsx_content = \"\"\"\n",
        "import { useState } from 'react';\n",
        "import axios from 'axios';\n",
        "\n",
        "function App() {\n",
        "  const [prompt, setPrompt] = useState('');\n",
        "  const [response, setResponse] = useState(null);\n",
        "  const [loading, setLoading] = useState(false);\n",
        "  const [error, setError] = useState(null);\n",
        "\n",
        "  // Replace with the actual public URL from your Cloudflare Tunnel output\n",
        "  // This URL changes each time the tunnel is started in Colab.\n",
        "  // In a real deployment, this would be a fixed domain name.\n",
        "  const backendUrl = \"YOUR_BACKEND_PUBLIC_URL\"; // <<< PASTE YOUR CLOUDFLARED PUBLIC URL HERE\n",
        "\n",
        "  const handleGenerate = async () => {\n",
        "    if (!prompt.trim()) {\n",
        "      setError(\"Please enter a prompt.\");\n",
        "      return;\n",
        "    }\n",
        "    if (backendUrl === \"YOUR_BACKEND_PUBLIC_URL\") {\n",
        "        setError(\"Please update the backendUrl in App.jsx with your Cloudflare Tunnel URL.\");\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    setLoading(true);\n",
        "    setResponse(null);\n",
        "    setError(null);\n",
        "\n",
        "    try {\n",
        "      const result = await axios.post(`${backendUrl}/api/generate-content`, { prompt });\n",
        "      setResponse(result.data);\n",
        "    } catch (err) {\n",
        "      console.error(\"Error calling backend:\", err);\n",
        "      setError(err.message || \"An error occurred while generating content.\");\n",
        "    } finally {\n",
        "      setLoading(false);\n",
        "    }\n",
        "  };\n",
        "\n",
        "  return (\n",
        "    <div style={{ padding: '20px', fontFamily: 'sans-serif', maxWidth: '600px', margin: 'auto' }}>\n",
        "      <h2>Afro Content AI Generator</h2>\n",
        "\n",
        "      <div style={{ marginBottom: '20px' }}>\n",
        "        <textarea\n",
        "          value={prompt}\n",
        "          onChange={(e) => setPrompt(e.target.value)}\n",
        "          rows={4}\n",
        "          cols={50}\n",
        "          placeholder=\"Enter your idea for content...\"\n",
        "          style={{ width: '100%', padding: '10px', boxSizing: 'border-box', border: '1px solid #ccc', borderRadius: '4px' }}\n",
        "        />\n",
        "      </div>\n",
        "\n",
        "      <button\n",
        "        onClick={handleGenerate}\n",
        "        disabled={loading || !prompt.trim() || backendUrl === \"YOUR_BACKEND_PUBLIC_URL\"}\n",
        "        style={{\n",
        "          padding: '10px 20px',\n",
        "          fontSize: '16px',\n",
        "          cursor: 'pointer',\n",
        "          backgroundColor: loading || !prompt.trim() || backendUrl === \"YOUR_BACKEND_PUBLIC_URL\" ? '#cccccc' : '#007bff',\n",
        "          color: 'white',\n",
        "          border: 'none',\n",
        "          borderRadius: '4px'\n",
        "        }}\n",
        "      >\n",
        "        {loading ? 'Generating...' : 'Generate Content'}\n",
        "      </button>\n",
        "\n",
        "      {error && (\n",
        "        <div style={{ color: 'red', marginTop: '15px' }}>\n",
        "          Error: {error}\n",
        "        </div>\n",
        "      )}\n",
        "\n",
        "      {response && (\n",
        "        <div style={{ marginTop: '20px', borderTop: '1px solid #eee', paddingTop: '20px' }}>\n",
        "          <h3>Generated Content:</h3>\n",
        "          {response.status === 'success' ? (\n",
        "            <div>\n",
        "              {response.text && (\n",
        "                <div style={{ marginBottom: '15px' }}>\n",
        "                  <h4>Text:</h4>\n",
        "                  <pre style={{ whiteSpace: 'pre-wrap', wordBreak: 'break-word', backgroundColor: '#f8f8f8', padding: '10px', borderRadius: '4px' }}>\n",
        "                    {JSON.stringify(response.text, null, 2)}\n",
        "                  </pre>\n",
        "                </div>\n",
        "              )}\n",
        "\n",
        "              {response.audio && (\n",
        "                <div style={{ marginBottom: '15px' }}>\n",
        "                   <h4>Audio (English):</h4>\n",
        "                   {/* Construct full audio URL by prepending backendUrl */}\n",
        "                   <audio controls src={`${backendUrl}${response.audio}`} style={{ display: 'block', marginTop: '5px' }} onError={(e) => console.error(\"Audio error:\", e)}>\n",
        "                       Your browser does not support the audio element.\n",
        "                   </audio>\n",
        "                   <p style={{fontSize: '0.8em', color: '#666'}}>Audio path from backend: {response.audio}</p>\n",
        "                </div>\n",
        "              )}\n",
        "\n",
        "              {response.video && (\n",
        "                <div style={{ marginBottom: '15px' }}>\n",
        "                   <h4>Video Reel:</h4>\n",
        "                   {/* Construct full video URL by prepending backendUrl */}\n",
        "                   <video controls width=\"400\" src={`${backendUrl}${response.video}`} style={{ display: 'block', marginTop: '5px' }} onError={(e) => console.error(\"Video error:\", e)}>\n",
        "                       Your browser does not support the video element.\n",
        "                   </video>\n",
        "                    <p style={{fontSize: '0.8em', color: '#666'}}>Video path from backend: {response.video}</p>\n",
        "                </div>\n",
        "              )}\n",
        "\n",
        "               {!response.text && !response.audio && !response.video && (\n",
        "                   <p>Backend returned success but no content files were generated.</p>\n",
        "               )}\n",
        "\n",
        "            </div>\n",
        "          ) : (\n",
        "            <div style={{ color: 'red' }}>\n",
        "              Backend Error: {response.message || \"Unknown error from backend.\"}\n",
        "            </div>\n",
        "          )}\n",
        "        </div>\n",
        "      )}\n",
        "    </div>\n",
        "  );\n",
        "}\n",
        "\n",
        "export default App;\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the frontend App.jsx file\n",
        "# Ensure the afro_content_ai/frontend/src directory exists.\n",
        "import os\n",
        "frontend_app_jsx_path = \"afro_content_ai/frontend/src/App.jsx\"\n",
        "frontend_src_dir = os.path.dirname(frontend_app_jsx_path)\n",
        "os.makedirs(frontend_src_dir, exist_ok=True)\n",
        "\n",
        "with open(frontend_app_jsx_path, \"w\") as f:\n",
        "    f.write(app_jsx_content)\n",
        "\n",
        "print(f\"Created or updated {frontend_app_jsx_path}\")\n",
        "print(\"\\nIMPORTANT: Remember to replace 'YOUR_BACKEND_PUBLIC_URL' in this file with the actual URL from your Cloudflare Tunnel output!\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created or updated afro_content_ai/frontend/src/App.jsx\n",
            "\n",
            "IMPORTANT: Remember to replace 'YOUR_BACKEND_PUBLIC_URL' in this file with the actual URL from your Cloudflare Tunnel output!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c917d339",
        "outputId": "edf10433-b46d-43a4-8846-6e30d80c5aa9"
      },
      "source": [
        "# This cell is for testing the generate-content endpoint locally in Colab.\n",
        "# It sends a POST request to the Flask app running via Cloudflared.\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "\n",
        "# You need to get the public URL from the cloudflared output in the cell that runs Flask + Cloudflared.\n",
        "# Replace the placeholder URL with the actual public URL.\n",
        "# This URL changes each time the tunnel is started in Colab.\n",
        "\n",
        "# IMPORTANT: Manually get the PUBLIC URL from the output of the Flask + Cloudflared cell\n",
        "PUBLIC_URL = \"YOUR_PUBLIC_URL_HERE\" # <<< REPLACE THIS WITH THE ACTUAL PUBLIC URL\n",
        "\n",
        "# Simple check to see if the URL is updated\n",
        "if PUBLIC_URL == \"YOUR_PUBLIC_URL_HERE\":\n",
        "    print(\"Please update PUBLIC_URL in this cell with the actual URL from the Flask/Cloudflared output.\")\n",
        "else:\n",
        "    prompt_data = {\n",
        "        \"prompt\": \"Write a short motivational message about overcoming challenges.\"\n",
        "    }\n",
        "\n",
        "    # Give the server a moment to start\n",
        "    print(\"Waiting 5 seconds for the server to be ready...\")\n",
        "    time.sleep(5)\n",
        "\n",
        "    print(f\"Sending POST request to {PUBLIC_URL}/api/generate-content\")\n",
        "\n",
        "    try:\n",
        "        # Send a POST request to the generate-content endpoint\n",
        "        response = requests.post(f\"{PUBLIC_URL}/api/generate-content\", json=prompt_data)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes (like 404, 500)\n",
        "\n",
        "        # Print the JSON response from the backend\n",
        "        print(\"\\n--- Backend Response ---\")\n",
        "        print(json.dumps(response.json(), indent=2))\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError sending request to backend: {e}\")\n",
        "        print(\"Please ensure the Flask app is running and the PUBLIC_URL is correct.\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"\\nError: Could not decode JSON response from backend.\")\n",
        "        print(\"Response content:\", response.text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please update PUBLIC_URL in this cell with the actual URL from the Flask/Cloudflared output.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "url = \"https://sep-temp-mega-ips.trycloudflare.com/api/generate-content\"\n",
        "r = requests.post(url, json={\"prompt\":\"Hard work and success\"})\n",
        "print(r.status_code)\n",
        "print(r.json())"
      ],
      "metadata": {
        "id": "wVUykJA356-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx create-vite@latest afro_content_ai/frontend -- --template react\n",
        "!cd afro_content_ai/frontend && npm install axios"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhlhawsE19wA",
        "outputId": "d4ae72d6-6bd1-42ac-e46f-e2c8a5f714a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\u001b[?25l\u001b\n",
            "[\n",
            "9\n",
            "0\n",
            "m\n",
            "â”‚\n",
            "\u001b\n",
            "[\n",
            "3\n",
            "9m\n",
            "\u001b\n",
            "[\n",
            "3\n",
            "6\n",
            "m\n",
            "â—†\n",
            "\u001b\n",
            "[\n",
            "3\n",
            "9m\n",
            "S\n",
            "e\n",
            "l\n",
            "e\n",
            "c\n",
            "t\n",
            "a\n",
            "f\n",
            "r\n",
            "a\n",
            "m\n",
            "e\n",
            "w\n",
            "o\n",
            "r\n",
            "k\n",
            ":\n",
            "\u001b\n",
            "[\n",
            "3\n",
            "6\n",
            "m\n",
            "â”‚\n",
            "\u001b\n",
            "[\n",
            "3\n",
            "9m\n",
            "\u001b\n",
            "[\n",
            "3\n",
            "6\n",
            "m\n",
            "â””\n",
            "\u001b\n",
            "[\n",
            "3\n",
            "9m\n",
            "^C\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "up to date, audited 28 packages in 677ms\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K6 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nTfqhm6y3O9",
        "outputId": "0ce71bbe-a39e-4c6a-a193-cc17b4b59b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (2.32.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.8)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2025.10.5)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install required packages (run in a fresh Colab runtime)\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q google-genai==1.43.0   # stable GenAI SDK (Gemini)\n",
        "!pip install -q deep-translator==1.11.4\n",
        "!pip install -q gTTS==2.5.0\n",
        "!pip install -q moviepy==1.0.3\n",
        "!pip install -q requests==2.32.4\n",
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DdJJJ3mzPEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd89700e-0d02-4c76-b708-3900fa1aa5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: google-genai\n",
            "Version: 1.43.0\n",
            "Summary: GenAI Python SDK\n",
            "Home-page: https://github.com/googleapis/python-genai\n",
            "Author: \n",
            "Author-email: Google LLC <googleapis-packages@google.com>\n",
            "License: Apache-2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: anyio, google-auth, httpx, pydantic, requests, tenacity, typing-extensions, websockets\n",
            "Required-by: google-adk, google-cloud-aiplatform\n",
            "Name: deep-translator\n",
            "Version: 1.11.4\n",
            "Summary: A flexible free and unlimited python tool to translate between different languages in a simple way using multiple translators\n",
            "Home-page: https://github.com/nidhaloff/deep_translator\n",
            "Author: Nidhal Baccouri\n",
            "Author-email: nidhalbacc@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: beautifulsoup4, requests\n",
            "Required-by: \n",
            "Name: gTTS\n",
            "Version: 2.5.0\n",
            "Summary: gTTS (Google Text-to-Speech), a Python library and CLI tool to interface with Google Translate text-to-speech API\n",
            "Home-page: https://github.com/pndurette/gTTS\n",
            "Author: \n",
            "Author-email: Pierre Nicolas Durette <pndurette@gmail.com>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: click, requests\n",
            "Required-by: \n",
            "Name: moviepy\n",
            "Version: 1.0.3\n",
            "Summary: Video editing with Python\n",
            "Home-page: https://zulko.github.io/moviepy/\n",
            "Author: Zulko 2017\n",
            "Author-email: \n",
            "License: MIT License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: decorator, imageio, imageio-ffmpeg, numpy, proglog, requests, tqdm\n",
            "Required-by: \n",
            "Unknown option: -#\n",
            "usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...\n",
            "Try `python -h' for more information.\n",
            "Name: google-genai\n",
            "Version: 1.43.0\n",
            "Summary: GenAI Python SDK\n",
            "Home-page: https://github.com/googleapis/python-genai\n",
            "Author: \n",
            "Author-email: Google LLC <googleapis-packages@google.com>\n",
            "License: Apache-2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: anyio, google-auth, httpx, pydantic, requests, tenacity, typing-extensions, websockets\n",
            "Required-by: google-adk, google-cloud-aiplatform\n",
            "Name: deep-translator\n",
            "Version: 1.11.4\n",
            "Summary: A flexible free and unlimited python tool to translate between different languages in a simple way using multiple translators\n",
            "Home-page: https://github.com/nidhaloff/deep_translator\n",
            "Author: Nidhal Baccouri\n",
            "Author-email: nidhalbacc@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: beautifulsoup4, requests\n",
            "Required-by: \n",
            "Name: gTTS\n",
            "Version: 2.5.0\n",
            "Summary: gTTS (Google Text-to-Speech), a Python library and CLI tool to interface with Google Translate text-to-speech API\n",
            "Home-page: https://github.com/pndurette/gTTS\n",
            "Author: \n",
            "Author-email: Pierre Nicolas Durette <pndurette@gmail.com>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: click, requests\n",
            "Required-by: \n",
            "Name: moviepy\n",
            "Version: 1.0.3\n",
            "Summary: Video editing with Python\n",
            "Home-page: https://zulko.github.io/moviepy/\n",
            "Author: Zulko 2017\n",
            "Author-email: \n",
            "License: MIT License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: decorator, imageio, imageio-ffmpeg, numpy, proglog, requests, tqdm\n",
            "Required-by: \n",
            "Python 3.12.12\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Verify installation versions\n",
        "!pip show google-genai || true\n",
        "!pip show deep-translator || true\n",
        "!pip show gTTS || true\n",
        "!pip show moviepy || true\n",
        "!python -V# Cell 2: Verify installation versions\n",
        "!pip show google-genai || true\n",
        "!pip show deep-translator || true\n",
        "!pip show gTTS || true\n",
        "!pip show moviepy || true\n",
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3Y0Gt1s3_en",
        "outputId": "47e2e9b1-ff89-4e5b-9607-101e7b42cc53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste GEMINI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "{'candidates': [{'content': {'parts': [{'text': \"A blush of pink, then gold begins to bloom,\\nDispelling shadows, chasing back the gloom.\\nThe sun climbs high, a brilliant, fiery grace,\\nAwakening the world, at dawn's sweet pace.\"}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0}], 'usageMetadata': {'promptTokenCount': 6, 'candidatesTokenCount': 47, 'totalTokenCount': 524, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 6}], 'thoughtsTokenCount': 471}, 'modelVersion': 'gemini-2.5-flash', 'responseId': 'R40EadXPCey9jMcP4qHyqAM'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt to enter your Gemini API key safely\n",
        "os.environ[\"GEMINI_API_KEY\"] = getpass(\"Paste GEMINI API key: \")\n",
        "\n",
        "# Example: using it in your request\n",
        "import requests\n",
        "\n",
        "API_KEY = os.environ[\"GEMINI_API_KEY\"]\n",
        "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={API_KEY}\" # Updated model name\n",
        "\n",
        "data = {\n",
        "    \"contents\": [\n",
        "        {\"parts\": [{\"text\": \"Write a short poem about sunrise\"}]}\n",
        "    ]\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2g5D2DZ4K5Q",
        "outputId": "7c287fba-97c0-4a06-e2fd-f3f15aaaa981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Raw response text ---\n",
            "Here's an Instagram caption about greed and money:\n",
            "\n",
            "Money. ðŸ’° It's a fundamental tool in our society, designed to facilitate exchange, provide security, and open doors to opportunity. We all need it, we all work for it. But somewhere along the line, for many, its purpose twists from a tool into a master. What begins as a desire for comfort can subtly morph into an insatiable hunger â€“ greed.\n",
            "\n",
            "Greed isn't simply about wanting more; it's about always wanting more, regardless of what you already possess or who might be deprived in the process. It's the relentless pursuit of accumulation, often at the expense of integrity, genuine relationships, and even peace of mind. The golden handcuffs might look luxurious, but they can bind you tighter than any physical chain, trapping you in a cycle of endless acquisition.\n",
            "\n",
            "When money becomes the sole metric of success, or the object of our ultimate desire, values shift. Compassion can be replaced by ruthless competition, generosity by hoarding, and genuine human connection by transactional relationships. We see its stark consequences in headlines, in corporate boardrooms, and sometimes, if we're honest, a whisper of it in our own hearts.\n",
            "\n",
            "It's a powerful reminder to pause and reflect: What is your relationship with money? Are you using it to build, to share, to uplift others and yourself? Or are you allowing its shadow to obscure what truly matters â€“ your character, your connections, and your contribution to the world? True wealth extends far beyond the bank account balance. Let's remember its purpose, and not let its powerful allure corrupt our souls. ðŸ™\n",
            "\n",
            "#GreedAndMoney #FinancialWisdom #WealthMindset #PurposeOverProfit #EthicalLiving #SelfReflection #TrueWealth #BeyondMoney #ValuesMatter #MoneyTalks\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Minimal Gemini test (single-language)\n",
        "from google import genai\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "# Quick test - simple English prompt\n",
        "resp = client.models.generate_content(\n",
        "    model=\"models/gemini-2.5-flash\",   # Changed model to gemini-2.5-flash\n",
        "    contents=\"Write a short (200-300 word) Instagram caption about greed and money.\"\n",
        ")\n",
        "\n",
        "print(\"--- Raw response text ---\")\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xbkTFGkO5xg1",
        "outputId": "7507cb61-748a-445d-d130-b03512dcdd50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- raw output ----\n",
            "```json\n",
            "{\n",
            "  \"en\": \"The relentless pursuit of money, unchecked by purpose, can easily morph into greed â€“ an insatiable hunger that distorts our values and blinds us to true richness. In a world that often measures success by bank accounts and possessions, it's tempting to believe that 'more' will finally bring happiness or peace. Yet, the trap of endless accumulation often leaves us feeling emptier.\\n\\nTrue wealth isn't solely quantified in dollars and cents. It's found in the warmth of genuine connections, the joy of shared experiences, the peace of mind from integrity, and the satisfaction of contributing to something larger than oneself. Money is a valuable tool, a resource that facilitates comfort and opportunity. However, when it becomes the master, dictating every choice and consuming\n",
            "\n",
            "=== Parsed data ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'en': \"The relentless pursuit of money, unchecked by purpose, can easily morph into greed â€“ an insatiable hunger that distorts our values and blinds us to true richness. In a world that often measures success by bank accounts and possessions, it's tempting to believe that 'more' will finally bring happiness or peace. Yet, the trap of endless accumulation often leaves us feeling emptier.\\n\\nTrue wealth isn't solely quantified in dollars and cents. It's found in the warmth of genuine connections, the joy of shared experiences, the peace of mind from integrity, and the satisfaction of contributing to something larger than oneself. Money is a valuable tool, a resource that facilitates comfort and opportunity. However, when it becomes the master, dictating every choice and consuming every thought, it strips away the very essence of what makes life meaningful.\\n\\nLet's pause and reflect. Are we building a life, or just accumulating assets? Are we genuinely happy, or constantly chasing the next financial milestone only to find the void remains? This isn't about rejecting financial stability or ambition, but a powerful reminder to guard our hearts against the seductive whisper of greed. Prioritize purpose over possessions, relationships over riches, and inner peace over endless profit. The richest lives are often those rich in spirit, compassion, and genuine human connection, not just cash. Cultivate an abundance mindset that recognizes wealth beyond currency, fostering gratitude for what you have and striving for impact, not just income. Your legacy isn't your net worth; it's the lives you've touched and the character you've built. Invest your energy and heart wisely.\",\n",
              " 'ar': 'Ø§Ù„Ù…Ø§Ù„ Ø£Ø¯Ø§Ø© Ù‚ÙˆÙŠØ©ØŒ ÙˆÙ„ÙƒÙ† Ø§Ù„Ø³Ø¹ÙŠ Ø§Ù„Ù…ÙØ±Ø· ÙˆØ±Ø§Ø¡Ù‡ Ù‚Ø¯ ÙŠØªØ­ÙˆÙ„ Ø¥Ù„Ù‰ Ø¬Ø´Ø¹ ÙŠØ¯Ù…Ø± Ø§Ù„Ù‚ÙŠÙ… ÙˆÙŠÙØ¹Ù…ÙŠ Ø¹Ù† Ø§Ù„Ø«Ø±Ø§Ø¡ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ. Ø§Ù„Ø³Ø¹Ø§Ø¯Ø© ÙˆØ§Ù„Ø³Ù„Ø§Ù… Ù„Ø§ ÙŠØ£ØªÙŠØ§Ù† Ø¨ÙƒÙ…ÙŠØ© Ø§Ù„Ù…Ù…ØªÙ„ÙƒØ§Øª. Ø§Ù„Ø«Ø±Ø§Ø¡ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ ÙŠÙƒÙ…Ù† ÙÙŠ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„ØµØ§Ø¯Ù‚Ø©ØŒ Ø§Ù„ØªØ¬Ø§Ø±Ø¨ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©ØŒ Ø§Ù„Ø³Ù„Ø§Ù… Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØŒ ÙˆØ§Ù„Ø¹Ø·Ø§Ø¡. Ù„Ø§ ØªØ¯Ø¹ Ø§Ù„Ù…Ø§Ù„ ÙŠØ³ÙŠØ·Ø± Ø¹Ù„Ù‰ Ø­ÙŠØ§ØªÙƒ ÙˆÙŠÙÙ†Ø³ÙŠÙƒ Ø¬ÙˆÙ‡Ø±Ù‡Ø§. Ø§Ø¬Ø¹Ù„ Ù‡Ø¯ÙÙƒ Ø£Ø³Ù…Ù‰ Ù…Ù† Ù…Ø¬Ø±Ø¯ Ø§Ù„Ø±Ø¨Ø­ØŒ ÙˆØ±ÙƒØ² Ø¹Ù„Ù‰ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø´Ø®ØµÙŠØ© ÙˆØªÙ„Ù…Ø³ Ø­ÙŠØ§Ø© Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†. Ø¥Ø±Ø«Ùƒ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù‡Ùˆ Ø£Ø«Ø±ÙƒØŒ Ù„Ø§ Ø«Ø±ÙˆØªÙƒ.',\n",
              " 'am': 'áŒˆáŠ•á‹˜á‰¥ áŠƒá‹­áˆˆáŠ› áˆ˜áˆ³áˆªá‹« áŠá‹á£ áŠáŒˆáˆ­ áŒáŠ• áŠ¨áˆáŠ­ á‹«áˆˆáˆ á‹¨áŒˆáŠ•á‹˜á‰¥ ááˆˆáŒ‹ á‹ˆá‹° áˆµáŒá‰¥áŒá‰¥áŠá‰µ á‰°áˆˆá‹áŒ¦ áŠ¥áˆ´á‰¶á‰»á‰½áŠ•áŠ• áˆŠá‹«áŒ á‹áŠ“ áŠ¥á‹áŠá‰°áŠ›á‹áŠ• á‹¨áˆ•á‹­á‹ˆá‰µ á‰¥áˆáŒ½áŒáŠ“ áˆŠá‹«áˆ³áŒ£áŠ• á‹­á‰½áˆ‹áˆá¢ á‹°áˆµá‰³áŠ“ áˆ°áˆ‹áˆ á‹¨áˆšáˆ˜áŒ¡á‰µ á‰ áŠ•á‰¥áˆ¨á‰µ á‰¥á‹›á‰µ áŠ á‹­á‹°áˆˆáˆá¢ áŠ¥á‹áŠá‰°áŠ› áˆ€á‰¥á‰µ á‰ á‰…áŠ• áŒáŠ•áŠ™áŠá‰¶á‰½á£ á‹á‰¥ áˆáˆá‹¶á‰½á£ á‹¨áŠ áŠ¥áˆáˆ® áˆ°áˆ‹áˆ áŠ¥áŠ“ á‰ áˆ˜áˆµáŒ á‰µ á‹áˆµáŒ¥ áŠá‹á¢ áŒˆáŠ•á‹˜á‰¥ áˆ…á‹­á‹ˆá‰µáˆ…áŠ• áŠ¥áŠ•á‹²á‰†áŒ£áŒ áˆ­á‰¥áˆ…áŠ“ á‹¨áˆ•á‹­á‹ˆá‰µáŠ• áˆáŠ•áŠá‰µ áŠ¥áŠ•á‹µá‰µáˆ¨áˆ³ áŠ á‰µáá‰€á‹µá¢ áŒá‰¥áˆ… áŠ¨á‰µáˆ­á á‰ áˆ‹á‹­ áŠ¨á á‹«áˆˆ á‹­áˆáŠ•á£ áˆµá‰¥á‹•áŠ“áˆ…áŠ• á‰ áˆ›áŒŽáˆá‰ á‰µáŠ“ á‹¨áˆŒáˆŽá‰½áŠ• áˆ•á‹­á‹ˆá‰µ á‰ áˆ˜áŠ•áŠ«á‰µ áˆ‹á‹­ áŠ á‰°áŠ©áˆ­á¢ áŠ¥á‹áŠá‰°áŠ› á‹áˆ­áˆµáˆ… á‹«áˆ³á‹°áˆ­áŠ¨á‹ á‰°áŒ½á‹•áŠ– áŠ¥áŠ•áŒ‚ á‹«áŠ«á‰ á‰µáŠ¨á‹ áˆ€á‰¥á‰µ áŠ á‹­á‹°áˆˆáˆá¢'}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell 5: Structured multilingual generation (request strict JSON)\n",
        "from google import genai\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "prompt = \"\"\"\n",
        "You are a professional multilingual social media writer.\n",
        "Produce a short motivational Instagram caption about greed and money.\n",
        "Return EXACTLY a JSON object (no extra text) with keys:\n",
        "{\n",
        "  \"en\": \"<English caption (200-300 words)>\",\n",
        "  \"ar\": \"<Arabic caption>\",\n",
        "  \"am\": \"<Amharic caption>\"\n",
        "}\n",
        "Make sure the values are plain strings and the entire response is valid JSON only.\n",
        "\"\"\"\n",
        "\n",
        "resp = client.models.generate_content(\n",
        "    model=\"models/gemini-2.5-flash\", # Changed model to models/gemini-2.5-flash\n",
        "    contents=prompt,\n",
        "    # optional: adjust token budget (max_output_tokens) if needed:\n",
        "    # max_output_tokens=300\n",
        ")\n",
        "\n",
        "raw = resp.text.strip()\n",
        "print(\"---- raw output ----\")\n",
        "print(raw[:800])\n",
        "\n",
        "# Try to extract JSON from the response robustly:\n",
        "json_text = None\n",
        "try:\n",
        "    json_text = raw\n",
        "    data = json.loads(json_text)\n",
        "except Exception:\n",
        "    # fallback: try to locate JSON block inside the text\n",
        "    m = re.search(r\"(\\{[\\s\\S]*\\})\", raw)\n",
        "    if m:\n",
        "        try:\n",
        "            data = json.loads(m.group(1))\n",
        "            json_text = m.group(1)\n",
        "        except Exception as e:\n",
        "            print(\"Failed to parse JSON fallback:\", e)\n",
        "            data = None\n",
        "    else:\n",
        "        print(\"No JSON block detected in model output.\")\n",
        "        data = None\n",
        "\n",
        "print(\"\\n=== Parsed data ===\")\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MUqt-vU7IJr",
        "outputId": "7bb751c5-9b36-4cd6-e06f-a3b5d5656518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: outputs/tts_en.mp3\n",
            "Saved: outputs/tts_ar.mp3\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Convert captions to speech\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "if not data:\n",
        "    raise SystemExit(\"No multilingual text available; re-run previous cell and ensure 'data' is parsed.\")\n",
        "\n",
        "# gTTS language codes: 'en', 'ar'. 'am' is not supported by gTTS.\n",
        "supported_languages = (\"en\", \"ar\")\n",
        "\n",
        "for code in supported_languages:\n",
        "    text = data.get(code)\n",
        "    if not text:\n",
        "        print(f\"No text for {code}, skipping.\")\n",
        "        continue\n",
        "    fname = f\"outputs/tts_{code}.mp3\"\n",
        "    try:\n",
        "        tts = gTTS(text, lang=code)\n",
        "        tts.save(fname)\n",
        "        print(\"Saved:\", fname)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error generating speech for {code}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd7de905",
        "outputId": "c95752d8-2234-4edc-8f4d-9bac696f7176"
      },
      "source": [
        "# Install required packages (should be done in Cell 1, but included here for clarity if running this cell independently)\n",
        "# !pip install -q moviepy==1.0.3 requests==2.32.4 deep-translator==1.11.4 gTTS==2.5.0\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, TextClip, CompositeVideoClip, concatenate_audioclips # Import concatenate_audioclips\n",
        "from moviepy.video.fx.all import fadein, fadeout # Import fade effects correctly\n",
        "from deep_translator import GoogleTranslator\n",
        "import moviepy.config as mp_config # Import moviepy.config\n",
        "\n",
        "# --- Configuration ---\n",
        "# Define directories and constants before they are used\n",
        "IMAGE_DOWNLOAD_DIR = \"downloaded_images\"\n",
        "IMAGE_COUNT = 5  # Increase image count for a longer video\n",
        "VIDEO_DURATION_PER_IMAGE = 8  # Increase duration per image for a longer video\n",
        "FADE_DURATION = 1.5 # Duration of fade transitions in seconds\n",
        "\n",
        "# Replace with your actual Unsplash Access Key or use Colab Secrets\n",
        "UNSPLASH_ACCESS_KEY = \"HCyqtDQ_2UhK7pY3zZ8ap9bFcUi8aC1Y2PSJ7fVtADk\"\n",
        "if UNSPLASH_ACCESS_KEY == \"YOUR_UNSPLASH_ACCESS_KEY\":\n",
        "    print(\"WARNING: Replace 'YOUR_UNSPLASH_ACCESS_KEY' with your actual Unsplash API key or set it as an environment variable.\")\n",
        "    print(\"You can set it in Colab Secrets (ðŸ”‘ icon on the left) and access with os.environ.get('UNSPLASH_ACCESS_KEY')\")\n",
        "\n",
        "# Set the path to the ImageMagick binary if MoviePy can't find it\n",
        "# Common paths in Colab might be '/usr/bin/convert' or similar.\n",
        "# We'll try a common path. If this doesn't work, you might need to find the exact path.\n",
        "IMAGEMAGICK_PATH = '/usr/bin/convert'\n",
        "if os.path.exists(IMAGEMAGICK_PATH):\n",
        "    mp_config.change_settings({\"IMAGEMAGICK_BINARY\": IMAGEMAGICK_PATH})\n",
        "    print(f\"Set ImageMagick binary path to: {IMAGEMAGICK_PATH}\")\n",
        "else:\n",
        "    print(f\"Warning: ImageMagick binary not found at {IMAGEMAGICK_PATH}. Text overlay might fail.\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(IMAGE_DOWNLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(\"outputs\", exist_ok=True) # Ensure outputs directory exists\n",
        "\n",
        "# Ensure 'data' variable from Cell 5 is available and contains the English caption\n",
        "if 'data' not in globals() or not data or 'en' not in data:\n",
        "    raise SystemExit(\"Error: 'data' variable with English caption not found. Please run Cell 5.\")\n",
        "\n",
        "# --- Keyword Extraction (Simple) ---\n",
        "search_query = data['en']\n",
        "print(f\"Using caption as search query: {search_query}\")\n",
        "\n",
        "# --- Unsplash API Image Fetching ---\n",
        "def search_unsplash_images(query, access_key, count):\n",
        "    url = f\"https://api.unsplash.com/search/photos\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Client-ID {access_key}\"\n",
        "    }\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"per_page\": count,\n",
        "        \"orientation\": \"landscape\" # Get landscape images suitable for video\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "        results = response.json() # Parse the JSON response into a dictionary\n",
        "        return results.get(\"results\", []) # Now call .get() on the dictionary\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching images from Unsplash: {e}\")\n",
        "        return []\n",
        "\n",
        "# Fetch images\n",
        "image_results = search_unsplash_images(search_query, UNSPLASH_ACCESS_KEY, IMAGE_COUNT)\n",
        "downloaded_image_paths = []\n",
        "\n",
        "if image_results:\n",
        "    print(f\"Found {len(image_results)} images. Downloading...\")\n",
        "    for i, img_info in enumerate(image_results):\n",
        "        img_url = img_info.get(\"urls\", {}).get(\"regular\") # Use 'regular' size\n",
        "        if img_url:\n",
        "            try:\n",
        "                img_response = requests.get(img_url, stream=True)\n",
        "                img_response.raise_for_status()\n",
        "                file_path = os.path.join(IMAGE_DOWNLOAD_DIR, f\"image_{i+1}.jpg\")\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in img_response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                downloaded_image_paths.append(file_path)\n",
        "                print(f\"Downloaded: {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Error downloading image {img_url}: {e}\")\n",
        "        if len(downloaded_image_paths) >= IMAGE_COUNT: # Stop if we've downloaded enough\n",
        "             break\n",
        "else:\n",
        "    print(\"No images found or error fetching images from Unsplash.\")\n",
        "    # Fallback to a single sample image if no images are downloaded\n",
        "    if not downloaded_image_paths:\n",
        "        print(\"Using sample image as fallback.\")\n",
        "        # Ensure sample.jpg exists (from Cell 7's original logic - might need to re-download if runtime reset)\n",
        "        sample_img_path = \"assets/sample.jpg\"\n",
        "        if not os.path.exists(\"assets\"):\n",
        "            os.makedirs(\"assets\")\n",
        "        if not os.path.exists(sample_img_path):\n",
        "             print(f\"Downloading sample image to {sample_img_path}\")\n",
        "             !wget -q -O assets/sample.jpg \"https://images.unsplash.com/photo-1507525428034-b723cf961d3e?w=1200\"\n",
        "             if not os.path.exists(sample_img_path):\n",
        "                 print(f\"Error: Failed to download sample image.\")\n",
        "                 raise SystemExit(\"Fatal Error: Could not get any images.\")\n",
        "\n",
        "        downloaded_image_paths.extend([sample_img_path] * IMAGE_COUNT) # Use sample image multiple times\n",
        "        print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "\n",
        "\n",
        "# --- Video Creation with Multiple Images and Transitions ---\n",
        "if downloaded_image_paths:\n",
        "    print(\"Creating video with downloaded images and transitions...\")\n",
        "    image_clips = []\n",
        "    for img_path in downloaded_image_paths:\n",
        "        try:\n",
        "            clip = ImageClip(img_path).set_duration(VIDEO_DURATION_PER_IMAGE)\n",
        "            image_clips.append(clip)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not create ImageClip from {img_path}: {e}\")\n",
        "            # Continue with other images\n",
        "\n",
        "    # Filter out clips with duration 0 or None\n",
        "    valid_image_clips = [clip for clip in image_clips if clip.duration is not None and clip.duration > 0]\n",
        "\n",
        "    if not valid_image_clips:\n",
        "        print(\"Error: No valid image clips created after filtering.\")\n",
        "        # Consider a more graceful exit or alternative here\n",
        "        # For now, we'll exit the if block\n",
        "    else:\n",
        "        # Apply fade out to all clips except the last one\n",
        "        clips_with_fade_out = [clip.fx(fadeout, duration=FADE_DURATION) for clip in valid_image_clips[:-1]]\n",
        "        # Apply fade in to all clips except the first one\n",
        "        clips_with_fade_in = [clip.fx(fadein, duration=FADE_DURATION) for clip in valid_image_clips[1:]]\n",
        "\n",
        "        # Concatenate clips with transitions\n",
        "        # The fade out of one clip overlaps with the fade in of the next\n",
        "        # Need to handle the case where there's only one valid clip\n",
        "        if len(valid_image_clips) > 1:\n",
        "            # Correctly concatenate the clips with transitions\n",
        "            # The logic for building 'final_clips' was conceptual; MoviePy's concatenate_videoclips\n",
        "            # with method=\"compose\" automatically handles the overlaps when clips have fade effects applied.\n",
        "            # So we just need to concatenate the clips AFTER applying the fades.\n",
        "            # The fade effects modify the clips in place or return modified clips.\n",
        "            # Let's re-apply fades and concatenate the resulting clips.\n",
        "\n",
        "            # This approach simplifies the concatenation logic by applying fades and then composing.\n",
        "            # The durations need careful management for perfect overlaps.\n",
        "            # A simpler way is to apply fade out to all but last, fade in to all but first,\n",
        "            # and then use the base clips for concatenation with overlap duration.\n",
        "\n",
        "            # Simpler concatenation with transitions:\n",
        "            # MoviePy's documentation suggests this pattern for simple fade transitions:\n",
        "            # result = concatenate_videoclips(clips, method=\"compose\")\n",
        "            # If clips have fade effects applied, compose handles the timing.\n",
        "            # Let's try applying the fades directly to the valid_image_clips and then concatenating.\n",
        "\n",
        "            # This still seems to be the intended logic. The error might be in the concatenation itself.\n",
        "            # Let's ensure we are passing a list of clips with effects applied to concatenate_videoclips.\n",
        "\n",
        "            # Re-evaluating the concatenation logic:\n",
        "            # The issue is likely how 'final_clips' was conceptually built vs how concat_videoclips works.\n",
        "            # Let's explicitly build the list of clips to concatenate including transitions.\n",
        "\n",
        "            # Concatenate clips manually with overlaps for transitions:\n",
        "            clips_to_concat_with_transitions = []\n",
        "            for i in range(len(valid_image_clips)):\n",
        "                clip = valid_image_clips[i]\n",
        "                if i > 0:\n",
        "                    # Apply fade in to all except the first\n",
        "                    clip = clip.fx(fadein, duration=FADE_DURATION)\n",
        "                if i < len(valid_image_clips) - 1:\n",
        "                    # Apply fade out to all except the last\n",
        "                    clip = clip.fx(fadeout, duration=FADE_DURATION)\n",
        "                clips_to_concat_with_transitions.append(clip)\n",
        "\n",
        "\n",
        "            # Now concatenate the clips WITH transitions applied\n",
        "            final_video_clip = concatenate_videoclips(clips_to_concat_with_transitions, method=\"compose\") # Use compose\n",
        "\n",
        "\n",
        "        else:\n",
        "             final_video_clip = valid_image_clips[0] # Only one clip, no concatenation needed\n",
        "\n",
        "\n",
        "        # Add Audio (Ensure audio file from Cell 6 exists - using English audio)\n",
        "        audio_file = \"outputs/tts_en.mp3\"\n",
        "        if os.path.exists(audio_file):\n",
        "            audio_clip = AudioFileClip(audio_file)\n",
        "\n",
        "            # Loop audio if it's shorter than the video\n",
        "            if audio_clip.duration < final_video_clip.duration:\n",
        "                num_loops = int(final_video_clip.duration / audio_clip.duration) + 1\n",
        "                # Use concatenate_audioclips for audio looping\n",
        "                looped_audio = concatenate_audioclips([audio_clip] * num_loops)\n",
        "                audio_clip = looped_audio.subclip(0, final_video_clip.duration) # Trim to video duration\n",
        "\n",
        "            # Trim audio if it's longer than the video\n",
        "            elif audio_clip.duration > final_video_clip.duration:\n",
        "                 audio_clip = audio_clip.subclip(0, final_video_clip.duration)\n",
        "\n",
        "            video_with_audio = final_video_clip.set_audio(audio_clip)\n",
        "        else:\n",
        "            print(f\"Warning: Audio file not found at {audio_file}. Creating video without audio.\")\n",
        "            video_with_audio = final_video_clip\n",
        "\n",
        "\n",
        "        out_path = \"outputs/reel_creative.mp4\"\n",
        "        video_with_audio.write_videofile(\n",
        "            out_path,\n",
        "            codec=\"libx264\",\n",
        "            audio_codec=\"aac\",\n",
        "            fps=24, # Maintain consistent fps\n",
        "            # Add preset=\"fast\" or \"medium\" for faster encoding if needed\n",
        "            preset=\"medium\" # Use a medium preset for better quality/speed balance\n",
        "        )\n",
        "        print(\"Saved reel:\", out_path)\n",
        "\n",
        "else:\n",
        "    print(\"No images available to create video.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ImageMagick binary not found at /usr/bin/convert. Text overlay might fail.\n",
            "Using caption as search query: The relentless pursuit of money, unchecked by purpose, can easily morph into greed â€“ an insatiable hunger that distorts our values and blinds us to true richness. In a world that often measures success by bank accounts and possessions, it's tempting to believe that 'more' will finally bring happiness or peace. Yet, the trap of endless accumulation often leaves us feeling emptier.\n",
            "\n",
            "True wealth isn't solely quantified in dollars and cents. It's found in the warmth of genuine connections, the joy of shared experiences, the peace of mind from integrity, and the satisfaction of contributing to something larger than oneself. Money is a valuable tool, a resource that facilitates comfort and opportunity. However, when it becomes the master, dictating every choice and consuming every thought, it strips away the very essence of what makes life meaningful.\n",
            "\n",
            "Let's pause and reflect. Are we building a life, or just accumulating assets? Are we genuinely happy, or constantly chasing the next financial milestone only to find the void remains? This isn't about rejecting financial stability or ambition, but a powerful reminder to guard our hearts against the seductive whisper of greed. Prioritize purpose over possessions, relationships over riches, and inner peace over endless profit. The richest lives are often those rich in spirit, compassion, and genuine human connection, not just cash. Cultivate an abundance mindset that recognizes wealth beyond currency, fostering gratitude for what you have and striving for impact, not just income. Your legacy isn't your net worth; it's the lives you've touched and the character you've built. Invest your energy and heart wisely.\n",
            "Found 5 images. Downloading...\n",
            "Downloaded: downloaded_images/image_1.jpg\n",
            "Downloaded: downloaded_images/image_2.jpg\n",
            "Downloaded: downloaded_images/image_3.jpg\n",
            "Downloaded: downloaded_images/image_4.jpg\n",
            "Downloaded: downloaded_images/image_5.jpg\n",
            "Creating video with downloaded images and transitions...\n",
            "Moviepy - Building video outputs/reel_creative.mp4.\n",
            "MoviePy - Writing audio in reel_creativeTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video outputs/reel_creative.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready outputs/reel_creative.mp4\n",
            "Saved reel: outputs/reel_creative.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttw_YiBy7vyi",
        "outputId": "7cc73877-69c5-476d-fb32-795344234867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video outputs/reel_en.mp4.\n",
            "MoviePy - Writing audio in reel_enTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video outputs/reel_en.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready outputs/reel_en.mp4\n",
            "Saved reel: outputs/reel_en.mp4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 7: Create a short reel (image + audio)\n",
        "!mkdir -p assets\n",
        "!wget -q -O assets/sample.jpg \"https://images.unsplash.com/photo-1507525428034-b723cf961d3e?w=1200\"\n",
        "\n",
        "from moviepy.editor import ImageClip, AudioFileClip\n",
        "audio_file = \"outputs/tts_en.mp3\"\n",
        "img_file = \"assets/sample.jpg\"\n",
        "\n",
        "clip = ImageClip(img_file, duration=8).set_fps(24)\n",
        "audio = AudioFileClip(audio_file).subclip(0,8)\n",
        "video = clip.set_audio(audio)\n",
        "out_path = \"outputs/reel_en.mp4\"\n",
        "video.write_videofile(out_path, codec=\"libx264\", audio_codec=\"aac\", fps=24)\n",
        "print(\"Saved reel:\", out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iryaIltg8HMu",
        "outputId": "b804ab11-0f0b-4216-8570-4bf7abd3fb99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved outputs/draft_meta.json\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Save metadata and optionally mount Drive\n",
        "import json, time\n",
        "meta = {\n",
        "    \"generated\": data,\n",
        "    \"files\": {\n",
        "        \"tts_en\": \"outputs/tts_en.mp3\",\n",
        "        \"tts_ar\": \"outputs/tts_ar.mp3\",\n",
        "        \"video_en\": \"outputs/reel_en.mp4\"\n",
        "    },\n",
        "    \"created_at\": time.time()\n",
        "}\n",
        "\n",
        "with open(\"outputs/draft_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved outputs/draft_meta.json\")\n",
        "\n",
        "# To persist to Drive (uncomment if you want):\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r outputs /content/drive/MyDrive/AI_Content_MVP_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3pD3PJ8_B-k",
        "outputId": "86e90762-5f08-47ae-88c2-c9b98fb690a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r outputs /content/drive/MyDrive/AI_Content_MVP_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "031c5da1"
      },
      "source": [
        "## Develop web application plan\n",
        "\n",
        "### Subtask:\n",
        "Outline the steps required to build a web application, including user authentication with Google accounts and integrating the content generation functionality.\n",
        "\n",
        "**Reasoning**:\n",
        "Outline the steps to build a web application with Google Sign-In and content generation integration based on the instructions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# ðŸŒ Updated Backend Setup (No ngrok)\n",
        "# ==========================\n",
        "\n",
        "# 1ï¸âƒ£ Create backend directory\n",
        "!rm -rf backend\n",
        "!mkdir -p backend\n",
        "\n",
        "# 2ï¸âƒ£ Create a clean requirements.txt file for your Flask + Cloudflared backend\n",
        "with open(\"backend/requirements.txt\", \"w\") as f:\n",
        "    f.write(\"\"\"Flask\n",
        "google-auth\n",
        "requests\n",
        "google-generativeai\n",
        "gTTS\n",
        "moviepy\n",
        "cloudflared\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… backend/requirements.txt created successfully.\\n\")\n",
        "\n",
        "# 3ï¸âƒ£ Show the contents of requirements.txt\n",
        "!cat backend/requirements.txt\n",
        "\n",
        "# 4ï¸âƒ£ (Optional) Install dependencies now\n",
        "!pip install -r backend/requirements.txt -q\n",
        "\n",
        "print(\"\\nâœ… All required packages are installed successfully and ngrok has been removed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2Ksnq64QJNE",
        "outputId": "369e8792-69ba-476b-b55c-e698798f8597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… backend/requirements.txt created successfully.\n",
            "\n",
            "Flask\n",
            "google-auth\n",
            "requests\n",
            "google-generativeai\n",
            "gTTS\n",
            "moviepy\n",
            "cloudflared\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cloudflared (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "âœ… All required packages are installed successfully and ngrok has been removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b4c7584",
        "outputId": "1769fbae-f3f3-4ab5-c26d-1c3e44d6e998"
      },
      "source": [
        "# Install backend dependencies from requirements.txt\n",
        "!pip install -r backend/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 2)) (2.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 4)) (0.8.5)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 6)) (1.0.3)\n",
            "Requirement already satisfied: cloudflared in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 7)) (1.0.0.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (8.1.8)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth->-r backend/requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (2025.10.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.28.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.185.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai->-r backend/requirements.txt (line 4)) (1.71.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.71.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy->-r backend/requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: setuptools_scm in /usr/local/lib/python3.12/dist-packages (from cloudflared->-r backend/requirements.txt (line 7)) (9.2.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (4.2.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from setuptools_scm->cloudflared->-r backend/requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from setuptools_scm->cloudflared->-r backend/requirements.txt (line 7)) (75.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a8750f6"
      },
      "source": [
        "## Implement web application (frontend and backend)\n",
        "\n",
        "### Subtask:\n",
        "Develop the user interface and the server-side logic for the web application.\n",
        "\n",
        "**Reasoning**:\n",
        "Set up the basic Flask project structure and a simple React project structure for the frontend to begin implementing the web application as outlined in the plan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95435bc2",
        "outputId": "4aa676f6-3ee4-4e8c-efa6-00318bc68eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "libavutil      56. 70.100 / 56. 70.100\n",
            "libavcodec     58.134.100 / 58.134.100\n",
            "libavformat    58. 76.100 / 58. 76.100\n",
            "libavdevice    58. 13.100 / 58. 13.100\n",
            "libavfilter     7.110.100 /  7.110.100\n",
            "libswscale      5.  9.100 /  5.  9.100\n",
            "libswresample   3.  9.100 /  3.  9.100\n",
            "libpostproc    55.  9.100 / 55.  9.100\n"
          ]
        }
      ],
      "source": [
        "# Check FFmpeg version in Colab\n",
        "!ffmpeg -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69e1fbff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd20cbe-0420-4d3d-a445-228e9e0b154d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_from_response', '_get_value', '_iter', '_setattr_handler', 'checkpoints', 'construct', 'copy', 'default_checkpoint_id', 'description', 'dict', 'display_name', 'endpoints', 'from_orm', 'input_token_limit', 'json', 'labels', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'name', 'output_token_limit', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'supported_actions', 'to_json_dict', 'tuned_model_info', 'update_forward_refs', 'validate', 'version']\n"
          ]
        }
      ],
      "source": [
        "# Inspect a model object to see its attributes\n",
        "for m in client.models.list():\n",
        "  print(dir(m))\n",
        "  break # Print attributes for only one model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afb20986",
        "outputId": "35f6450a-34d0-414a-aca1-43ed2dac2c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: models/gemini-2.5-pro-preview-03-25\n",
            "Model: models/gemini-2.5-flash-preview-05-20\n",
            "Model: models/gemini-2.5-flash\n",
            "Model: models/gemini-2.5-flash-lite-preview-06-17\n",
            "Model: models/gemini-2.5-pro-preview-05-06\n",
            "Model: models/gemini-2.5-pro-preview-06-05\n",
            "Model: models/gemini-2.5-pro\n",
            "Model: models/gemini-2.0-flash-exp\n",
            "Model: models/gemini-2.0-flash\n",
            "Model: models/gemini-2.0-flash-001\n",
            "Model: models/gemini-2.0-flash-exp-image-generation\n",
            "Model: models/gemini-2.0-flash-lite-001\n",
            "Model: models/gemini-2.0-flash-lite\n",
            "Model: models/gemini-2.0-flash-preview-image-generation\n",
            "Model: models/gemini-2.0-flash-lite-preview-02-05\n",
            "Model: models/gemini-2.0-flash-lite-preview\n",
            "Model: models/gemini-2.0-pro-exp\n",
            "Model: models/gemini-2.0-pro-exp-02-05\n",
            "Model: models/gemini-exp-1206\n",
            "Model: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "Model: models/gemini-2.0-flash-thinking-exp\n",
            "Model: models/gemini-2.0-flash-thinking-exp-1219\n",
            "Model: models/gemini-2.5-flash-preview-tts\n",
            "Model: models/gemini-2.5-pro-preview-tts\n",
            "Model: models/learnlm-2.0-flash-experimental\n",
            "Model: models/gemma-3-1b-it\n",
            "Model: models/gemma-3-4b-it\n",
            "Model: models/gemma-3-12b-it\n",
            "Model: models/gemma-3-27b-it\n",
            "Model: models/gemma-3n-e4b-it\n",
            "Model: models/gemma-3n-e2b-it\n",
            "Model: models/gemini-flash-latest\n",
            "Model: models/gemini-flash-lite-latest\n",
            "Model: models/gemini-pro-latest\n",
            "Model: models/gemini-2.5-flash-lite\n",
            "Model: models/gemini-2.5-flash-image-preview\n",
            "Model: models/gemini-2.5-flash-image\n",
            "Model: models/gemini-2.5-flash-preview-09-2025\n",
            "Model: models/gemini-2.5-flash-lite-preview-09-2025\n",
            "Model: models/gemini-robotics-er-1.5-preview\n",
            "Model: models/gemini-2.5-computer-use-preview-10-2025\n"
          ]
        }
      ],
      "source": [
        "# List available models\n",
        "for m in client.models.list():\n",
        "    if 'generateContent' in m.supported_actions: # Trying supported_actions instead of supported_methods\n",
        "        print(f\"Model: {m.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ec6b44"
      },
      "source": [
        "# Task\n",
        "Modify the existing code to generate videos between 1 and 3 minutes long, incorporating different images and creative elements. Additionally, outline a plan to develop a web application with Google sign-in for users to create content with prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ea942b5"
      },
      "source": [
        "## Explore longer video creation\n",
        "\n",
        "### Subtask:\n",
        "Investigate methods for creating videos longer than a few seconds using MoviePy or other libraries, potentially involving multiple images or video clips.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfabadf9"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to explore MoviePy's capabilities for creating longer videos by combining images or video clips. The MoviePy documentation is the primary source for this information. I will outline the relevant functionalities and then propose a strategy based on my findings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3c43aff"
      },
      "source": [
        "# Download sample image if it doesn't exist\n",
        "import os\n",
        "if not os.path.exists(\"assets\"):\n",
        "    os.makedirs(\"assets\")\n",
        "sample_img_path = \"assets/sample.jpg\"\n",
        "if not os.path.exists(sample_img_path):\n",
        "    print(f\"Downloading sample image to {sample_img_path}\")\n",
        "    !wget -q -O assets/sample.jpg \"https://images.unsplash.com/photo-1507525428034-b723cf961d3e?w=1200\"\n",
        "    if not os.path.exists(sample_img_path):\n",
        "        print(f\"Error: Failed to download sample image.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82051710"
      },
      "source": [
        "## Setting up the Web Application Projects\n",
        "\n",
        "We've outlined the structure and core components for the Flask backend and React frontend in the previous planning steps. Now, let's set up the actual project directories and initial files outside of this Colab environment.\n",
        "\n",
        "**Backend (Flask):**\n",
        "\n",
        "1.  **Create a project directory:** Choose a name for your project (e.g., `ai-content-mvp`) and create a directory for it.\n",
        "2.  **Create the backend directory:** Inside the project directory, create a subdirectory named `backend`.\n",
        "3.  **Create `app.py`:** Inside the `backend` directory, create a file named `app.py`. This will be your main Flask application file. Copy the combined conceptual Flask code from our previous steps into this file.\n",
        "4.  **Create `requirements.txt`:** Inside the `backend` directory, create a file named `requirements.txt`. Add the necessary Python dependencies to this file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5a804da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ec353a-37a9-4752-cc45-d94bbdec7087"
      },
      "source": [
        "!npm install @react-oauth/google\n",
        "# or using yarn:\n",
        "# !yarn add @react-oauth/google"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K\n",
            "added 4 packages in 2s\n",
            "\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d81e650b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03735fc0-2980-49aa-8c4d-0190e8577a58"
      },
      "source": [
        "# Step 5: Set up a new React project for the frontend.\n",
        "# This is typically done using create-react-app or similar tools.\n",
        "# We can simulate this by outlining the necessary files as shown above.\n",
        "# To actually create the React project, you would run one of the following\n",
        "# commands in your terminal where you want the project to be created:\n",
        "\n",
        "# Using create-react-app (requires Node.js and npm/yarn installed):\n",
        "!npx create-react-app frontend\n",
        "# or using Vite (a faster alternative):\n",
        "# !npm create vite@latest frontend --template react\n",
        "\n",
        "# After creating the project, you would navigate into the 'frontend' directory\n",
        "# and install additional dependencies like the Google Sign-In library:\n",
        "# cd frontend\n",
        "# !npm install @react-oauth/google\n",
        "# or using yarn:\n",
        "# !yarn add @react-oauth/google\n",
        "\n",
        "print(\"Outlined steps and provided shell commands for setting up the React frontend project.\")\n",
        "print(\"Note: These commands will create a 'frontend' directory in your current working directory in the Colab environment.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "create-react-app@5.1.0\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m uid-number@0.0.6: This package is no longer supported.\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m fstream-ignore@1.0.5: This package is no longer supported.\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m rimraf@2.7.1: Rimraf versions prior to v4 are no longer supported\n",
            "\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.\n",
            "\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m glob@7.2.3: Glob versions prior to v9 are no longer supported\n",
            "\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m fstream@1.0.12: This package is no longer supported.\n",
            "\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m tar@2.2.2: This version of tar is no longer supported, and will not receive security updates. Please upgrade asap.\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K\u001b[33m\u001b[1mcreate-react-app is deprecated.\u001b[22m\u001b[39m\n",
            "\n",
            "You can find a list of up-to-date React frameworks on react.dev\n",
            "For more info see:\u001b[4mhttps://react.dev/link/cra\u001b[24m\n",
            "\n",
            "\u001b[90mThis error message will only be shown once per install.\u001b[39m\n",
            "The directory \u001b[32mfrontend\u001b[39m contains files that could conflict:\n",
            "\n",
            "  index.html\n",
            "  \u001b[34mnode_modules/\u001b[39m\n",
            "  package-lock.json\n",
            "  package.json\n",
            "  \u001b[34mpublic/\u001b[39m\n",
            "  \u001b[34msrc/\u001b[39m\n",
            "  tsconfig.json\n",
            "\n",
            "Either try using a new directory name, or remove the files listed above.\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0KOutlined steps and provided shell commands for setting up the React frontend project.\n",
            "Note: These commands will create a 'frontend' directory in your current working directory in the Colab environment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a2af29e"
      },
      "source": [
        "## Incorporate diverse images\n",
        "\n",
        "### Subtask:\n",
        "Explore ways to dynamically select or generate different images for the video based on the prompt or other criteria.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d79432ed"
      },
      "source": [
        "**Reasoning**:\n",
        "Explore image sourcing options and outline a strategy for integrating them into the workflow and handling multiple images for longer videos. This involves researching potential image sources and thinking about how to connect text content to image selection or generation. Since this subtask is primarily about research and outlining a strategy, a single code block with comments and print statements to explain the findings and plan is appropriate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deb9e4c6"
      },
      "source": [
        "## Enhance video creativity\n",
        "\n",
        "### Subtask:\n",
        "Look into adding transitions, text overlays, or other effects to the video using MoviePy or other video editing libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1801182"
      },
      "source": [
        "**Reasoning**:\n",
        "Research MoviePy capabilities for adding transitions and text overlays, and outline a plan for incorporating them into the video generation process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de835ba5"
      },
      "source": [
        "## Develop web application plan\n",
        "\n",
        "### Subtask:\n",
        "Outline the steps required to build a web application, including user authentication with Google accounts and integrating the content generation functionality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc047485"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the steps to build a web application with Google Sign-In and content generation integration based on the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40cc69dc"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the Google Sign-In flow on the frontend and create a corresponding backend endpoint to receive the token, fulfilling steps 3 and 4 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05324da7",
        "outputId": "a735e2d4-e16d-42f2-d275-fb769fcb6866"
      },
      "source": [
        "!pip install flask-cors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.12/dist-packages (6.0.1)\n",
            "Requirement already satisfied: flask>=0.9 in /usr/local/lib/python3.12/dist-packages (from flask-cors) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.12/dist-packages (from flask-cors) (3.1.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (8.1.8)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask>=0.9->flask-cors) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "383724d6",
        "outputId": "2a50e81b-c964-4628-b806-95f000708f8d"
      },
      "source": [
        "# Set the GOOGLE_CLIENT_ID environment variable\n",
        "# Replace \"YOUR_GOOGLE_CLIENT_ID\" with your actual Google Client ID\n",
        "%env GOOGLE_CLIENT_ID=\"1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\"\n",
        "\n",
        "# You can verify it's set by running:\n",
        "# import os\n",
        "# print(os.environ.get(\"GOOGLE_CLIENT_ID\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_CLIENT_ID=\"1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2e01725"
      },
      "source": [
        "**Reasoning**:\n",
        "Integrate the content generation logic (Gemini, gTTS, MoviePy) into the backend `generate-content` endpoint, fulfilling step 6 of the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5317fe56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1c1ac3-1416-4530-f204-584de8a99dbe"
      },
      "source": [
        "# Step 6: Integrate the content generation logic into the /api/generate-content endpoint.\n",
        "\n",
        "# Backend (backend/app.py - updated with content generation logic):\n",
        "# (This code block replaces the previous definition of the generate_content route\n",
        "# in the Flask app)\n",
        "\n",
        "# Ensure you have imported the necessary libraries at the top of your app.py:\n",
        "from flask import Flask, request, jsonify\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import os\n",
        "# Import flask_ngrok to run the app in Colab\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS # Import CORS\n",
        "\n",
        "# Import libraries for content generation\n",
        "from google import genai\n",
        "from gtts import gTTS\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, TextClip, CompositeVideoClip, concatenate_audioclips\n",
        "from moviepy.video.fx.all import fadein, fadeout\n",
        "import moviepy.config as mp_config\n",
        "import requests\n",
        "import json\n",
        "import re # For robust JSON parsing from model output\n",
        "\n",
        "# Initialize Flask app, CORS, and run_with_ngrok as in the previous cell.\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# Set GOOGLE_CLIENT_ID, GEMINI_API_KEY, UNSPLASH_ACCESS_KEY environment variables.\n",
        "# Initialize GenAI client (only if GEMINI_API_KEY is available).\n",
        "# Set ImageMagick path (if needed for TextClip).\n",
        "# ... (previous code for initialization and /api/google-signin route)\n",
        "\n",
        "# In a real app, use environment variables or a config file for the client ID\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\") # Make sure to set this env var\n",
        "if not GOOGLE_CLIENT_ID:\n",
        "    print(\"Warning: GOOGLE_CLIENT_ID environment variable is not set. Google Sign-In verification will fail.\")\n",
        "\n",
        "# Initialize GenAI client\n",
        "# Initialize GenAI client only if GEMINI_API_KEY is available\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\") # Make sure to set this env var\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing GenAI client: {e}\")\n",
        "        # In a real app, you might handle this differently, but for this example,\n",
        "        # we'll print and allow the app to run, but API calls will fail.\n",
        "        genai_client = None\n",
        "else:\n",
        "     print(\"Warning: GEMINI_API_KEY is not set. Content generation will fail.\")\n",
        "     genai_client = None\n",
        "\n",
        "\n",
        "# Set ImageMagick path (needed for TextClip, but potentially problematic as seen)\n",
        "# Note: Text overlay is still commented out due to previous issues,\n",
        "# but the ImageMagick path setting remains as part of the original integration attempt.\n",
        "IMAGEMAGICK_PATH = '/usr/bin/convert' # Or the path found in your environment\n",
        "if os.path.exists(IMAGEMAGICK_PATH):\n",
        "    mp_config.change_settings({\"IMAGEMAGICK_BINARY\": IMAGEMAGICK_PATH})\n",
        "    print(f\"Set ImageMagick binary path to: {IMAGEMAGICK_PATH}\")\n",
        "else:\n",
        "    print(f\"Warning: ImageMagick binary not found at {IMAGEMAGICK_PATH}. Text overlay might fail.\")\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return 'Flask backend is running!'\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Specify the CLIENT_ID of the app that accesses the backend:\n",
        "        # Use the GOOGLE_CLIENT_ID obtained from environment variables\n",
        "        if not GOOGLE_CLIENT_ID:\n",
        "             # This case should be caught by the warning at the top,\n",
        "             # but returning an error here provides a more direct response\n",
        "             # if the environment variable wasn't set.\n",
        "             return jsonify({\"error\": \"GOOGLE_CLIENT_ID is not set on the backend\"}), 500\n",
        "\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), GOOGLE_CLIENT_ID)\n",
        "\n",
        "        # ID token is valid. Get the user's Google Account ID from the decoded token.\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '') # Get name if available\n",
        "\n",
        "        # Here you would typically:\n",
        "        # 1. Check if the user exists in your database based on `userid` or `email`.\n",
        "        # 2. If user exists, load their session/data.\n",
        "        # 3. If user does not exist, create a new user record in the database.\n",
        "        # 4. Establish a server-side session for the user (e.g., using Flask sessions).\n",
        "\n",
        "        # For this step, we'll just return the verified user info as confirmation\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\n",
        "                \"id\": userid,\n",
        "                \"email\": email,\n",
        "                \"name\": name\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except ValueError:\n",
        "        # Invalid token\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        # Other errors during verification\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "# In a real app, you might add @login_required or similar decorator for authentication\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "\n",
        "    # In a real application, you would authenticate the user here based on session\n",
        "    # or a token sent with the prompt request after successful sign-in.\n",
        "\n",
        "    print(f\"Received prompt from frontend: {prompt}\") # Log the received prompt\n",
        "\n",
        "    # --- 1. Generate Multilingual Text (Gemini API) ---\n",
        "    if not genai_client:\n",
        "         return jsonify({\"error\": \"Gemini API client not initialized. GEMINI_API_KEY might be missing.\"}), 500\n",
        "\n",
        "    text_prompt = f\"\"\"\n",
        "    You are a professional multilingual social media writer.\n",
        "    Produce a short motivational Instagram caption about the user's prompt: \"{prompt}\"\n",
        "    Return EXACTLY a JSON object (no extra text) with keys:\n",
        "    {{\n",
        "      \"en\": \"<English caption (30-40 words)>\",\n",
        "      \"ar\": \"<Arabic caption>\",\n",
        "      \"am\": \"<Amharic caption>\"\n",
        "    }}\n",
        "    Make sure the values are plain strings and the entire response is valid JSON only.\n",
        "    \"\"\"\n",
        "\n",
        "    text_data = None # Initialize text_data to None\n",
        "    try:\n",
        "        # Use the GenAI client\n",
        "        text_resp = genai_client.models.generate_content(\n",
        "            model=\"models/gemini-2.5-flash\", # Use gemini-2.5-flash for faster response\n",
        "            contents=text_prompt,\n",
        "            # max_output_tokens=300 # Adjust as needed\n",
        "        )\n",
        "        raw_text = text_resp.text.strip()\n",
        "\n",
        "        # Robustly parse JSON from the model output\n",
        "        text_data = None\n",
        "        try:\n",
        "            text_data = json.loads(raw_text)\n",
        "        except Exception:\n",
        "            m = re.search(r\"(\\{[\\s\\S]*\\})\", raw_text)\n",
        "            if m:\n",
        "                try:\n",
        "                    text_data = json.loads(m.group(1))\n",
        "                except Exception:\n",
        "                    pass # JSON parsing failed even with fallback\n",
        "            if not text_data:\n",
        "                 print(\"Warning: Failed to parse JSON from model output.\")\n",
        "                 print(\"Raw model output:\", raw_text)\n",
        "                 return jsonify({\"error\": \"Failed to generate and parse text content\"}), 500\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating text content: {e}\")\n",
        "        return jsonify({\"error\": f\"Error generating text content: {e}\"}), 500\n",
        "\n",
        "    english_caption = text_data.get('en', '')\n",
        "    if not english_caption:\n",
        "         return jsonify({\"error\": \"Generated English caption is empty\"}), 500\n",
        "\n",
        "\n",
        "    # --- 2. Generate Audio (gTTS) ---\n",
        "    # Generate a unique filename for the audio to avoid conflicts in a web app\n",
        "    audio_filename = f\"tts_en_{os.urandom(4).hex()}.mp3\"\n",
        "    audio_file_path = os.path.join(\"outputs\", audio_filename) # Save English audio for video\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "    audio_clip = None # Initialize audio_clip to None\n",
        "    try:\n",
        "        tts = gTTS(english_caption, lang='en')\n",
        "        tts.save(audio_file_path)\n",
        "        print(\"Saved audio:\", audio_file_path)\n",
        "        audio_clip = AudioFileClip(audio_file_path) # Load audio clip\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating audio: {e}\")\n",
        "        print(\"Warning: Proceeding without audio.\")\n",
        "\n",
        "\n",
        "    # --- 3. Fetch Images (Unsplash API) ---\n",
        "    IMAGE_COUNT = 5  # Number of images for video\n",
        "    VIDEO_DURATION_PER_IMAGE = 8 # Duration per image segment\n",
        "    IMAGE_DOWNLOAD_DIR = \"downloaded_images\"\n",
        "    os.makedirs(IMAGE_DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "    downloaded_image_paths = []\n",
        "    if not UNSPLASH_ACCESS_KEY or UNSPLASH_ACCESS_KEY == \"YOUR_UNSPLASH_ACCESS_KEY\":\n",
        "        print(\"Warning: Unsplash Access Key is not set. Skipping image fetching.\")\n",
        "        # Fallback to sample image if key is not set\n",
        "        sample_img_path = \"assets/sample.jpg\" # Assume sample.jpg exists or handle download\n",
        "        if os.path.exists(sample_img_path):\n",
        "             downloaded_image_paths.extend([sample_img_path] * IMAGE_COUNT) # Use sample image multiple times\n",
        "             print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "        else:\n",
        "            print(f\"Error: Sample image not found at {sample_img_path}. Cannot create video without images.\")\n",
        "            return jsonify({\"error\": \"Unsplash key not set and sample image not found\"}), 500\n",
        "    else:\n",
        "        # Use a keyword from the generated text as search query (e.g., first few words or extracted keywords)\n",
        "        # For simplicity, use a broader query or part of the generated text.\n",
        "        img_search_query = \"motivational OR hope OR mental health\" # Example: Use broader keywords\n",
        "        # Alternatively, use a part of the generated caption:\n",
        "        # img_search_query = \" \".join(english_caption.split()[:5]) # First 5 words as query\n",
        "\n",
        "        # Search Unsplash - assuming search_unsplash_images function is defined elsewhere or add it here\n",
        "        def search_unsplash_images(query, access_key, count):\n",
        "            url = f\"https://api.unsplash.com/search/photos\"\n",
        "            headers = {\n",
        "                \"Authorization\": f\"Client-ID {access_key}\"\n",
        "            }\n",
        "            params = {\n",
        "                \"query\": query,\n",
        "                \"per_page\": count,\n",
        "                \"orientation\": \"landscape\" # Get landscape images suitable for video\n",
        "            }\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, params=params)\n",
        "                response.raise_for_status() # Raise an exception for bad status codes\n",
        "                results = response.json()\n",
        "                return results.get(\"results\", [])\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Error fetching images from Unsplash: {e}\")\n",
        "                return []\n",
        "\n",
        "        image_results = search_unsplash_images(img_search_query, UNSPLASH_ACCESS_KEY, IMAGE_COUNT)\n",
        "        if image_results:\n",
        "            print(f\"Found {len(image_results)} images. Downloading...\")\n",
        "            for i, img_info in enumerate(image_results):\n",
        "                img_url = img_info.get(\"urls\", {}).get(\"regular\") # Use 'regular' size\n",
        "                if img_url:\n",
        "                    try:\n",
        "                        img_response = requests.get(img_url, stream=True)\n",
        "                        img_response.raise_for_status()\n",
        "                        # Generate a unique filename for each image\n",
        "                        img_filename = f\"image_{i+1}_{os.urandom(4).hex()}.jpg\"\n",
        "                        file_path = os.path.join(IMAGE_DOWNLOAD_DIR, img_filename)\n",
        "                        with open(file_path, 'wb') as f:\n",
        "                            for chunk in img_response.iter_content(chunk_size=8192):\n",
        "                                f.write(chunk)\n",
        "                        downloaded_image_paths.append(file_path)\n",
        "                        print(f\"Downloaded: {file_path}\")\n",
        "                    except requests.exceptions.RequestException as e:\n",
        "                        print(f\"Error downloading image {img_url}: {e}\")\n",
        "                if len(downloaded_image_paths) >= IMAGE_COUNT: # Stop if we've downloaded enough\n",
        "                     break\n",
        "        else:\n",
        "            print(\"No images found from Unsplash.\")\n",
        "            # Fallback to sample image if Unsplash search fails\n",
        "            sample_img_path = \"assets/sample.jpg\"\n",
        "            if os.path.exists(sample_img_path):\n",
        "                 downloaded_image_paths.extend([sample_img_path] * IMAGE_COUNT)\n",
        "                 print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "            else:\n",
        "                print(f\"Error: Sample image not found at {sample_img_path}. Cannot create video without images.\")\n",
        "                return jsonify({\"error\": \"Unsplash search failed and sample image not found\"}), 500\n",
        "\n",
        "\n",
        "    # --- 4. Create Video (MoviePy) ---\n",
        "    if not downloaded_image_paths:\n",
        "         return jsonify({\"error\": \"No images available to create video\"}), 500\n",
        "\n",
        "    print(\"Creating video with downloaded images and transitions...\")\n",
        "    image_clips = [ImageClip(img_path).set_duration(VIDEO_DURATION_PER_IMAGE) for img_path in downloaded_image_paths]\n",
        "\n",
        "    # Apply fade out to all clips except the last one\n",
        "    FADE_DURATION = 1.5 # Make sure FADE_DURATION is defined or use a fixed value here\n",
        "    clips_with_fade_out = [clip.fx(fadeout, duration=FADE_DURATION) for clip in image_clips[:-1]]\n",
        "    # Apply fade in to all clips except the first one\n",
        "    clips_with_fade_in = [clip.fx(fadein, duration=FADE_DURATION) for clip in image_clips[1:]]\n",
        "\n",
        "    # Concatenate clips with transitions\n",
        "    # The fade out of one clip overlaps with the fade in of the next\n",
        "    # Need to handle the case where there's only one valid clip\n",
        "    if len(image_clips) > 1:\n",
        "        # Concatenate clips manually with overlaps for transitions:\n",
        "        clips_to_concat_with_transitions = []\n",
        "        for i in range(len(image_clips)):\n",
        "            clip = image_clips[i]\n",
        "            if i > 0:\n",
        "                # Apply fade in to all except the first\n",
        "                clip = clip.fx(fadein, duration=FADE_DURATION)\n",
        "            if i < len(image_clips) - 1:\n",
        "                # Apply fade out to all except the last\n",
        "                clip = clip.fx(fadeout, duration=FADE_DURATION)\n",
        "            clips_to_concat_with_transitions.append(clip)\n",
        "\n",
        "        final_video_clip = concatenate_videoclips(clips_to_concat_with_transitions, method=\"compose\") # Use compose\n",
        "\n",
        "\n",
        "    else:\n",
        "         final_video_clip = image_clips[0] # Only one clip, no concatenation needed\n",
        "\n",
        "\n",
        "    # Add Audio to Video\n",
        "    if audio_clip:\n",
        "        # Adjust audio duration to match the total video duration\n",
        "        if audio_clip.duration < final_video_clip.duration:\n",
        "            num_loops = int(final_video_clip.duration / audio_clip.duration) + 1\n",
        "            # Use concatenate_audioclips for audio looping\n",
        "            looped_audio = concatenate_audioclips([audio_clip] * num_loops)\n",
        "            audio_clip = looped_audio.subclip(0, final_video_clip.duration) # Trim to video duration\n",
        "\n",
        "        elif audio_clip.duration > final_video_clip.duration:\n",
        "             audio_clip = audio_clip.subclip(0, final_video_clip.duration)\n",
        "\n",
        "        video_final = final_video_clip.set_audio(audio_clip)\n",
        "    else:\n",
        "        video_final = final_video_clip # Video without audio\n",
        "\n",
        "\n",
        "    # Generate a unique filename for the output video\n",
        "    video_filename = f\"generated_reel_{os.urandom(4).hex()}.mp4\"\n",
        "    out_path = os.path.join(\"outputs\", video_filename) # Use a generic name for generated files\n",
        "    os.makedirs(\"outputs\", exist_ok=True) # Ensure outputs directory exists\n",
        "\n",
        "    try:\n",
        "        video_final.write_videofile(\n",
        "            out_path,\n",
        "            codec=\"libx264\",\n",
        "            audio_codec=\"aac\",\n",
        "            fps=24,\n",
        "            preset=\"medium\"\n",
        "        )\n",
        "        print(\"Saved generated reel:\", out_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing video file: {e}\")\n",
        "        return jsonify({\"error\": f\"Error creating video file: {e}\"}), 500\n",
        "\n",
        "\n",
        "    # --- 5. Store and Serve (Basic) ---\n",
        "    # In a real app, store file path and metadata in database,\n",
        "    # and provide a URL to access the file.\n",
        "    # For this example, we'll just return the path and other generated data.\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Content generated successfully\",\n",
        "        \"text_content\": text_data,\n",
        "        \"video_path\": out_path # Return the server path (for demonstration)\n",
        "    })\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This block is for running the Flask app directly (e.g., for local development).\n",
        "    # If using flask_ngrok in Colab, run_with_ngrok(app) starts the server,\n",
        "    # so the app.run() call here is typically not needed when using ngrok.\n",
        "    # For local development, uncomment the line below:\n",
        "    # app.run(debug=True)\n",
        "    pass # Keep this pass statement if the __name__ == '__main__' block is used but app.run() is commented out."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ImageMagick binary not found at /usr/bin/convert. Text overlay might fail.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import re\n",
        "from flask import Flask, request, jsonify\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "\n",
        "# Kill any existing Flask process\n",
        "!kill -9 $(lsof -t -i:5000) 2>/dev/null || echo \"No previous Flask process running.\"\n",
        "\n",
        "# Google Client ID\n",
        "os.environ[\"GOOGLE_CLIENT_ID\"] = \"1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\"\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "\n",
        "# Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return 'âœ… Flask backend is running via Cloudflare Tunnel!'\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "    try:\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), GOOGLE_CLIENT_ID)\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\"id\": idinfo['sub'], \"email\": idinfo['email'], \"name\": idinfo.get('name','')}\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 401\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "    print(f\"Received prompt: {prompt}\")\n",
        "    return jsonify({\"status\": \"success\", \"received_prompt\": prompt})\n",
        "\n",
        "# Function to run Flask\n",
        "def run_flask():\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Function to run Cloudflared and print public URL\n",
        "def run_cloudflared():\n",
        "    time.sleep(3)  # give Flask a moment\n",
        "    proc = subprocess.Popen(\n",
        "        [\"cloudflared\", \"tunnel\", \"--url\", \"http://localhost:5000\", \"--no-autoupdate\"],\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
        "        text=True\n",
        "    )\n",
        "    while True:\n",
        "        line = proc.stdout.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        print(line, end='')\n",
        "        if \"trycloudflare.com\" in line:\n",
        "            match = re.search(r\"https://[0-9a-z\\-]+\\.trycloudflare\\.com\", line)\n",
        "            if match:\n",
        "                print(\"\\nðŸŒ PUBLIC URL:\", match.group(0))\n",
        "                print(\"ðŸ”— You can now use this URL in your frontend or Postman tests.\\n\")\n",
        "\n",
        "# Start both Flask and Cloudflared in parallel\n",
        "threading.Thread(target=run_flask).start()\n",
        "threading.Thread(target=run_cloudflared).start()"
      ],
      "metadata": {
        "id": "nzGsqP3kfnfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ðŸ”¹ STEP 1 â€” Install dependencies\n",
        "# ================================\n",
        "!pip install flask google-auth cloudflared -q\n",
        "\n",
        "# ================================\n",
        "# ðŸ”¹ STEP 2 â€” Configure environment\n",
        "# ================================\n",
        "import os\n",
        "os.environ[\"GOOGLE_CLIENT_ID\"] = \"1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\"\n",
        "\n",
        "# ================================\n",
        "# ðŸ”¹ STEP 3 â€” Create Flask backend\n",
        "# ================================\n",
        "from flask import Flask, request, jsonify\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import threading\n",
        "import subprocess\n",
        "import re\n",
        "import time\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return 'âœ… Flask backend is running via Cloudflare Tunnel!'\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    if not GOOGLE_CLIENT_ID:\n",
        "        return jsonify({\"error\": \"GOOGLE_CLIENT_ID not set\"}), 500\n",
        "\n",
        "    try:\n",
        "        idinfo = id_token.verify_oauth2_token(\n",
        "            token, google_requests.Request(), GOOGLE_CLIENT_ID\n",
        "        )\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '')\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\"id\": userid, \"email\": email, \"name\": name}\n",
        "        })\n",
        "    except ValueError:\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "    print(f\"Received prompt: {prompt}\")\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Prompt received successfully\",\n",
        "        \"received_prompt\": prompt\n",
        "    })\n",
        "\n",
        "# ================================\n",
        "# ðŸ”¹ STEP 4 â€” Run Flask + Cloudflared\n",
        "# ================================\n",
        "def run_flask():\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "def start_cloudflared():\n",
        "    # Wait for Flask to start\n",
        "    time.sleep(3)\n",
        "    proc = subprocess.Popen(\n",
        "        [\"cloudflared\", \"tunnel\", \"--url\", \"http://localhost:5000\", \"--no-autoupdate\"],\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        "    )\n",
        "    for line in proc.stdout:\n",
        "        # Find the public URL in the output\n",
        "        if \"trycloudflare.com\" in line:\n",
        "            public_url = re.search(r\"https://[0-9a-z\\-]+\\.trycloudflare\\.com\", line).group(0)\n",
        "            print(\"\\nðŸŒ PUBLIC URL:\", public_url)\n",
        "            print(\"ðŸ”— You can now use this URL in your front-end or Postman tests.\\n\")\n",
        "        print(line, end=\"\")\n",
        "\n",
        "# Run both Flask and Cloudflared in parallel\n",
        "threading.Thread(target=run_flask).start()\n",
        "threading.Thread(target=start_cloudflared).start()"
      ],
      "metadata": {
        "id": "Rjxt-wpIMNd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a358186b"
      },
      "source": [
        "# This cell is for testing the generate-content endpoint locally in Colab.\n",
        "# It sends a POST request to the Flask app running in the previous cell.\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "# You need to get the public URL from the cloudflared output in the previous cell.\n",
        "# Replace the placeholder URL with the actual public URL.\n",
        "# If using flask_ngrok, the URL will be printed when the cell runs.\n",
        "# If using cloudflared directly (as in the combined cell with threading),\n",
        "# the URL will also be printed.\n",
        "\n",
        "# Find the public URL from the output of the cell running the Flask app\n",
        "# This might require manual copying or using a more advanced method to capture output\n",
        "# For now, replace this with the URL you see in the output after running the Flask cell.\n",
        "PUBLIC_URL = \"YOUR_PUBLIC_URL_HERE\" # <<< REPLACE WITH YOUR ACTUAL PUBLIC URL\n",
        "\n",
        "# Simple check to see if the URL is updated\n",
        "if PUBLIC_URL == \"YOUR_PUBLIC_URL_HERE\":\n",
        "    print(\"Please update PUBLIC_URL with the actual URL from the Flask/Cloudflared output.\")\n",
        "else:\n",
        "    prompt_data = {\n",
        "        \"prompt\": \"Write a short motivational message about overcoming challenges.\"\n",
        "    }\n",
        "\n",
        "    # Give the server a moment to start\n",
        "    time.sleep(5)\n",
        "\n",
        "    try:\n",
        "        # Send a POST request to the generate-content endpoint\n",
        "        response = requests.post(f\"{PUBLIC_URL}/api/generate-content\", json=prompt_data)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "\n",
        "        # Print the JSON response from the backend\n",
        "        print(\"\\n--- Backend Response ---\")\n",
        "        print(json.dumps(response.json(), indent=2))\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nError sending request to backend: {e}\")\n",
        "        print(\"Please ensure the Flask app is running and the PUBLIC_URL is correct.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -L 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdjhRG4ztREt",
        "outputId": "5e8d6159-5ae0-4654-9625-1c1befa8d343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: tree: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "253deffe",
        "outputId": "b6a3d46b-9ab5-48dd-8fa8-effd996a2a02"
      },
      "source": [
        "!apt-get install tree -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 0s (96.0 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 125083 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a60ebd98"
      },
      "source": [
        "## Run the Frontend Application\n",
        "\n",
        "Now that the frontend files are updated with the correct backend URL, you can run the development server to see the application in your browser.\n",
        "\n",
        "1. Ensure the Cloudflare Tunnel cell is still running to provide a public URL for the backend.\n",
        "2. Navigate to the `afro_content_ai/frontend` directory.\n",
        "3. Run `npm run dev` to start the Vite development server.\n",
        "\n",
        "This will typically provide a local URL (like `http://localhost:5173`) and potentially a network URL that you can open in your web browser to see the frontend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "739dcb1e",
        "outputId": "07d49c9e-6235-4b11-a42a-9e8275b9302d"
      },
      "source": [
        "# Navigate to the frontend directory and run the development server\n",
        "# Note: This command will block the Colab cell execution while the server is running.\n",
        "# You may need to open the provided URL in a new browser tab.\n",
        "!cd afro_content_ai/frontend && npm run dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> frontend@0.0.0 dev\n",
            "> vite\n",
            "\n",
            "\u001b[1G\u001b[0K\n",
            "\u001b[1;1H\u001b[0J\n",
            "  \u001b[32m\u001b[1mVITE\u001b[22m v7.1.12\u001b[39m  \u001b[2mready in \u001b[0m\u001b[1m516\u001b[22m\u001b[2m\u001b[0m ms\u001b[22m\n",
            "\n",
            "  \u001b[32mâžœ\u001b[39m  \u001b[1mLocal\u001b[22m:   \u001b[36mhttp://localhost:\u001b[1m5173\u001b[22m/\u001b[39m\n",
            "\u001b[2m  \u001b[32mâžœ\u001b[39m  \u001b[1mNetwork\u001b[22m\u001b[2m: use \u001b[22m\u001b[1m--host\u001b[22m\u001b[2m to expose\u001b[22m\n",
            "\u001b[2m\u001b[32m  âžœ\u001b[39m\u001b[22m\u001b[2m  press \u001b[22m\u001b[1mh + enter\u001b[22m\u001b[2m to show help\u001b[22m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install axios"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6o-7tIs4WZc",
        "outputId": "738b26ff-02f8-4237-d855-4e48fa635e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\n",
            "added 23 packages, and audited 28 packages in 2s\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K6 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yes | npx create-vite@latest frontend -- --template react\n",
        "!cd frontend && npm install && npm install axios"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RulbnXaWDhFw",
        "outputId": "8a4e09e7-396a-404f-c573-d254ee50fd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mexec\u001b[39m The following package was not found and will be installed: create-vite@8.0.2\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0K\u001b[90mâ”‚\u001b[39m\n",
            "\u001b[32mâ—‡\u001b[39m  Scaffolding project in /content/frontend...\n",
            "\u001b[90mâ”‚\u001b[39m\n",
            "\u001b[90mâ””\u001b[39m  Done. Now run:\n",
            "\n",
            "  cd frontend\n",
            "  npm install\n",
            "  npm run dev\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\n",
            "added 14 packages, and audited 15 packages in 12s\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K5 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\n",
            "added 24 packages, and audited 39 packages in 2s\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K11 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7848ec82",
        "outputId": "1e403e87-6945-4f68-a69a-cd0ec7e2ed63"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create the backend directory if it doesn't exist\n",
        "os.makedirs(\"backend\", exist_ok=True)\n",
        "\n",
        "# Define the content of backend/app.py\n",
        "# This content is based on the conceptual Flask app code we developed earlier (e.g., in cell 8dQ6H6B8OSuE)\n",
        "app_py_content = \"\"\"\n",
        "from flask import Flask, request, jsonify\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import os\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "# Run the app with ngrok in Colab\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# In a real app, use environment variables or a config file for the client ID\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\") # Make sure to set this env var\n",
        "if not GOOGLE_CLIENT_ID:\n",
        "    print(\"Warning: GOOGLE_CLIENT_ID environment variable is not set. Google Sign-In verification will fail.\")\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return 'Flask backend is running!'\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Specify the CLIENT_ID of the app that accesses the backend:\n",
        "        if not GOOGLE_CLIENT_ID:\n",
        "             return jsonify({\"error\": \"GOOGLE_CLIENT_ID is not set on the backend\"}), 500\n",
        "\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), GOOGLE_CLIENT_ID)\n",
        "\n",
        "        # ID token is valid. Get the user's Google Account ID from the decoded token.\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '') # Get name if available\n",
        "\n",
        "        # Here you would typically:\n",
        "        # 1. Check if the user exists in your database based on `userid` or `email`.\n",
        "        # 2. If user exists, load their session/data.\n",
        "        # 3. If user does not exist, create a new user record in the database.\n",
        "        # 4. Establish a server-side session for the user (e.g., using Flask sessions).\n",
        "\n",
        "        # For this step, we'll just return the verified user info as confirmation\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\n",
        "                \"id\": userid,\n",
        "                \"email\": email,\n",
        "                \"name\": name\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except ValueError:\n",
        "        # Invalid token\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        # Other errors during verification\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "\n",
        "    # Step 7: Implement the basic backend logic to process the received prompt\n",
        "    # (without integrating the content generation APIs yet),\n",
        "    # perhaps just echoing the prompt back to the frontend as a confirmation.\n",
        "\n",
        "    # In a real application, you would authenticate the user here based on session\n",
        "    # or a token sent with the prompt request after successful sign-in.\n",
        "\n",
        "    print(f\"Received prompt from frontend: {prompt}\") # Log the received prompt\n",
        "\n",
        "    # Echo the prompt back as a confirmation\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Prompt received successfully\",\n",
        "        \"received_prompt\": prompt\n",
        "    })\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # When using run_with_ngrok(app), app.run() is not needed.\n",
        "    # It is handled internally by flask_ngrok.\n",
        "    pass\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to backend/app.py\n",
        "with open(\"backend/app.py\", \"w\") as f:\n",
        "    f.write(app_py_content)\n",
        "\n",
        "print(\"Created backend/app.py\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created backend/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r backend/requirements.txt\n",
        "from backend.app import app\n",
        "# app.run(port=5000) # Remove this line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTw8ZT12Edd6",
        "outputId": "c2f59d4e-875e-4f91-f53f-75fb81a02085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 2)) (2.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 4)) (0.8.5)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 6)) (1.0.3)\n",
            "Requirement already satisfied: cloudflared in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 7)) (1.0.0.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (8.1.8)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth->-r backend/requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (2025.10.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.28.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.185.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai->-r backend/requirements.txt (line 4)) (1.71.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.71.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy->-r backend/requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: setuptools_scm in /usr/local/lib/python3.12/dist-packages (from cloudflared->-r backend/requirements.txt (line 7)) (9.2.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (4.2.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from setuptools_scm->cloudflared->-r backend/requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from setuptools_scm->cloudflared->-r backend/requirements.txt (line 7)) (75.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === AUTO-SAVE NOTEBOOK AS .ipynb AND .py ===\n",
        "import os\n",
        "\n",
        "# âœ… 1. Set your notebook name (no extension)\n",
        "notebook_name = \"AI_Content_Multilang_MVP\"\n",
        "\n",
        "# âœ… 2. Define paths\n",
        "ipynb_path = f\"/content/{notebook_name}.ipynb\"\n",
        "drive_folder = \"/content/drive/MyDrive/AI_Content_MVP/\"\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "# âœ… 3. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# âœ… 4. Save .ipynb (full notebook)\n",
        "!jupyter nbconvert --to notebook \"{ipynb_path}\" --output \"{drive_folder}{notebook_name}.ipynb\"\n",
        "\n",
        "# âœ… 5. Save .py (code-only version)\n",
        "!jupyter nbconvert --to script \"{ipynb_path}\" --output \"{drive_folder}{notebook_name}.py\"\n",
        "\n",
        "print(\"âœ… Successfully saved Afro Content AI project in both formats.\")\n",
        "print(f\"ðŸ“‚ Folder: {drive_folder}\")\n",
        "print(f\"ðŸ“˜ Notebook: {notebook_name}.ipynb\")\n",
        "print(f\"ðŸ Script: {notebook_name}.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA3bgOc2wQhv",
        "outputId": "1221b34a-0171-4039-c64c-26b9f06c9ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[NbConvertApp] WARNING | pattern '/content/AI_Content_Multilang_MVP.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n",
            "[NbConvertApp] WARNING | pattern '/content/AI_Content_Multilang_MVP.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n",
            "âœ… Successfully saved Afro Content AI project in both formats.\n",
            "ðŸ“‚ Folder: /content/drive/MyDrive/AI_Content_MVP/\n",
            "ðŸ“˜ Notebook: AI_Content_Multilang_MVP.ipynb\n",
            "ðŸ Script: AI_Content_Multilang_MVP.py\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ga0pQJhqqri89gZEpXjkVABixBy30NqM",
      "authorship_tag": "ABX9TyMnzle+lShk7iKhFpcTK0Hz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}