{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7nTfqhm6y3O9"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install required packages (run in a fresh Colab runtime)\n",
        "!pip install -q --upgrade pip\n",
        "# Upgrade google-genai to a version that includes genai.Client (version 2.0.0 or higher)\n",
        "!pip install -q --upgrade google-genai>=2.0.0 deep-translator==1.11.4 gTTS==2.5.0 moviepy==1.0.3 requests==2.32.4 flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3DdJJJ3mzPEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4404fca8-28fd-43a1-8e8d-031598c11804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: google-genai\n",
            "Version: 1.46.0\n",
            "Summary: GenAI Python SDK\n",
            "Home-page: https://github.com/googleapis/python-genai\n",
            "Author: \n",
            "Author-email: Google LLC <googleapis-packages@google.com>\n",
            "License-Expression: Apache-2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: anyio, google-auth, httpx, pydantic, requests, tenacity, typing-extensions, websockets\n",
            "Required-by: google-adk, google-cloud-aiplatform\n",
            "Name: deep-translator\n",
            "Version: 1.11.4\n",
            "Summary: A flexible free and unlimited python tool to translate between different languages in a simple way using multiple translators\n",
            "Home-page: https://github.com/nidhaloff/deep_translator\n",
            "Author: Nidhal Baccouri\n",
            "Author-email: nidhalbacc@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: beautifulsoup4, requests\n",
            "Required-by: \n",
            "Name: gTTS\n",
            "Version: 2.5.0\n",
            "Summary: gTTS (Google Text-to-Speech), a Python library and CLI tool to interface with Google Translate text-to-speech API\n",
            "Home-page: https://github.com/pndurette/gTTS\n",
            "Author: \n",
            "Author-email: Pierre Nicolas Durette <pndurette@gmail.com>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: click, requests\n",
            "Required-by: \n",
            "Name: moviepy\n",
            "Version: 1.0.3\n",
            "Summary: Video editing with Python\n",
            "Home-page: https://zulko.github.io/moviepy/\n",
            "Author: Zulko 2017\n",
            "Author-email: \n",
            "License: MIT License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: decorator, imageio, imageio-ffmpeg, numpy, proglog, requests, tqdm\n",
            "Required-by: \n",
            "Unknown option: -#\n",
            "usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...\n",
            "Try `python -h' for more information.\n",
            "Name: google-genai\n",
            "Version: 1.46.0\n",
            "Summary: GenAI Python SDK\n",
            "Home-page: https://github.com/googleapis/python-genai\n",
            "Author: \n",
            "Author-email: Google LLC <googleapis-packages@google.com>\n",
            "License-Expression: Apache-2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: anyio, google-auth, httpx, pydantic, requests, tenacity, typing-extensions, websockets\n",
            "Required-by: google-adk, google-cloud-aiplatform\n",
            "Name: deep-translator\n",
            "Version: 1.11.4\n",
            "Summary: A flexible free and unlimited python tool to translate between different languages in a simple way using multiple translators\n",
            "Home-page: https://github.com/nidhaloff/deep_translator\n",
            "Author: Nidhal Baccouri\n",
            "Author-email: nidhalbacc@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: beautifulsoup4, requests\n",
            "Required-by: \n",
            "Name: gTTS\n",
            "Version: 2.5.0\n",
            "Summary: gTTS (Google Text-to-Speech), a Python library and CLI tool to interface with Google Translate text-to-speech API\n",
            "Home-page: https://github.com/pndurette/gTTS\n",
            "Author: \n",
            "Author-email: Pierre Nicolas Durette <pndurette@gmail.com>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: click, requests\n",
            "Required-by: \n",
            "Name: moviepy\n",
            "Version: 1.0.3\n",
            "Summary: Video editing with Python\n",
            "Home-page: https://zulko.github.io/moviepy/\n",
            "Author: Zulko 2017\n",
            "Author-email: \n",
            "License: MIT License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: decorator, imageio, imageio-ffmpeg, numpy, proglog, requests, tqdm\n",
            "Required-by: \n",
            "Python 3.12.12\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Verify installation versions\n",
        "!pip show google-genai || true\n",
        "!pip show deep-translator || true\n",
        "!pip show gTTS || true\n",
        "!pip show moviepy || true\n",
        "!python -V# Cell 2: Verify installation versions\n",
        "!pip show google-genai || true\n",
        "!pip show deep-translator || true\n",
        "!pip show gTTS || true\n",
        "!pip show moviepy || true\n",
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y3Y0Gt1s3_en",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ee5137-47f6-411c-b0ca-7e142ca61c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste GEMINI API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "{'candidates': [{'content': {'parts': [{'text': \"The night's last whisper starts to fade,\\nA blush of pink, a golden braid.\\nThe sky awakes, a soft, slow gleam,\\nA world reborn, a hopeful dream.\\n\\nThe sun, a fiery, rising eye,\\nPaints silent beauty in the sky.\\nNew day arrives, with gentle grace,\\nAnd light now fills each empty space.\"}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0}], 'usageMetadata': {'promptTokenCount': 6, 'candidatesTokenCount': 79, 'totalTokenCount': 353, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 6}], 'thoughtsTokenCount': 268}, 'modelVersion': 'gemini-2.5-flash', 'responseId': 'jN35aO3WH-Otz7IPs9zyoQI'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt to enter your Gemini API key safely\n",
        "os.environ[\"GEMINI_API_KEY\"] = getpass(\"Paste GEMINI API key: \")\n",
        "\n",
        "# Example: using it in your request\n",
        "import requests\n",
        "\n",
        "API_KEY = os.environ[\"GEMINI_API_KEY\"]\n",
        "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={API_KEY}\" # Updated model name\n",
        "\n",
        "data = {\n",
        "    \"contents\": [\n",
        "        {\"parts\": [{\"text\": \"Write a short poem about sunrise\"}]}\n",
        "    ]\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O2g5D2DZ4K5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc37e48-fbc4-458a-e31e-406cb95d29d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Raw response text ---\n",
            "Here's an Instagram caption about greed and money:\n",
            "\n",
            "Money. ğŸ’° It's a fundamental part of our world, a tool that can provide comfort, security, and open doors to incredible opportunities. We chase it, we work hard for it, and often, we measure success by how much of it we accumulate. Thereâ€™s nothing inherently wrong with ambition or striving for financial stability; it can fund education, build businesses, and support the people we love.\n",
            "\n",
            "But thereâ€™s a delicate, often blurred line between healthy ambition and destructive greed. âš–ï¸ When the pursuit of wealth becomes an insatiable hunger, consuming all else, that's where the danger lies. Greed whispers promises of endless happiness and fulfillment, yet often delivers only emptiness. It pushes us to chase the next dollar, the next acquisition, constantly moving the goalposts so true contentment is always just out of reach. ğŸƒâ€â™€ï¸ğŸ’¨\n",
            "\n",
            "In its relentless grip, we often sacrifice what truly matters: our integrity, our relationships, our peace of mind. ğŸ’” Friendships fray, family bonds weaken, and our sense of self can erode as we prioritize profit over people, material gain over moral principles. The golden handcuffs might shine brightly, but they can trap us in a lonely prison of our own making, where the worth of a person is measured only by their net worth. â›“ï¸ğŸ’¸\n",
            "\n",
            "Let's pause and reflect. Is the endless chase truly worth the cost? Are we building a life of abundance, or merely accumulating a collection of things that fail to fill the void within? True richness isn't found in bank accounts alone, but in the connections we foster, the values we uphold, and the peace we cultivate. âœ¨ Choose wisely what you worship.\n",
            "\n",
            "#Greed #MoneyTalks #FinancialFreedom #WealthMindset #TrueWealth #LifeLessons #Priorities #Mindfulness #BeyondMoney #Reflection #EthicalLiving #ValuesOverValuables #InnerPeace\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Minimal Gemini test (single-language)\n",
        "from google import genai\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "# Quick test - simple English prompt\n",
        "resp = client.models.generate_content(\n",
        "    model=\"models/gemini-2.5-flash\",   # Changed model to gemini-2.5-flash\n",
        "    contents=\"Write a short (200-300 word) Instagram caption about greed and money.\"\n",
        ")\n",
        "\n",
        "print(\"--- Raw response text ---\")\n",
        "print(resp.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xbkTFGkO5xg1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bb2f22b-0a2c-4e52-e97d-2d54cdc39951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- raw output ----\n",
            "```json\n",
            "{\n",
            "  \"en\": \"In a world that often equates success with material accumulation, it's easy to fall prey to the seductive whisper of greed. Money, in itself, is a tool â€“ a means to an end, capable of facilitating good, empowering dreams, and providing security. Yet, when its pursuit becomes an insatiable hunger, when 'enough' is never truly enough, it transforms into a master, chaining us to an endless cycle of want. This relentless chase for more can blind us to the true riches of life: the warmth of genuine connections, the quiet satisfaction of meaningful work, the simple joy of shared laughter, or the profound peace found in contributing to something larger than ourselves. It can erode our values, compromise our integrity, and distance us from our own humanity. The trap of greed lie\n",
            "\n",
            "=== Parsed data ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'en': \"In a world that often equates success with material accumulation, it's easy to fall prey to the seductive whisper of greed. Money, in itself, is a tool â€“ a means to an end, capable of facilitating good, empowering dreams, and providing security. Yet, when its pursuit becomes an insatiable hunger, when 'enough' is never truly enough, it transforms into a master, chaining us to an endless cycle of want. This relentless chase for more can blind us to the true riches of life: the warmth of genuine connections, the quiet satisfaction of meaningful work, the simple joy of shared laughter, or the profound peace found in contributing to something larger than ourselves. It can erode our values, compromise our integrity, and distance us from our own humanity. The trap of greed lies not in possessing wealth, but in being possessed by it. Itâ€™s a hollow victory where the prize is never truly claimed, as the goal post perpetually shifts further away. Let us pause and reflect. What are we truly chasing? Is it just currency, or is it a sense of purpose, belonging, and well-being that money can only *support*, not *supply*? True abundance isn't measured by the size of our bank account, but by the richness of our character, the depth of our relationships, and the positive impact we make on the world. Let's reframe our relationship with money: see it as a resource to be managed wisely, a tool to build a life of meaning, not an idol to be worshipped at the expense of our soul. Seek not just to earn, but to learn; not just to get, but to give; not just to consume, but to create. For in giving, we receive; in creating, we find fulfillment; and in purpose, we discover an enduring wealth that no market fluctuation can diminish. Choose purpose over profit, integrity over acquisition, and connection over consumption. That's where true prosperity resides.\",\n",
              " 'ar': 'ÙÙŠ Ø¹Ø§Ù„Ù… ÙŠØ±Ø¨Ø· Ø§Ù„Ù†Ø¬Ø§Ø­ ØºØ§Ù„Ø¨Ù‹Ø§ Ø¨Ø§Ù„Ø«Ø±Ø§Ø¡ Ø§Ù„Ù…Ø§Ø¯ÙŠØŒ Ù…Ù† Ø§Ù„Ø³Ù‡Ù„ Ø§Ù„ÙˆÙ‚ÙˆØ¹ ÙØ±ÙŠØ³Ø© Ù„Ù‡Ù…Ø³ Ø§Ù„Ø·Ù…Ø¹ Ø§Ù„Ù…ØºØ±ÙŠ. Ø§Ù„Ù…Ø§Ù„ØŒ Ø¨Ø­Ø¯ Ø°Ø§ØªÙ‡ØŒ Ø£Ø¯Ø§Ø©Ø› ÙˆØ³ÙŠÙ„Ø© Ù„ØªØ­Ù‚ÙŠÙ‚ ØºØ§ÙŠØ§Øª Ø¹Ø¸ÙŠÙ…Ø©ØŒ ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø£Ø­Ù„Ø§Ù…ØŒ ÙˆØªÙˆÙÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù†. Ù„ÙƒÙ† Ø¹Ù†Ø¯Ù…Ø§ ÙŠØµØ¨Ø­ Ø§Ù„Ø³Ø¹ÙŠ ÙˆØ±Ø§Ø¡Ù‡ Ø¬ÙˆØ¹Ù‹Ø§ Ù„Ø§ ÙŠØ´Ø¨Ø¹ØŒ ÙˆÙŠØºØ¯Ùˆ \"Ø§Ù„ÙƒØ§ÙÙŠ\" Ù„Ø§ ÙŠÙƒÙÙŠ Ø£Ø¨Ø¯Ù‹Ø§ØŒ ÙØ¥Ù†Ù‡ ÙŠØªØ­ÙˆÙ„ Ø¥Ù„Ù‰ Ø³ÙŠØ¯ ÙŠØ³ØªØ¹Ø¨Ø¯Ù†Ø§ ÙÙŠ Ø­Ù„Ù‚Ø© Ù„Ø§ Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ù† Ø§Ù„Ø±ØºØ¨Ø§Øª. Ù‡Ø°Ø§ Ø§Ù„Ù…Ø·Ø§Ø±Ø¯Ø© Ø§Ù„ØªÙŠ Ù„Ø§ ØªØªÙˆÙ‚Ù Ù„Ù„Ù…Ø²ÙŠØ¯ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªØ¹Ù…ÙŠÙ†Ø§ Ø¹Ù† ÙƒÙ†ÙˆØ² Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©: Ø¯ÙØ¡ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„ØµØ§Ø¯Ù‚Ø©ØŒ Ø§Ù„Ø±Ø¶Ø§ Ø§Ù„Ù‡Ø§Ø¯Ø¦ Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„Ù‡Ø§Ø¯ÙØŒ Ù…ØªØ¹Ø© Ø§Ù„Ø¶Ø­Ùƒ Ø§Ù„Ù…Ø´ØªØ±ÙƒØŒ Ø£Ùˆ Ø§Ù„Ø³Ù„Ø§Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø§Ù„Ø°ÙŠ Ù†Ø¬Ø¯Ù‡ ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© ÙÙŠ Ø´ÙŠØ¡ Ø£ÙƒØ¨Ø± Ù…Ù†Ø§. ÙØ® Ø§Ù„Ø·Ù…Ø¹ Ù„Ø§ ÙŠÙƒÙ…Ù† ÙÙŠ Ø§Ù…ØªÙ„Ø§Ùƒ Ø§Ù„Ø«Ø±ÙˆØ©ØŒ Ø¨Ù„ ÙÙŠ Ø£Ù† ØªÙ…Ù„ÙƒÙ†Ø§ Ø§Ù„Ø«Ø±ÙˆØ©. Ø¯Ø¹ÙˆÙ†Ø§ Ù†ØªÙˆÙ‚Ù ÙˆÙ†ØªØ£Ù…Ù„: Ù…Ø§ Ø§Ù„Ø°ÙŠ Ù†Ø·Ø§Ø±Ø¯Ù‡ Ø­Ù‚Ù‹Ø§ØŸ Ù‡Ù„ Ù‡Ùˆ Ù…Ø¬Ø±Ø¯ Ù†Ù‚ÙˆØ¯ØŒ Ø£Ù… Ù‡Ùˆ Ø¥Ø­Ø³Ø§Ø³ Ø¨Ø§Ù„Ù‡Ø¯ÙØŒ Ø§Ù„Ø§Ù†ØªÙ…Ø§Ø¡ØŒ ÙˆØ§Ù„Ø±ÙØ§Ù‡ÙŠØ© Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ù„Ù„Ù…Ø§Ù„ Ø£Ù† *ÙŠØ¯Ø¹Ù…Ù‡Ø§* ÙÙ‚Ø·ØŒ Ù„Ø§ Ø£Ù† *ÙŠÙˆÙØ±Ù‡Ø§*ØŸ Ø§Ù„ÙˆÙØ±Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ø§ ØªÙÙ‚Ø§Ø³ Ø¨Ø­Ø¬Ù… Ø±ØµÙŠØ¯Ù†Ø§ Ø§Ù„Ø¨Ù†ÙƒÙŠØŒ Ø¨Ù„ Ø¨Ø«Ø±Ø§Ø¡ Ø´Ø®ØµÙŠØªÙ†Ø§ØŒ Ø¹Ù…Ù‚ Ø¹Ù„Ø§Ù‚Ø§ØªÙ†Ø§ØŒ ÙˆØ§Ù„Ø£Ø«Ø± Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠ Ø§Ù„Ø°ÙŠ Ù†ØªØ±ÙƒÙ‡ ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…. Ù„Ù†Ø¹ÙŠØ¯ ØµÙŠØ§ØºØ© Ø¹Ù„Ø§Ù‚ØªÙ†Ø§ Ø¨Ø§Ù„Ù…Ø§Ù„: Ø§Ù†Ø¸Ø± Ø¥Ù„ÙŠÙ‡ ÙƒØ£Ø¯Ø§Ø© Ù„Ø¨Ù†Ø§Ø¡ Ø­ÙŠØ§Ø© Ø°Ø§Øª Ù…Ø¹Ù†Ù‰ØŒ Ù„Ø§ ÙƒØµÙ†Ù… ÙŠÙØ¹Ø¨Ø¯ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø£Ø±ÙˆØ§Ø­Ù†Ø§. Ø§Ø®ØªØ± Ø§Ù„Ù‡Ø¯Ù ÙÙˆÙ‚ Ø§Ù„Ø±Ø¨Ø­ØŒ ÙˆØ§Ù„Ù†Ø²Ø§Ù‡Ø© ÙÙˆÙ‚ Ø§Ù„ØªÙ…Ù„ÙƒØŒ ÙˆØ§Ù„Ø§ØªØµØ§Ù„ ÙÙˆÙ‚ Ø§Ù„Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ. Ù‡Ù†Ø§Ùƒ ÙŠÙƒÙ…Ù† Ø§Ù„Ø§Ø²Ø¯Ù‡Ø§Ø± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ.',\n",
              " 'am': 'á‰¥á‹™á‹áŠ• áŒŠá‹œ áˆµáŠ¬á‰µáŠ• áŠ¨á‰áˆ³á‹Š á‰¥áˆáŒ½áŒáŠ“ áŒ‹áˆ­ á‰ áˆšá‹«á‹­ á‹“áˆˆáˆ á‹áˆµáŒ¥á£ á‹¨áˆµáŒá‰¥áŒá‰¥áŠá‰µáŠ• áŠ áˆ³áˆ³á‰½ áˆ¹áŠ­áˆ¹áŠ­á‰³ á‰ á‰€áˆ‹áˆ‰ áˆáŠ•á‹ˆá‹µá‰… áŠ¥áŠ•á‰½áˆ‹áˆˆáŠ•á¢ áŒˆáŠ•á‹˜á‰¥ á‰ áˆ«áˆ± áˆ˜áˆ³áˆªá‹« áŠá‹ â€” á‹“áˆ‹áˆ›áŠ• áˆˆáˆ›áˆ³áŠ«á‰µá£ áˆ…áˆáˆá‰½áŠ• áˆˆáˆ›áŒáˆá‰ á‰µ áŠ¥áŠ“ á‹°áˆ…áŠ•áŠá‰µáŠ• áˆˆáˆ›á‰…áˆ¨á‰¥ á‹¨áˆšá‹«áˆµá‰½áˆ áˆ˜áŠ•áŒˆá‹µá¢ áŠáŒˆáˆ­ áŒáŠ•á£ áŠ¥áˆ±áŠ• áˆ›áˆ³á‹°á‹µ á‹¨áˆ›á‹­áŒ áŒˆá‰¥ ááˆ‹áŒá‰µ áˆ²áˆ†áŠ•á£ â€˜á‰ á‰‚â€™ á‹¨áˆšáˆˆá‹ á‰ƒáˆ áˆáŒ½áˆ á‰ á‰‚ áˆ³á‹­áˆ†áŠ• áˆ²á‰€áˆ­á£ á‹¨ááˆ‹áŒá‰µ áˆ›á‰¥á‰‚á‹« á‰ áˆŒáˆˆá‹ áŠ­á‰ á‰¥ á‹áˆµáŒ¥ á‹¨áˆšá‹«áˆµáˆ¨áŠ• áŒŒá‰³ á‹­áˆ†áŠ“áˆá¢ á‹­áˆ… á‰°áŒ¨áˆ›áˆª áˆˆáˆ›áŒáŠ˜á‰µ á‹¨áˆ›á‹«á‰‹áˆ­áŒ¥ ááˆˆáŒ‹ á‹¨áŠ¥á‹áŠá‰°áŠ› áˆ…á‹­á‹ˆá‰µáŠ• áˆ€á‰¥á‰¶á‰½ áŠ¥áŠ•á‹³áŠ“á‹­ áˆŠá‹«á‹°áˆ­áŒˆáŠ• á‹­á‰½áˆ‹áˆá¡ á‹¨áŠ¥á‹áŠá‰°áŠ› áŒáŠ•áŠ™áŠá‰¶á‰½ áˆ™á‰€á‰µá£ á‰µáˆ­áŒ‰áˆ á‰£áˆˆá‹ áˆµáˆ« á‹¨á‰°áŒˆáŠ˜ áŒ¸áŒ¥ á‹«áˆˆ áŠ¥áˆ­áŠ«á‰³á£ á‹¨á‰°áŒ‹áˆ« áˆ³á‰… á‰€áˆ‹áˆ á‹°áˆµá‰³á£ á‹ˆá‹­áˆ áŠ¨áˆ«áˆ³á‰½áŠ• á‰ áˆ‹á‹­ áˆˆáˆ†áŠ áŠáŒˆáˆ­ áŠ áˆµá‰°á‹‹á…á‹– á‰ áˆ›á‹µáˆ¨áŒ á‹¨áˆšáŒˆáŠ áŒ¥áˆá‰… áˆ°áˆ‹áˆá¢ á‹¨áˆµáŒá‰¥áŒá‰¥áŠá‰µ á‹ˆáŒ¥áˆ˜á‹µ á‹«áˆˆá‹ áˆ€á‰¥á‰µáŠ• á‰ áˆ˜á‹«á‹ áˆ‹á‹­ áˆ³á‹­áˆ†áŠ•á£ á‰ áˆ€á‰¥á‰µ á‰°á‹­á‹˜á‹ á‰ áˆ˜áŠ–áˆ«á‰¸á‹ áŠá‹á¢ áŠ¥áŠ•áŒá‹²áˆ… áˆˆáŠ áá‰³ áŠ¥áŠ•á‰áˆ áŠ¥áŠ“ áŠ¥áŠ“áˆµá‰¥á¢ á‰ á‰µáŠ­áŠ­áˆ áˆáŠ• áŠ¥á‹«áˆ³á‹°á‹µáŠ• áŠá‹? áŒˆáŠ•á‹˜á‰¥ á‰¥á‰» áŠá‹ á‹ˆá‹­áˆµ áŒˆáŠ•á‹˜á‰¥ *áˆŠá‹°áŒáˆá‹* á‰¥á‰» á‹¨áˆšá‰½áˆˆá‹á£ *áˆŠá‹«á‰€áˆ­á‰ á‹* á‹¨áˆ›á‹­á‰½áˆˆá‹ á‹¨á‹“áˆ‹áˆ›á£ á‹¨áˆ˜á‰°á‰£á‰ áˆ­ áŠ¥áŠ“ á‹¨á‹°áˆ…áŠ•áŠá‰µ áˆµáˆœá‰µ áŠá‹? áŠ¥á‹áŠá‰°áŠ› á‰¥áˆáŒ½áŒáŠ“ á‹¨áˆšáˆˆáŠ«á‹ á‰ á‰£áŠ•áŠ­ áˆ‚áˆ³á‰£á‰½áŠ• áˆ˜áŒ áŠ• áˆ³á‹­áˆ†áŠ•á£ á‰ á‰£áˆ…áˆªá‹«á‰½áŠ• á‰¥áˆáŒ½áŒáŠ“á£ á‰ áŒáŠ•áŠ™áŠá‰³á‰½áŠ• áŒ¥áˆá‰€á‰µ áŠ¥áŠ“ á‰ á‹“áˆˆáˆ áˆ‹á‹­ á‰ áˆáŠ“á‹°áˆ­áŒˆá‹ áŠ á‹áŠ•á‰³á‹Š á‰°á…á‹•áŠ– áŠá‹á¢ áŠ¨áŒˆáŠ•á‹˜á‰¥ áŒ‹áˆ­ á‹«áˆˆáŠ•áŠ• áŒáŠ•áŠ™áŠá‰µ áŠ¥áŠ•á‹°áŒˆáŠ“ áŠ¥áŠ•áŒáˆˆáŒ½á¡ á‹¨á‰µáˆ­áŒ‰áˆ áˆ…á‹­á‹ˆá‰µáŠ• áˆˆáˆ˜áŒˆáŠ•á‰£á‰µ á‹¨áˆšá‹«áŒˆáˆˆáŒáˆ áˆ˜áˆ³áˆªá‹« áŠ á‹µáˆ­áŒˆáŠ• áŠ¥áŠ•á‹¨á‹á£ á‹¨áŠááˆ³á‰½áŠ•áŠ• á‹‹áŒ‹ áŠ¨ááˆˆáŠ• á‹¨áˆáŠ“áˆ˜áˆáŠ¨á‹ áŒ£á‹–á‰µ áˆ³á‹­áˆ†áŠ•á¢ áŠ¨á‰µáˆ­á á‹­áˆá‰… á‹“áˆ‹áˆ›áŠ•á£ áŠ¨áŒá‹¢ á‹­áˆá‰… á‰³áˆ›áŠáŠá‰µáŠ•á£ áŠ¥áŠ“ áŠ¨ááŒ†á‰³ á‹­áˆá‰… áŒáŠ•áŠ™áŠá‰µáŠ• áˆáˆ¨áŒ¥á¢ áŠ¥á‹áŠá‰°áŠ› á‰¥áˆáŒ½áŒáŠ“ á‹¨áˆšáŠ–áˆ¨á‹ áŠ¥á‹šá‹« áŠá‹á¢'}"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "0# Cell 5: Structured multilingual generation (request strict JSON)\n",
        "from google import genai\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "prompt = \"\"\"\n",
        "You are a professional multilingual social media writer.\n",
        "Produce a short motivational Instagram caption about greed and money.\n",
        "Return EXACTLY a JSON object (no extra text) with keys:\n",
        "{\n",
        "  \"en\": \"<English caption (200-300 words)>\",\n",
        "  \"ar\": \"<Arabic caption>\",\n",
        "  \"am\": \"<Amharic caption>\"\n",
        "}\n",
        "Make sure the values are plain strings and the entire response is valid JSON only.\n",
        "\"\"\"\n",
        "\n",
        "resp = client.models.generate_content(\n",
        "    model=\"models/gemini-2.5-flash\", # Changed model to models/gemini-2.5-flash\n",
        "    contents=prompt,\n",
        "    # optional: adjust token budget (max_output_tokens) if needed:\n",
        "    # max_output_tokens=300\n",
        ")\n",
        "\n",
        "raw = resp.text.strip()\n",
        "print(\"---- raw output ----\")\n",
        "print(raw[:800])\n",
        "\n",
        "# Try to extract JSON from the response robustly:\n",
        "json_text = None\n",
        "try:\n",
        "    json_text = raw\n",
        "    data = json.loads(json_text)\n",
        "except Exception:\n",
        "    # fallback: try to locate JSON block inside the text\n",
        "    m = re.search(r\"(\\{[\\s\\S]*\\})\", raw)\n",
        "    if m:\n",
        "        try:\n",
        "            data = json.loads(m.group(1))\n",
        "            json_text = m.group(1)\n",
        "        except Exception as e:\n",
        "            print(\"Failed to parse JSON fallback:\", e)\n",
        "            data = None\n",
        "    else:\n",
        "        print(\"No JSON block detected in model output.\")\n",
        "        data = None\n",
        "\n",
        "print(\"\\n=== Parsed data ===\")\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5MUqt-vU7IJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ee2e52-0924-4545-c455-aa898cc8c19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: outputs/tts_en.mp3\n",
            "Saved: outputs/tts_ar.mp3\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Convert captions to speech\n",
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "if not data:\n",
        "    raise SystemExit(\"No multilingual text available; re-run previous cell and ensure 'data' is parsed.\")\n",
        "\n",
        "# gTTS language codes: 'en', 'ar'. 'am' is not supported by gTTS.\n",
        "supported_languages = (\"en\", \"ar\")\n",
        "\n",
        "for code in supported_languages:\n",
        "    text = data.get(code)\n",
        "    if not text:\n",
        "        print(f\"No text for {code}, skipping.\")\n",
        "        continue\n",
        "    fname = f\"outputs/tts_{code}.mp3\"\n",
        "    try:\n",
        "        tts = gTTS(text, lang=code)\n",
        "        tts.save(fname)\n",
        "        print(\"Saved:\", fname)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error generating speech for {code}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd7de905",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d73ffc7-c3b5-4654-acab-81074e39291c"
      },
      "source": [
        "# Install required packages (should be done in Cell 1, but included here for clarity if running this cell independently)\n",
        "# !pip install -q moviepy==1.0.3 requests==2.32.4 deep-translator==1.11.4 gTTS==2.5.0\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, TextClip, CompositeVideoClip, concatenate_audioclips # Import concatenate_audioclips\n",
        "from moviepy.video.fx.all import fadein, fadeout # Import fade effects correctly\n",
        "from deep_translator import GoogleTranslator\n",
        "import moviepy.config as mp_config # Import moviepy.config\n",
        "\n",
        "# --- Configuration ---\n",
        "# Define directories and constants before they are used\n",
        "IMAGE_DOWNLOAD_DIR = \"downloaded_images\"\n",
        "IMAGE_COUNT = 5  # Increase image count for a longer video\n",
        "VIDEO_DURATION_PER_IMAGE = 8  # Increase duration per image for a longer video\n",
        "FADE_DURATION = 1.5 # Duration of fade transitions in seconds\n",
        "\n",
        "# Replace with your actual Unsplash Access Key or use Colab Secrets\n",
        "UNSPLASH_ACCESS_KEY = \"HCyqtDQ_2UhK7pY3zZ8ap9bFcUi8aC1Y2PSJ7fVtADk\"\n",
        "if UNSPLASH_ACCESS_KEY == \"YOUR_UNSPLASH_ACCESS_KEY\":\n",
        "    print(\"WARNING: Replace 'YOUR_UNSPLASH_ACCESS_KEY' with your actual Unsplash API key or set it as an environment variable.\")\n",
        "    print(\"You can set it in Colab Secrets (ğŸ”‘ icon on the left) and access with os.environ.get('UNSPLASH_ACCESS_KEY')\")\n",
        "\n",
        "# Set the path to the ImageMagick binary if MoviePy can't find it\n",
        "# Common paths in Colab might be '/usr/bin/convert' or similar.\n",
        "# We'll try a common path. If this doesn't work, you might need to find the exact path.\n",
        "IMAGEMAGICK_PATH = '/usr/bin/convert'\n",
        "if os.path.exists(IMAGEMAGICK_PATH):\n",
        "    mp_config.change_settings({\"IMAGEMAGICK_BINARY\": IMAGEMAGICK_PATH})\n",
        "    print(f\"Set ImageMagick binary path to: {IMAGEMAGICK_PATH}\")\n",
        "else:\n",
        "    print(f\"Warning: ImageMagick binary not found at {IMAGEMAGICK_PATH}. Text overlay might fail.\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(IMAGE_DOWNLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(\"outputs\", exist_ok=True) # Ensure outputs directory exists\n",
        "\n",
        "# Ensure 'data' variable from Cell 5 is available and contains the English caption\n",
        "if 'data' not in globals() or not data or 'en' not in data:\n",
        "    raise SystemExit(\"Error: 'data' variable with English caption not found. Please run Cell 5.\")\n",
        "\n",
        "# --- Keyword Extraction (Simple) ---\n",
        "search_query = data['en']\n",
        "print(f\"Using caption as search query: {search_query}\")\n",
        "\n",
        "# --- Unsplash API Image Fetching ---\n",
        "def search_unsplash_images(query, access_key, count):\n",
        "    url = f\"https://api.unsplash.com/search/photos\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Client-ID {access_key}\"\n",
        "    }\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"per_page\": count,\n",
        "        \"orientation\": \"landscape\" # Get landscape images suitable for video\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "        results = response.json() # Parse the JSON response into a dictionary\n",
        "        return results.get(\"results\", []) # Now call .get() on the dictionary\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching images from Unsplash: {e}\")\n",
        "        return []\n",
        "\n",
        "# Fetch images\n",
        "image_results = search_unsplash_images(search_query, UNSPLASH_ACCESS_KEY, IMAGE_COUNT)\n",
        "downloaded_image_paths = []\n",
        "\n",
        "if image_results:\n",
        "    print(f\"Found {len(image_results)} images. Downloading...\")\n",
        "    for i, img_info in enumerate(image_results):\n",
        "        img_url = img_info.get(\"urls\", {}).get(\"regular\") # Use 'regular' size\n",
        "        if img_url:\n",
        "            try:\n",
        "                img_response = requests.get(img_url, stream=True)\n",
        "                img_response.raise_for_status()\n",
        "                file_path = os.path.join(IMAGE_DOWNLOAD_DIR, f\"image_{i+1}.jpg\")\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in img_response.iter_content(chunk_size=8192):\n",
        "                        f.write(chunk)\n",
        "                downloaded_image_paths.append(file_path)\n",
        "                print(f\"Downloaded: {file_path}\")\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Error downloading image {img_url}: {e}\")\n",
        "        if len(downloaded_image_paths) >= IMAGE_COUNT: # Stop if we've downloaded enough\n",
        "             break\n",
        "else:\n",
        "    print(\"No images found or error fetching images from Unsplash.\")\n",
        "    # Fallback to a single sample image if no images are downloaded\n",
        "    if not downloaded_image_paths:\n",
        "        print(\"Using sample image as fallback.\")\n",
        "        # Ensure sample.jpg exists (from Cell 7's original logic - might need to re-download if runtime reset)\n",
        "        sample_img_path = \"assets/sample.jpg\"\n",
        "        if not os.path.exists(\"assets\"):\n",
        "            os.makedirs(\"assets\")\n",
        "        if not os.path.exists(sample_img_path):\n",
        "             print(f\"Downloading sample image to {sample_img_path}\")\n",
        "             !wget -q -O assets/sample.jpg \"https://images.unsplash.com/photo-1507525428034-b723cf961d3e?w=1200\"\n",
        "             if not os.path.exists(sample_img_path):\n",
        "                 print(f\"Error: Failed to download sample image.\")\n",
        "                 raise SystemExit(\"Fatal Error: Could not get any images.\")\n",
        "\n",
        "        downloaded_image_paths.extend([sample_img_path] * IMAGE_COUNT) # Use sample image multiple times\n",
        "        print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "\n",
        "\n",
        "# --- Video Creation with Multiple Images and Transitions ---\n",
        "if downloaded_image_paths:\n",
        "    print(\"Creating video with downloaded images and transitions...\")\n",
        "    image_clips = []\n",
        "    for img_path in downloaded_image_paths:\n",
        "        try:\n",
        "            clip = ImageClip(img_path).set_duration(VIDEO_DURATION_PER_IMAGE)\n",
        "            image_clips.append(clip)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not create ImageClip from {img_path}: {e}\")\n",
        "            # Continue with other images\n",
        "\n",
        "    # Filter out clips with duration 0 or None\n",
        "    valid_image_clips = [clip for clip in image_clips if clip.duration is not None and clip.duration > 0]\n",
        "\n",
        "    if not valid_image_clips:\n",
        "        print(\"Error: No valid image clips created after filtering.\")\n",
        "        # Consider a more graceful exit or alternative here\n",
        "        # For now, we'll exit the if block\n",
        "    else:\n",
        "        # Apply fade out to all clips except the last one\n",
        "        clips_with_fade_out = [clip.fx(fadeout, duration=FADE_DURATION) for clip in valid_image_clips[:-1]]\n",
        "        # Apply fade in to all clips except the first one\n",
        "        clips_with_fade_in = [clip.fx(fadein, duration=FADE_DURATION) for clip in valid_image_clips[1:]]\n",
        "\n",
        "        # Concatenate clips with transitions\n",
        "        # The fade out of one clip overlaps with the fade in of the next\n",
        "        # Need to handle the case where there's only one valid clip\n",
        "        if len(valid_image_clips) > 1:\n",
        "            # Correctly concatenate the clips with transitions\n",
        "            # The logic for building 'final_clips' was conceptual; MoviePy's concatenate_videoclips\n",
        "            # with method=\"compose\" automatically handles the overlaps when clips have fade effects applied.\n",
        "            # So we just need to concatenate the clips AFTER applying the fades.\n",
        "            # The fade effects modify the clips in place or return modified clips.\n",
        "            # Let's re-apply fades and concatenate the resulting clips.\n",
        "\n",
        "            # This approach simplifies the concatenation logic by applying fades and then composing.\n",
        "            # The durations need careful management for perfect overlaps.\n",
        "            # A simpler way is to apply fade out to all but last, fade in to all but first,\n",
        "            # and then use the base clips for concatenation with overlap duration.\n",
        "\n",
        "            # Simpler concatenation with transitions:\n",
        "            # MoviePy's documentation suggests this pattern for simple fade transitions:\n",
        "            # result = concatenate_videoclips(clips, method=\"compose\")\n",
        "            # If clips have fade effects applied, compose handles the timing.\n",
        "            # Let's try applying the fades directly to the valid_image_clips and then concatenating.\n",
        "\n",
        "            # This still seems to be the intended logic. The error might be in the concatenation itself.\n",
        "            # Let's ensure we are passing a list of clips with effects applied to concatenate_videoclips.\n",
        "\n",
        "            # Re-evaluating the concatenation logic:\n",
        "            # The issue is likely how 'final_clips' was conceptually built vs how concat_videoclips works.\n",
        "            # Let's explicitly build the list of clips to concatenate including transitions.\n",
        "\n",
        "            # Concatenate clips manually with overlaps for transitions:\n",
        "            clips_to_concat_with_transitions = []\n",
        "            for i in range(len(valid_image_clips)):\n",
        "                clip = valid_image_clips[i]\n",
        "                if i > 0:\n",
        "                    # Apply fade in to all except the first\n",
        "                    clip = clip.fx(fadein, duration=FADE_DURATION)\n",
        "                if i < len(valid_image_clips) - 1:\n",
        "                    # Apply fade out to all except the last\n",
        "                    clip = clip.fx(fadeout, duration=FADE_DURATION)\n",
        "                clips_to_concat_with_transitions.append(clip)\n",
        "\n",
        "\n",
        "            # Now concatenate the clips WITH transitions applied\n",
        "            final_video_clip = concatenate_videoclips(clips_to_concat_with_transitions, method=\"compose\") # Use compose\n",
        "\n",
        "\n",
        "        else:\n",
        "             final_video_clip = valid_image_clips[0] # Only one clip, no concatenation needed\n",
        "\n",
        "\n",
        "        # Add Audio (Ensure audio file from Cell 6 exists - using English audio)\n",
        "        audio_file = \"outputs/tts_en.mp3\"\n",
        "        if os.path.exists(audio_file):\n",
        "            audio_clip = AudioFileClip(audio_file)\n",
        "\n",
        "            # Loop audio if it's shorter than the video\n",
        "            if audio_clip.duration < final_video_clip.duration:\n",
        "                num_loops = int(final_video_clip.duration / audio_clip.duration) + 1\n",
        "                # Use concatenate_audioclips for audio looping\n",
        "                looped_audio = concatenate_audioclips([audio_clip] * num_loops)\n",
        "                audio_clip = looped_audio.subclip(0, final_video_clip.duration) # Trim to video duration\n",
        "\n",
        "            # Trim audio if it's longer than the video\n",
        "            elif audio_clip.duration > final_video_clip.duration:\n",
        "                 audio_clip = audio_clip.subclip(0, final_video_clip.duration)\n",
        "\n",
        "            video_with_audio = final_video_clip.set_audio(audio_clip)\n",
        "        else:\n",
        "            print(f\"Warning: Audio file not found at {audio_file}. Creating video without audio.\")\n",
        "            video_with_audio = final_video_clip\n",
        "\n",
        "\n",
        "        out_path = \"outputs/reel_creative.mp4\"\n",
        "        video_with_audio.write_videofile(\n",
        "            out_path,\n",
        "            codec=\"libx264\",\n",
        "            audio_codec=\"aac\",\n",
        "            fps=24, # Maintain consistent fps\n",
        "            # Add preset=\"fast\" or \"medium\" for faster encoding if needed\n",
        "            preset=\"medium\" # Use a medium preset for better quality/speed balance\n",
        "        )\n",
        "        print(\"Saved reel:\", out_path)\n",
        "\n",
        "else:\n",
        "    print(\"No images available to create video.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ImageMagick binary not found at /usr/bin/convert. Text overlay might fail.\n",
            "Using caption as search query: In a world that often equates success with material accumulation, it's easy to fall prey to the seductive whisper of greed. Money, in itself, is a tool â€“ a means to an end, capable of facilitating good, empowering dreams, and providing security. Yet, when its pursuit becomes an insatiable hunger, when 'enough' is never truly enough, it transforms into a master, chaining us to an endless cycle of want. This relentless chase for more can blind us to the true riches of life: the warmth of genuine connections, the quiet satisfaction of meaningful work, the simple joy of shared laughter, or the profound peace found in contributing to something larger than ourselves. It can erode our values, compromise our integrity, and distance us from our own humanity. The trap of greed lies not in possessing wealth, but in being possessed by it. Itâ€™s a hollow victory where the prize is never truly claimed, as the goal post perpetually shifts further away. Let us pause and reflect. What are we truly chasing? Is it just currency, or is it a sense of purpose, belonging, and well-being that money can only *support*, not *supply*? True abundance isn't measured by the size of our bank account, but by the richness of our character, the depth of our relationships, and the positive impact we make on the world. Let's reframe our relationship with money: see it as a resource to be managed wisely, a tool to build a life of meaning, not an idol to be worshipped at the expense of our soul. Seek not just to earn, but to learn; not just to get, but to give; not just to consume, but to create. For in giving, we receive; in creating, we find fulfillment; and in purpose, we discover an enduring wealth that no market fluctuation can diminish. Choose purpose over profit, integrity over acquisition, and connection over consumption. That's where true prosperity resides.\n",
            "Found 5 images. Downloading...\n",
            "Downloaded: downloaded_images/image_1.jpg\n",
            "Downloaded: downloaded_images/image_2.jpg\n",
            "Downloaded: downloaded_images/image_3.jpg\n",
            "Downloaded: downloaded_images/image_4.jpg\n",
            "Downloaded: downloaded_images/image_5.jpg\n",
            "Creating video with downloaded images and transitions...\n",
            "Moviepy - Building video outputs/reel_creative.mp4.\n",
            "MoviePy - Writing audio in reel_creativeTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video outputs/reel_creative.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready outputs/reel_creative.mp4\n",
            "Saved reel: outputs/reel_creative.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ttw_YiBy7vyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da8499d-c441-4cb4-9df5-779d092883ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video outputs/reel_en.mp4.\n",
            "MoviePy - Writing audio in reel_enTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video outputs/reel_en.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready outputs/reel_en.mp4\n",
            "Saved reel: outputs/reel_en.mp4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 7: Create a short reel (image + audio)\n",
        "!mkdir -p assets\n",
        "!wget -q -O assets/sample.jpg \"https://images.unsplash.com/photo-1507525428034-b723cf961d3e?w=1200\"\n",
        "\n",
        "from moviepy.editor import ImageClip, AudioFileClip\n",
        "audio_file = \"outputs/tts_en.mp3\"\n",
        "img_file = \"assets/sample.jpg\"\n",
        "\n",
        "clip = ImageClip(img_file, duration=8).set_fps(24)\n",
        "audio = AudioFileClip(audio_file).subclip(0,8)\n",
        "video = clip.set_audio(audio)\n",
        "out_path = \"outputs/reel_en.mp4\"\n",
        "video.write_videofile(out_path, codec=\"libx264\", audio_codec=\"aac\", fps=24)\n",
        "print(\"Saved reel:\", out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iryaIltg8HMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5475ad38-3006-4772-9ee0-95ba145f4bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved outputs/draft_meta.json\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Save metadata and optionally mount Drive\n",
        "import json, time\n",
        "meta = {\n",
        "    \"generated\": data,\n",
        "    \"files\": {\n",
        "        \"tts_en\": \"outputs/tts_en.mp3\",\n",
        "        \"tts_ar\": \"outputs/tts_ar.mp3\",\n",
        "        \"video_en\": \"outputs/reel_en.mp4\"\n",
        "    },\n",
        "    \"created_at\": time.time()\n",
        "}\n",
        "\n",
        "with open(\"outputs/draft_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved outputs/draft_meta.json\")\n",
        "\n",
        "# To persist to Drive (uncomment if you want):\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !cp -r outputs /content/drive/MyDrive/AI_Content_MVP_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s3pD3PJ8_B-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c98c1d-5b9b-4211-d366-07a8d7517a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r outputs /content/drive/MyDrive/AI_Content_MVP_outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "031c5da1"
      },
      "source": [
        "## Develop web application plan\n",
        "\n",
        "### Subtask:\n",
        "Outline the steps required to build a web application, including user authentication with Google accounts and integrating the content generation functionality.\n",
        "\n",
        "**Reasoning**:\n",
        "Outline the steps to build a web application with Google Sign-In and content generation integration based on the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1493453d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8977d9-3aeb-41b1-a6c2-1b521c2f3903"
      },
      "source": [
        "# Subtask: Outline the steps required to build a web application, including user authentication with Google accounts and integrating the content generation functionality.\n",
        "\n",
        "# 1. Identify core components:\n",
        "# - Frontend: User interface for interacting with the application (input prompts, viewing generated content).\n",
        "# - Backend: Handles user authentication, interacts with APIs (Gemini, gTTS), processes video creation (MoviePy), and manages data.\n",
        "# - Database: Stores user information, prompts, generated content metadata, and file paths.\n",
        "\n",
        "print(\"Identified core web application components: Frontend, Backend, Database.\")\n",
        "\n",
        "# 2. Outline the technology stack:\n",
        "# - Backend Framework: Python framework like Flask or Django. Flask is suitable for smaller applications, while Django is more robust for larger ones. Let's assume Flask for this outline.\n",
        "# - Frontend Framework: JavaScript framework like React, Vue.js, or Angular. React is a popular choice.\n",
        "# - Database: A relational database like PostgreSQL or MySQL, or a NoSQL database like MongoDB. PostgreSQL is a good general-purpose choice.\n",
        "\n",
        "print(\"Outlined technology stack: Flask (Backend), React (Frontend), PostgreSQL (Database).\")\n",
        "\n",
        "# 3. Detail steps for implementing Google Sign-In:\n",
        "# - Obtain Google API Credentials: Create a project in the Google Cloud Console, enable the Google Sign-In API, and obtain a Client ID and Secret.\n",
        "# - Frontend Integration: Use a Google Sign-In library for React (e.g., `react-google-login` or `@react-oauth/google`) to initiate the OAuth 2.0 flow. The frontend will send the authentication token to the backend.\n",
        "# - Backend Verification: On the backend (Flask), receive the authentication token from the frontend. Use a Google Identity Services client library for Python (e.g., `google-auth`) to verify the token's authenticity and retrieve user information (email, name, profile picture).\n",
        "# - User Management: Based on the verified user information, either log in an existing user or create a new user record in the database.\n",
        "\n",
        "print(\"Detailed Google Sign-In steps: Obtain credentials, frontend integration with a library, backend token verification, and user management in the database.\")\n",
        "\n",
        "# 4. Describe integration of content generation functionality into the backend:\n",
        "# - API Calls: The backend will receive prompts from the frontend. Use the `google-genai` library to call the Gemini API for text generation based on the user's prompt.\n",
        "# - Text-to-Speech: Use the `gTTS` library to convert the generated text into audio files.\n",
        "# - Video Creation: Use the `moviepy` library to create videos, incorporating sourced/generated images and the generated audio. This will involve the strategies outlined in previous subtasks (concatenating clips, adding text overlays, etc.).\n",
        "# - Error Handling: Implement error handling for API calls and video processing.\n",
        "\n",
        "print(\"Described backend integration of content generation: Gemini API for text, gTTS for audio, MoviePy for video creation, and error handling.\")\n",
        "\n",
        "# 5. Plan for storing and serving generated content:\n",
        "# - Storage: Store generated audio and video files on the server's file system or a cloud storage service (e.g., Google Cloud Storage, AWS S3). Store metadata (prompt, generation date, file paths) in the database.\n",
        "# - Serving: Provide endpoints in the backend to serve the generated video and audio files to the frontend for playback or download. This could involve direct file serving or generating signed URLs for cloud storage.\n",
        "\n",
        "print(\"Planned storage and serving of content: Store files on server/cloud storage, store metadata in database, provide backend endpoints for serving.\")\n",
        "\n",
        "# 6. Consider user interface requirements:\n",
        "# - Prompt Input: A text area or input field for users to enter their content prompts.\n",
        "# - Options: Potentially include options for language selection, video length preferences, or image style preferences.\n",
        "# - Loading Indicator: Provide visual feedback while content is being generated (which can take time).\n",
        "# - Content Display: An area to display the generated text, and a video player to play the generated video.\n",
        "# - Download Options: Buttons to download the generated audio and video files.\n",
        "\n",
        "print(\"Considered user interface requirements: Prompt input, options, loading indicator, content display, download options.\")\n",
        "\n",
        "# 7. Outline a basic architecture diagram/description:\n",
        "# - User (Frontend): Interacts with the web interface (React).\n",
        "# - Backend (Flask): Receives requests from the frontend.\n",
        "# - Google Authentication Service: Handles user sign-in flow initiated by the frontend and verified by the backend.\n",
        "# - Database (PostgreSQL): Stores user data and generated content metadata.\n",
        "# - Content Generation Components (Integrated in Backend):\n",
        "#     - Gemini API: Text generation.\n",
        "#     - gTTS: Text-to-speech.\n",
        "#     - MoviePy: Video creation.\n",
        "# - Storage (File System/Cloud Storage): Stores generated audio and video files.\n",
        "\n",
        "# Flow:\n",
        "# 1. User signs in via Google (Frontend -> Google Auth -> Frontend -> Backend).\n",
        "# 2. Backend verifies user and manages session.\n",
        "# 3. User submits prompt (Frontend -> Backend).\n",
        "# 4. Backend calls Gemini API for text (Backend -> Gemini API).\n",
        "# 5. Backend calls gTTS for audio (Backend -> gTTS).\n",
        "# 6. Backend uses MoviePy and potentially image sourcing to create video (Backend -> MoviePy/Image Source).\n",
        "# 7. Backend stores generated files and metadata (Backend -> Storage, Backend -> Database).\n",
        "# 8. Backend sends metadata/file paths to Frontend (Backend -> Frontend).\n",
        "# 9. Frontend displays content and provides download links (Frontend -> User).\n",
        "\n",
        "print(\"Outlined basic architecture and flow.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified core web application components: Frontend, Backend, Database.\n",
            "Outlined technology stack: Flask (Backend), React (Frontend), PostgreSQL (Database).\n",
            "Detailed Google Sign-In steps: Obtain credentials, frontend integration with a library, backend token verification, and user management in the database.\n",
            "Described backend integration of content generation: Gemini API for text, gTTS for audio, MoviePy for video creation, and error handling.\n",
            "Planned storage and serving of content: Store files on server/cloud storage, store metadata in database, provide backend endpoints for serving.\n",
            "Considered user interface requirements: Prompt input, options, loading indicator, content display, download options.\n",
            "Outlined basic architecture and flow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09862494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe98955d-3146-4307-fbe0-082b0da91688"
      },
      "source": [
        "# Create the backend directory and a dummy requirements.txt for demonstration\n",
        "!mkdir -p backend\n",
        "!echo \"Flask\" > backend/requirements.txt\n",
        "!echo \"google-auth\" >> backend/requirements.txt\n",
        "!echo \"requests\" >> backend/requirements.txt\n",
        "!echo \"google-generativeai\" >> backend/requirements.txt\n",
        "!echo \"gTTS\" >> backend/requirements.txt\n",
        "!echo \"moviepy\" >> backend/requirements.txt\n",
        "!echo \"flask-ngrok\" >> backend/requirements.txt\n",
        "\n",
        "print(\"Created backend directory and dummy requirements.txt.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created backend directory and dummy requirements.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b4c7584",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6df22bf-67e6-4e6b-a8d5-6564293fc6a5"
      },
      "source": [
        "# Install backend dependencies from requirements.txt\n",
        "!pip install -r backend/requirements.txt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 2)) (2.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 4)) (0.8.5)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 6)) (1.0.3)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.12/dist-packages (from -r backend/requirements.txt (line 7)) (0.0.25)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (8.1.8)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask->-r backend/requirements.txt (line 1)) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r backend/requirements.txt (line 2)) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth->-r backend/requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->-r backend/requirements.txt (line 3)) (2025.10.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.26.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.185.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai->-r backend/requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai->-r backend/requirements.txt (line 4)) (1.71.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r backend/requirements.txt (line 4)) (1.71.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy->-r backend/requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy->-r backend/requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (4.2.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai->-r backend/requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai->-r backend/requirements.txt (line 4)) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a8750f6"
      },
      "source": [
        "## Implement web application (frontend and backend)\n",
        "\n",
        "### Subtask:\n",
        "Develop the user interface and the server-side logic for the web application.\n",
        "\n",
        "**Reasoning**:\n",
        "Set up the basic Flask project structure and a simple React project structure for the frontend to begin implementing the web application as outlined in the plan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57856a3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07cbee20-6b16-49d1-ab6a-7e67f71170b6"
      },
      "source": [
        "# Step 1: Set up a new Flask project for the backend.\n",
        "# This requires creating a directory structure and basic Flask app files.\n",
        "# We cannot execute shell commands to create directories and files directly here,\n",
        "# but we can outline the required structure and minimal content for a Flask app.\n",
        "\n",
        "# Project Directory: ai-content-mvp\n",
        "#   - backend/\n",
        "#     - app.py       # Main Flask application file\n",
        "#     - requirements.txt # List of Python dependencies (Flask, google-auth, etc.)\n",
        "#   - frontend/\n",
        "#     - public/      # Static assets\n",
        "#     - src/         # React source files\n",
        "#       - App.js     # Main App component\n",
        "#       - index.js   # Entry point\n",
        "#     - package.json # Node.js package file (React dependencies)\n",
        "\n",
        "# Minimal backend/app.py content:\n",
        "# from flask import Flask\n",
        "# app = Flask(__name__)\n",
        "# @app.route('/')\n",
        "# def index():\n",
        "#     return 'Flask backend is running!'\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(debug=True)\n",
        "\n",
        "# Minimal backend/requirements.txt content:\n",
        "# Flask\n",
        "# google-auth # For Google token verification later\n",
        "\n",
        "# Minimal frontend/src/index.js content:\n",
        "# import React from 'react';\n",
        "# import ReactDOM from 'react-dom/client';\n",
        "# import App from './App';\n",
        "# const root = ReactDOM.createRoot(document.getElementById('root'));\n",
        "# root.render(<React.StrictMode><App /></React.StrictMode>);\n",
        "\n",
        "# Minimal frontend/src/App.js content:\n",
        "# import React from 'react';\n",
        "# function App() {Äµ\n",
        "#   return (\n",
        "#     <div>\n",
        "#       <h1>AI Content MVP Frontend</h1>\n",
        "#     </div>\n",
        "#   );\n",
        "# }\n",
        "# export default App;\n",
        "\n",
        "# Minimal frontend/package.json content (requires manual creation or using create-react-app):\n",
        "# {\n",
        "#   \"name\": \"frontend\",\n",
        "#   \"version\": \"0.1.0\",\n",
        "#   \"private\": true,\n",
        "#   \"dependencies\": {\n",
        "#     \"react\": \"^18.2.0\",\n",
        "#     \"react-dom\": \"^18.2.0\",\n",
        "#     \"react-scripts\": \"5.0.1\"\n",
        "#   },\n",
        "#   \"scripts\": {\n",
        "#     \"start\": \"react-scripts start\",\n",
        "#     \"build\": \"react-scripts build\"\n",
        "#   },\n",
        "#   \"browserslist\": {\n",
        "#     \"production\": [\">0.2%\", \"not dead\", \"not op_mini all\"],\n",
        "#     \"development\": [\"last 1 chrome version\", \"last 1 firefox version\", \"last 1 safari version\"]\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# Step 2: Create the basic structure for the frontend using React.\n",
        "# This is typically done using create-react-app or similar tools.\n",
        "# We can simulate this by outlining the necessary files as shown above.\n",
        "\n",
        "print(\"Outlined Flask backend and React frontend project structures.\")\n",
        "print(\"To proceed, manually create these files and directories, then install dependencies:\")\n",
        "print(\"Backend: pip install -r backend/requirements.txt\")\n",
        "print(\"Frontend: cd frontend && npm install\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outlined Flask backend and React frontend project structures.\n",
            "To proceed, manually create these files and directories, then install dependencies:\n",
            "Backend: pip install -r backend/requirements.txt\n",
            "Frontend: cd frontend && npm install\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcf78db8"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the Google Sign-In flow on the frontend and create a corresponding backend endpoint to receive the token, fulfilling steps 3 and 4 of the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "700832a6"
      },
      "source": [
        "# Step 3: Implement the Google Sign-In flow on the frontend.\n",
        "# This requires adding a Google Sign-In button to the React frontend and handling the response.\n",
        "# We'll use the `@react-oauth/google` library as it's a modern approach.\n",
        "\n",
        "# Frontend (frontend/src/App.js - conceptual addition):\n",
        "# import React from 'react';\n",
        "# import { GoogleOAuthProvider, GoogleLogin } from '@react-oauth/google';\n",
        "\n",
        "# function App() {\n",
        "#   const handleSuccess = (credentialResponse) => {\n",
        "#     console.log(credentialResponse);\n",
        "#     # Send the credentialResponse.credential (ID token) to the backend\n",
        "#     fetch('/api/google-signin', {\n",
        "#       method: 'POST',\n",
        "#       headers: {\n",
        "#         'Content-Type': 'application/json',\n",
        "#       },\n",
        "#       body: JSON.stringify({ id_token: credentialResponse.credential }),\n",
        "#     })\n",
        "#     .then(response => response.json())\n",
        "#     .then(data => console.log('Backend response:', data))\n",
        "#     .catch((error) => console.error('Error sending token to backend:', error));\n",
        "#   };\n",
        "\n",
        "#   const handleError = () => {\n",
        "#     console.log('Login Failed');\n",
        "#   };\n",
        "\n",
        "#   return (\n",
        "#     <GoogleOAuthProvider clientId=\"YOUR_GOOGLE_CLIENT_ID\"> # Replace with your Client ID\n",
        "#       <div>\n",
        "#         <h1>AI Content MVP Frontend</h1>\n",
        "#         <GoogleLogin\n",
        "#           onSuccess={handleSuccess}\n",
        "#           onError={handleError}\n",
        "#         />\n",
        "#       </div>\n",
        "#     </GoogleOAuthProvider>\n",
        "#   );\n",
        "# }\n",
        "\n",
        "# export default App;\n",
        "\n",
        "# Frontend (frontend/src/index.js - wrap with GoogleOAuthProvider):\n",
        "# import React from 'react';\n",
        "# import ReactDOM from 'react-dom/client';\n",
        "# import App from './App';\n",
        "# import { GoogleOAuthProvider } from '@react-oauth/google'; # Import here\n",
        "\n",
        "# const root = ReactDOM.createRoot(document.getElementById('root'));\n",
        "# root.render(\n",
        "#   <React.StrictMode>\n",
        "#     # Wrap App with GoogleOAuthProâ°0Â²vider\n",
        "#     <GoogleOAuthProvider clientId=\"YOUR_GOOGLE_CLIENT_ID\"> # Replace with your Client ID\n",
        "#       <App />\n",
        "#     </GoogleOAuthProvider>\n",
        "#   </React.StrictMode>\n",
        "# );\n",
        "\n",
        "\n",
        "# Step 4: Create a backend endpoint in Flask to receive and verify the Google authentication token.\n",
        "# This requires adding a new route to the Flask app.\n",
        "\n",
        "# Backend (backend/app.py - conceptual addition):\n",
        "from flask import Flask, request, jsonify\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import os\n",
        "\n",
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# In a real app, use environment variables or a config file for the client ID\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\") # Make sure to set this env var\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Specify the CLIENT_ID of the app that accesses the backend:\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), GOOGLE_CLIENT_ID)\n",
        "\n",
        "        # ID token is valid. Get the user's Google Account ID from the decoded token.\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '') # Get name if available\n",
        "\n",
        "        # Here you would typically:\n",
        "        # 1. Check if the user exists in your database based on `userid` or `email`.\n",
        "        # 2. If user exists, load their session/data.\n",
        "        # 3. If user does not exist, create a new user record in the database.\n",
        "        # 4. Establish a server-side session for the user (e.g., using Flask sessions).\n",
        "\n",
        "        # For this step, we'll just return the verified user info as confirmation\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\n",
        "                \"id\": userid,\n",
        "                \"email\": email,\n",
        "                \"name\": name\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except ValueError:\n",
        "        # Invalid token\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        # Other errors during verification\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "# Keep the index route or remove if not needed in the API\n",
        "# @app.route('/')\n",
        "# def index():\n",
        "#     return 'Flask backend is running!'\n",
        "\n",
        "# This block is for running the Flask app directly, often used for development.\n",
        "# In Colab with ngrok, you might not need this if run_with_ngrok handles it.\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(debug=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58674206"
      },
      "source": [
        "**Reasoning**:\n",
        "Design the user interface for prompt input on the frontend and create a backend endpoint to receive these prompts, fulfilling steps 5 and 6 of the instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ea22e2"
      },
      "source": [
        "**Reasoning**:\n",
        "Combine the Google Sign-In and prompt input backend endpoints into a single Flask application file, fulfilling steps 3 through 6 of the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d1336d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c0566a-25f8-401f-cba7-27abd3685b9f"
      },
      "source": [
        "# Backend (backend/app.py - combining endpoints)\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import os\n",
        "# Potentially import Flask-CORS if frontend is on a different domain/port\n",
        "# from flask_cors import CORS\n",
        "# from flask_ngrok import run_with_ngrok # If running in Colab with ngrok\n",
        "\n",
        "# Import libraries for content generation\n",
        "from google import genai\n",
        "from gtts import gTTS\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, TextClip, CompositeVideoClip, concatenate_audioclips\n",
        "from moviepy.video.fx.all import fadein, fadeout\n",
        "import moviepy.config as mp_config\n",
        "import requests\n",
        "import json\n",
        "import re # For robust JSON parsing from model output\n",
        "\n",
        "\n",
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "# CORS(app) # Enable CORS if needed\n",
        "\n",
        "# If running in Colab with ngrok, uncomment this line:\n",
        "# run_with_ngrok(app)\n",
        "\n",
        "# --- Configuration and API Key Setup (Backend) ---\n",
        "# It's best practice to load API keys from environment variables or a secure config file\n",
        "# in a real web application, not hardcoded.\n",
        "# For Colab demonstration, we used os.environ.get or direct assignment.\n",
        "# In a deployed app, use proper environment variable loading.\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "UNSPLASH_ACCESS_KEY = os.environ.get(\"UNSPLASH_ACCESS_KEY\") # Load Unsplash Key as well\n",
        "\n",
        "# Initialize GenAI client\n",
        "# Initialize GenAI client only if GEMINI_API_KEY is available\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing GenAI client: {e}\")\n",
        "        # In a real app, you might handle this differently, but for this example,\n",
        "        # we'll print and allow the app to run, but API calls will fail.\n",
        "        genai_client = None\n",
        "else:\n",
        "     print(\"Warning: GEMINI_API_KEY is not set. Content generation will fail.\")\n",
        "     genai_client = None\n",
        "\n",
        "\n",
        "# Set ImageMagick path (needed for TextClip, but potentially problematic as seen)\n",
        "# Note: Text overlay is still commented out due to previous issues,\n",
        "# but the ImageMagick path setting remains as part of the original integration attempt.\n",
        "IMAGEMAGICK_PATH = '/usr/bin/convert' # Or the path found in your environment\n",
        "if os.path.exists(IMAGEMAGICK_PATH):\n",
        "    mp_config.change_settings({\"IMAGEMAGICK_BINARY\": IMAGEMAGICK_PATH})\n",
        "    print(f\"Set ImageMagick binary path to: {IMAGEMAGICK_PATH}\")\n",
        "else:\n",
        "    print(f\"Warning: ImageMagick binary not found at {IMAGEMAGICK_PATH}. Text overlay might fail.\")\n",
        "\n",
        "\n",
        "# --- Google Sign-In Endpoint ---\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Specify the CLIENT_ID of the app that accesses the backend:\n",
        "        # In a real app, GOOGLE_CLIENT_ID should be set as an environment variable\n",
        "        google_client_id = os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "        if not google_client_id:\n",
        "            return jsonify({\"error\": \"GOOGLE_CLIENT_ID is not set on the backend\"}), 500\n",
        "\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), google_client_id)\n",
        "\n",
        "        # ID token is valid. Get the user's Google Account ID from the decoded token.\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '') # Get name if available\n",
        "\n",
        "        # Here you would typically:\n",
        "        # 1. Check if the user exists in your database based on `userid` or `email`.\n",
        "        # 2. If user exists, load their session/data.\n",
        "        # 3. If user does not exist, create a new user record in the database.\n",
        "        # 4. Establish a server-side session for the user (e.g., using Flask sessions).\n",
        "\n",
        "        # For this step, we'll just return the verified user info as confirmation\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\n",
        "                \"id\": userid,\n",
        "                \"email\": email,\n",
        "                \"name\": name\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except ValueError:\n",
        "        # Invalid token\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        # Other errors during verification\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "# --- Content Generation Endpoint (Integrated Logic) ---\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "# In a real app, you might add @login_required or similar decorator for authentication\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "\n",
        "    # In a real application, you would authenticate the user here based on session\n",
        "    # or a token sent with the prompt request after successful sign-in.\n",
        "\n",
        "    print(f\"Received prompt from frontend: {prompt}\") # Log the received prompt\n",
        "\n",
        "    # --- 1. Generate Multilingual Text (Gemini API) ---\n",
        "    if not genai_client:\n",
        "         return jsonify({\"error\": \"Gemini API client not initialized. GEMINI_API_KEY might be missing.\"}), 500\n",
        "\n",
        "    text_prompt = f\"\"\"\n",
        "    You are a professional multilingual social media writer.\n",
        "    Produce a short motivational Instagram caption about depression and sadness, related to the user's prompt: \"{prompt}\"\n",
        "    Return EXACTLY a JSON object (no extra text) with keys:\n",
        "    {{\n",
        "      \"en\": \"<English caption (30-40 words)>\",\n",
        "      \"ar\": \"<Arabic caption>\",\n",
        "      \"am\": \"<Amharic caption>\"\n",
        "    }}\n",
        "    Make sure the values are plain strings and the entire response is valid JSON only.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Use the GenAI client\n",
        "        text_resp = genai_client.models.generate_content(\n",
        "            model=\"models/gemini-2.5-flash\", # Use gemini-2.5-flash for faster response\n",
        "            contents=text_prompt,\n",
        "            # max_output_tokens=300 # Adjust as needed\n",
        "        )\n",
        "        raw_text = text_resp.text.strip()\n",
        "\n",
        "        # Robustly parse JSON from the model output\n",
        "        text_data = None\n",
        "        try:\n",
        "            text_data = json.loads(raw_text)\n",
        "        except Exception:\n",
        "            m = re.search(r\"(\\{[\\s\\S]*\\})\", raw_text)\n",
        "            if m:\n",
        "                try:\n",
        "                    text_data = json.loads(m.group(1))\n",
        "                except Exception:\n",
        "                    pass # JSON parsing failed even with fallback\n",
        "            if not text_data:\n",
        "                 print(\"Warning: Failed to parse JSON from model output.\")\n",
        "                 print(\"Raw model output:\", raw_text)\n",
        "                 return jsonify({\"error\": \"Failed to generate and parse text content\"}), 500\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating text content: {e}\")\n",
        "        return jsonify({\"error\": f\"Error generating text content: {e}\"}), 500\n",
        "\n",
        "    english_caption = text_data.get('en', '')\n",
        "    if not english_caption:\n",
        "         return jsonify({\"error\": \"Generated English caption is empty\"}), 500\n",
        "\n",
        "\n",
        "    # --- 2. Generate Audio (gTTS) ---\n",
        "    # Generate a unique filename for the audio to avoid conflicts in a web app\n",
        "    audio_filename = f\"tts_en_{os.urandom(4).hex()}.mp3\"\n",
        "    audio_file_path = os.path.join(\"outputs\", audio_filename) # Save English audio for video\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "    audio_clip = None # Initialize audio_clip to None\n",
        "    try:\n",
        "        tts = gTTS(english_caption, lang='en')\n",
        "        tts.save(audio_file_path)\n",
        "        print(\"Saved audio:\", audio_file_path)\n",
        "        audio_clip = AudioFileClip(audio_file_path) # Load audio clip\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating audio: {e}\")\n",
        "        print(\"Warning: Proceeding without audio.\")\n",
        "\n",
        "\n",
        "    # --- 3. Fetch Images (Unsplash API) ---\n",
        "    IMAGE_COUNT = 5  # Number of images for video\n",
        "    VIDEO_DURATION_PER_IMAGE = 8 # Duration per image segment\n",
        "    IMAGE_DOWNLOAD_DIR = \"downloaded_images\"\n",
        "    os.makedirs(IMAGE_DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "    downloaded_image_paths = []\n",
        "    if not UNSPLASH_ACCESS_KEY or UNSPLASH_ACCESS_KEY == \"YOUR_UNSPLASH_ACCESS_KEY\":\n",
        "        print(\"Warning: Unsplash Access Key is not set. Skipping image fetching.\")\n",
        "        # Fallback to sample image if key is not set\n",
        "        sample_img_path = \"assets/sample.jpg\" # Assume sample.jpg exists or handle download\n",
        "        if os.path.exists(sample_img_path):\n",
        "             downloaded_image_paths.extend([sample_img_path] * IMAGE_COUNT) # Use sample image multiple times\n",
        "             print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "        else:\n",
        "            print(f\"Error: Sample image not found at {sample_img_path}. Cannot create video without images.\")\n",
        "            return jsonify({\"error\": \"Unsplash key not set and sample image not found\"}), 500\n",
        "    else:\n",
        "        # Use a keyword from the generated text as search query (e.g., first few words or extracted keywords)\n",
        "        # For simplicity, use a broader query or part of the generated text.\n",
        "        img_search_query = \"motivational OR hope OR mental health\" # Example: Use broader keywords\n",
        "        # Alternatively, use a part of the generated caption:\n",
        "        # img_search_query = \" \".join(english_caption.split()[:5]) # First 5 words as query\n",
        "\n",
        "        image_results = search_unsplash_images(img_search_query, UNSPLASH_ACCESS_KEY, IMAGE_COUNT)\n",
        "        if image_results:\n",
        "            print(f\"Found {len(image_results)} images. Downloading...\")\n",
        "            for i, img_info in enumerate(image_results):\n",
        "                img_url = img_info.get(\"urls\", {}).get(\"regular\") # Use 'regular' size\n",
        "                if img_url:\n",
        "                    try:\n",
        "                        img_response = requests.get(img_url, stream=True)\n",
        "                        img_response.raise_for_status()\n",
        "                        # Generate a unique filename for each image\n",
        "                        img_filename = f\"image_{i+1}_{os.urandom(4).hex()}.jpg\"\n",
        "                        file_path = os.path.join(IMAGE_DOWNLOAD_DIR, img_filename)\n",
        "                        with open(file_path, 'wb') as f:\n",
        "                            for chunk in img_response.iter_content(chunk_size=8192):\n",
        "                                f.write(chunk)\n",
        "                        downloaded_image_paths.append(file_path)\n",
        "                        print(f\"Downloaded: {file_path}\")\n",
        "                    except requests.exceptions.RequestException as e:\n",
        "                        print(f\"Error downloading image {img_url}: {e}\")\n",
        "                if len(downloaded_image_paths) >= IMAGE_COUNT: # Stop if we've downloaded enough\n",
        "                     break\n",
        "        else:\n",
        "            print(\"No images found from Unsplash.\")\n",
        "            # Fallback to sample image if Unsplash search fails\n",
        "            sample_img_path = \"assets/sample.jpg\"\n",
        "            if os.path.exists(sample_img_path):\n",
        "                 downloaded_image_paths.extend([sample_img_path] * IMAGE_COUNT)\n",
        "                 print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "            else:\n",
        "                print(f\"Error: Sample image not found at {sample_img_path}. Cannot create video without images.\")\n",
        "                return jsonify({\"error\": \"Unsplash search failed and sample image not found\"}), 500\n",
        "\n",
        "\n",
        "    # --- 4. Create Video (MoviePy) ---\n",
        "    if not downloaded_image_paths:\n",
        "         return jsonify({\"error\": \"No images available to create video\"}), 500\n",
        "\n",
        "    print(\"Creating video with downloaded images and transitions...\")\n",
        "    image_clips = [ImageClip(img_path).set_duration(VIDEO_DURATION_PER_IMAGE) for img_path in downloaded_image_paths]\n",
        "\n",
        "    # Apply fade out to all clips except the last one\n",
        "    FADE_DURATION = 1.5 # Make sure FADE_DURATION is defined\n",
        "    clips_with_fade_out = [clip.fx(fadeout, duration=FADE_DURATION) for clip in image_clips[:-1]]\n",
        "    # Apply fade in to all clips except the first one\n",
        "    clips_with_fade_in = [clip.fx(fadein, duration=FADE_DURATION) for clip in image_clips[1:]]\n",
        "\n",
        "    # Concatenate clips with transitions\n",
        "    # The fade out of one clip overlaps with the fade in of the next\n",
        "    final_clips = [clips_with_fade_out[0]] # Start with the first clip (with fade out)\n",
        "    for i in range(len(clips_with_fade_in)):\n",
        "        # Concatenate the fade-out part of clip_i with the fade-in part of clip_i+1\n",
        "        final_clips.append(clips_with_fade_in[i])\n",
        "\n",
        "    final_video_clip = concatenate_videoclips(image_clips, method=\"compose\") # Use compose for transitions\n",
        "\n",
        "\n",
        "    # Add Audio to Video\n",
        "    if audio_clip:\n",
        "        # Adjust audio duration to match the total video duration\n",
        "        if audio_clip.duration < final_video_clip.duration:\n",
        "            num_loops = int(final_video_clip.duration / audio_clip.duration) + 1\n",
        "            # Use concatenate_audioclips for audio looping\n",
        "            looped_audio = concatenate_audioclips([audio_clip] * num_loops)\n",
        "            audio_clip = looped_audio.subclip(0, final_video_clip.duration) # Trim to video duration\n",
        "\n",
        "        elif audio_clip.duration > final_video_clip.duration:\n",
        "             audio_clip = audio_clip.subclip(0, final_video_clip.duration)\n",
        "\n",
        "        video_final = final_video_clip.set_audio(audio_clip)\n",
        "    else:\n",
        "        video_final = final_video_clip # Video without audio\n",
        "\n",
        "\n",
        "    # Generate a unique filename for the output video\n",
        "    video_filename = f\"generated_reel_{os.urandom(4).hex()}.mp4\"\n",
        "    out_path = os.path.join(\"outputs\", video_filename) # Use a generic name for generated files\n",
        "    os.makedirs(\"outputs\", exist_ok=True) # Ensure outputs directory exists\n",
        "\n",
        "    try:\n",
        "        video_final.write_videofile(\n",
        "            out_path,\n",
        "            codec=\"libx264\",\n",
        "            audio_codec=\"aac\",\n",
        "            fps=24,\n",
        "            preset=\"medium\"\n",
        "        )\n",
        "        print(\"Saved generated reel:\", out_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing video file: {e}\")\n",
        "        return jsonify({\"error\": f\"Error creating video file: {e}\"}), 500\n",
        "\n",
        "\n",
        "    # --- 5. Store and Serve (Basic) ---\n",
        "    # In a real app, store file path and metadata in database,\n",
        "    # and provide a URL to access the file.\n",
        "    # For this example, we'll just return the path and other generated data.\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Content generated successfully\",\n",
        "        \"text_content\": text_data,\n",
        "        \"video_path\": out_path # Return the server path (for demonstration)\n",
        "    })\n",
        "\n",
        "\n",
        "# --- Optional: Root endpoint ---\n",
        "# @app.route('/')\n",
        "# def index():\n",
        "#     return 'Flask backend is running!'\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # This block is for running the Flask app directly (e.g., for local development).\n",
        "    # If using flask_ngrok in Colab, run_with_ngrok(app) starts the server,\n",
        "    # so the app.run() call here is typically not needed when using ngrok.\n",
        "    # For local development, uncomment the line below:\n",
        "    # app.run(debug=True)\n",
        "    pass # Keep this pass statement if the __name__ == '__main__' block is used but app.run() is commented out."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ImageMagick binary not found at /usr/bin/convert. Text overlay might fail.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "537b513e"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the steps for integrating the content generation logic (Gemini, gTTS, MoviePy) into the backend `generate-content` endpoint, fulfilling step 6 of the instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45168c03"
      },
      "source": [
        "**Reasoning**:\n",
        "Provide the corrected conceptual code for the `generate_content` function with integrated content generation logic, removing the duplicate route definition that caused the `AssertionError`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "676c9507"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the steps for deploying the web application, fulfilling step 7 of the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b017b5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f2123eb-3b79-4ea9-e7b2-f109bb572bbe"
      },
      "source": [
        "# Step 10: Deployment\n",
        "# This step is conceptual and cannot be executed directly in Colab.\n",
        "# Deploying a web application involves making it accessible to users over the internet.\n",
        "\n",
        "print(\"Outlining deployment steps:\")\n",
        "\n",
        "# 1. Choose a hosting platform:\n",
        "#    - Cloud Platforms: Google Cloud Platform (App Engine, Cloud Run, Kubernetes Engine), AWS (Elastic Beanstalk, ECS, EC2), Azure (App Service, Kubernetes Service), Heroku, Render, etc.\n",
        "#    - Virtual Private Servers (VPS): DigitalOcean, Linode, Vultr, etc. Requires more manual server management.\n",
        "\n",
        "print(\"  - Choose a hosting platform (Cloud Platform or VPS).\")\n",
        "\n",
        "# 2. Prepare for deployment:\n",
        "#    - Ensure all dependencies are listed in `requirements.txt` (Python backend) and `package.json` (Node.js frontend).\n",
        "#    - Configure environment variables for sensitive information (API keys, database credentials, Google Client ID/Secret).\n",
        "#    - Set up a production-ready WSGI server for Flask (e.g., Gunicorn, uWSGI).\n",
        "#    - Build the frontend for production (e.g., `npm run build` for React).\n",
        "\n",
        "print(\"  - Prepare dependencies and configuration.\")\n",
        "print(\"  - Set up a production-ready WSGI server (e.g., Gunicorn).\")\n",
        "print(\"  - Build the frontend for production.\")\n",
        "\n",
        "# 3. Database setup:\n",
        "#    - Provision a database instance on the hosting platform or a separate database service.\n",
        "#    - Configure the backend to connect to the production database.\n",
        "\n",
        "print(\"  - Set up a production database.\")\n",
        "\n",
        "# 4. Deployment process (Platform specific):\n",
        "#    - For Platform-as-a-Service (PaaS) like App Engine or Heroku: Often involves pushing code to a repository (e.g., Git) and the platform handles building and deploying.\n",
        "#    - For containerization (Docker, Kubernetes): Build Docker images for the frontend and backend and deploy them to a container orchestration service.\n",
        "#    - For VPS: Manually set up the server environment (install Python, Node.js, web server like Nginx/Apache), deploy code, configure the WSGI server, and set up a reverse proxy (Nginx/Apache) to serve the frontend and forward API requests to the backend.\n",
        "\n",
        "print(\"  - Follow platform-specific deployment steps.\")\n",
        "\n",
        "# 5. Configure domain and SSL:\n",
        "#    - Point your domain name to the deployed application.\n",
        "#    - Set up SSL/TLS certificates for secure HTTPS connections.\n",
        "\n",
        "print(\"  - Configure domain and SSL.\")\n",
        "\n",
        "# 6. Monitoring and logging:\n",
        "#    - Set up monitoring and logging to track application performance and errors.\n",
        "\n",
        "print(\"  - Set up monitoring and logging.\")\n",
        "\n",
        "# This outlines the general steps. The specific commands and configurations will vary significantly based on the chosen hosting platform and deployment method."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outlining deployment steps:\n",
            "  - Choose a hosting platform (Cloud Platform or VPS).\n",
            "  - Prepare dependencies and configuration.\n",
            "  - Set up a production-ready WSGI server (e.g., Gunicorn).\n",
            "  - Build the frontend for production.\n",
            "  - Set up a production database.\n",
            "  - Follow platform-specific deployment steps.\n",
            "  - Configure domain and SSL.\n",
            "  - Set up monitoring and logging.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e01e11b"
      },
      "source": [
        "## Finish task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the work done and provide instructions on how to use the application or the updated video generation code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "394d6f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207d5a21-45c9-488a-bb71-508f9873a22f"
      },
      "source": [
        "# Step 11: Finish task.\n",
        "# This step is a summary and instruction phase.\n",
        "\n",
        "print(\"--- Task Summary ---\")\n",
        "print(\"We have successfully:\")\n",
        "print(\"- Outlined a plan for building a content generation web application.\")\n",
        "print(\"- Explored methods for creating longer videos with multiple images using MoviePy.\")\n",
        "print(\"- Implemented dynamic image fetching from Unsplash based on text content.\")\n",
        "print(\"- Added fade transitions between images in the video.\")\n",
        "print(\"- Integrated audio from generated speech into the video.\")\n",
        "print(\"- Outlined the core components, technology stack, Google Sign-In steps, and content generation integration for the web application backend.\")\n",
        "print(\"- Provided conceptual code snippets for the Flask backend and React frontend structure.\")\n",
        "print(\"- Outlined the steps for deploying the web application.\")\n",
        "\n",
        "print(\"\\n--- Next Steps / How to Use ---\")\n",
        "print(\"1.  **Video Generation (in Colab):**\")\n",
        "print(\"    - Ensure you have run Cell 1 (Install packages) and Cell 3 (Set GEMINI_API_KEY).\")\n",
        "print(\"    - Run Cell 5 (Structured multilingual generation) to generate the multilingual captions and ensure the 'data' variable is populated.\")\n",
        "print(\"    - Run Cell 6 (Convert captions to speech) to generate the audio files from the captions.\")\n",
        "print(\"    - **Crucially:** Update Cell cd7de905 (Image fetching and video creation) with your actual Unsplash Access Key.\")\n",
        "print(\"    - Run Cell cd7de905 (Image fetching and video creation) to generate the video with dynamic images, transitions, and audio.\")\n",
        "print(\"    - The generated video will be saved as outputs/reel_creative.mp4.\")\n",
        "print(\"    - Run Cells iryaIltg8HMu (Save metadata) and s3pD3PJ8_B-k (Copy to Drive) to save the output metadata and copy the outputs to Google Drive (if mounted).\")\n",
        "\n",
        "print(\"\\n2.  **Web Application Development:**\")\n",
        "print(\"    - Take the conceptual code snippets provided for the Flask backend and React frontend and assemble them into a standard web application project outside of this Colab notebook.\")\n",
        "print(\"    - Implement the remaining parts of the plan (database integration, full API integration in the backend, complete frontend UI).\")\n",
        "print(\"    - Obtain your Google API credentials for Google Sign-In.\")\n",
        "print(\"    - Set up environment variables for your API keys (Gemini, Unsplash) and Google Client ID/Secret in your development and deployment environment.\")\n",
        "print(\"    - Follow the outlined deployment steps to make your application accessible.\")\n",
        "\n",
        "print(\"\\nThis concludes the tasks we've worked on within this Colab notebook. You now have working code for generating videos with dynamic images and audio, and a clear plan and initial code structure for building the web application.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task Summary ---\n",
            "We have successfully:\n",
            "- Outlined a plan for building a content generation web application.\n",
            "- Explored methods for creating longer videos with multiple images using MoviePy.\n",
            "- Implemented dynamic image fetching from Unsplash based on text content.\n",
            "- Added fade transitions between images in the video.\n",
            "- Integrated audio from generated speech into the video.\n",
            "- Outlined the core components, technology stack, Google Sign-In steps, and content generation integration for the web application backend.\n",
            "- Provided conceptual code snippets for the Flask backend and React frontend structure.\n",
            "- Outlined the steps for deploying the web application.\n",
            "\n",
            "--- Next Steps / How to Use ---\n",
            "1.  **Video Generation (in Colab):**\n",
            "    - Ensure you have run Cell 1 (Install packages) and Cell 3 (Set GEMINI_API_KEY).\n",
            "    - Run Cell 5 (Structured multilingual generation) to generate the multilingual captions and ensure the 'data' variable is populated.\n",
            "    - Run Cell 6 (Convert captions to speech) to generate the audio files from the captions.\n",
            "    - **Crucially:** Update Cell cd7de905 (Image fetching and video creation) with your actual Unsplash Access Key.\n",
            "    - Run Cell cd7de905 (Image fetching and video creation) to generate the video with dynamic images, transitions, and audio.\n",
            "    - The generated video will be saved as outputs/reel_creative.mp4.\n",
            "    - Run Cells iryaIltg8HMu (Save metadata) and s3pD3PJ8_B-k (Copy to Drive) to save the output metadata and copy the outputs to Google Drive (if mounted).\n",
            "\n",
            "2.  **Web Application Development:**\n",
            "    - Take the conceptual code snippets provided for the Flask backend and React frontend and assemble them into a standard web application project outside of this Colab notebook.\n",
            "    - Implement the remaining parts of the plan (database integration, full API integration in the backend, complete frontend UI).\n",
            "    - Obtain your Google API credentials for Google Sign-In.\n",
            "    - Set up environment variables for your API keys (Gemini, Unsplash) and Google Client ID/Secret in your development and deployment environment.\n",
            "    - Follow the outlined deployment steps to make your application accessible.\n",
            "\n",
            "This concludes the tasks we've worked on within this Colab notebook. You now have working code for generating videos with dynamic images and audio, and a clear plan and initial code structure for building the web application.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "95435bc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd1e1a7-30a5-44f9-8e40-284f80a40f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "libavutil      56. 70.100 / 56. 70.100\n",
            "libavcodec     58.134.100 / 58.134.100\n",
            "libavformat    58. 76.100 / 58. 76.100\n",
            "libavdevice    58. 13.100 / 58. 13.100\n",
            "libavfilter     7.110.100 /  7.110.100\n",
            "libswscale      5.  9.100 /  5.  9.100\n",
            "libswresample   3.  9.100 /  3.  9.100\n",
            "libpostproc    55.  9.100 / 55.  9.100\n"
          ]
        }
      ],
      "source": [
        "# Check FFmpeg version in Colab\n",
        "!ffmpeg -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "69e1fbff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8058e773-5a8e-46b2-ebd2-2ff21329bf41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_from_response', '_get_value', '_iter', '_setattr_handler', 'checkpoints', 'construct', 'copy', 'default_checkpoint_id', 'description', 'dict', 'display_name', 'endpoints', 'from_orm', 'input_token_limit', 'json', 'labels', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'name', 'output_token_limit', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'supported_actions', 'to_json_dict', 'tuned_model_info', 'update_forward_refs', 'validate', 'version']\n"
          ]
        }
      ],
      "source": [
        "# Inspect a model object to see its attributes\n",
        "for m in client.models.list():\n",
        "  print(dir(m))\n",
        "  break # Print attributes for only one model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "afb20986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89821ad6-4b2d-407f-b528-a1f5554836cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: models/gemini-2.5-pro-preview-03-25\n",
            "Model: models/gemini-2.5-flash-preview-05-20\n",
            "Model: models/gemini-2.5-flash\n",
            "Model: models/gemini-2.5-flash-lite-preview-06-17\n",
            "Model: models/gemini-2.5-pro-preview-05-06\n",
            "Model: models/gemini-2.5-pro-preview-06-05\n",
            "Model: models/gemini-2.5-pro\n",
            "Model: models/gemini-2.0-flash-exp\n",
            "Model: models/gemini-2.0-flash\n",
            "Model: models/gemini-2.0-flash-001\n",
            "Model: models/gemini-2.0-flash-exp-image-generation\n",
            "Model: models/gemini-2.0-flash-lite-001\n",
            "Model: models/gemini-2.0-flash-lite\n",
            "Model: models/gemini-2.0-flash-preview-image-generation\n",
            "Model: models/gemini-2.0-flash-lite-preview-02-05\n",
            "Model: models/gemini-2.0-flash-lite-preview\n",
            "Model: models/gemini-2.0-pro-exp\n",
            "Model: models/gemini-2.0-pro-exp-02-05\n",
            "Model: models/gemini-exp-1206\n",
            "Model: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "Model: models/gemini-2.0-flash-thinking-exp\n",
            "Model: models/gemini-2.0-flash-thinking-exp-1219\n",
            "Model: models/gemini-2.5-flash-preview-tts\n",
            "Model: models/gemini-2.5-pro-preview-tts\n",
            "Model: models/learnlm-2.0-flash-experimental\n",
            "Model: models/gemma-3-1b-it\n",
            "Model: models/gemma-3-4b-it\n",
            "Model: models/gemma-3-12b-it\n",
            "Model: models/gemma-3-27b-it\n",
            "Model: models/gemma-3n-e4b-it\n",
            "Model: models/gemma-3n-e2b-it\n",
            "Model: models/gemini-flash-latest\n",
            "Model: models/gemini-flash-lite-latest\n",
            "Model: models/gemini-pro-latest\n",
            "Model: models/gemini-2.5-flash-lite\n",
            "Model: models/gemini-2.5-flash-image-preview\n",
            "Model: models/gemini-2.5-flash-image\n",
            "Model: models/gemini-2.5-flash-preview-09-2025\n",
            "Model: models/gemini-2.5-flash-lite-preview-09-2025\n",
            "Model: models/gemini-robotics-er-1.5-preview\n",
            "Model: models/gemini-2.5-computer-use-preview-10-2025\n"
          ]
        }
      ],
      "source": [
        "# List available models\n",
        "for m in client.models.list():\n",
        "    if 'generateContent' in m.supported_actions: # Trying supported_actions instead of supported_methods\n",
        "        print(f\"Model: {m.name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ec6b44"
      },
      "source": [
        "# Task\n",
        "Modify the existing code to generate videos between 1 and 3 minutes long, incorporating different images and creative elements. Additionally, outline a plan to develop a web application with Google sign-in for users to create content with prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ea942b5"
      },
      "source": [
        "## Explore longer video creation\n",
        "\n",
        "### Subtask:\n",
        "Investigate methods for creating videos longer than a few seconds using MoviePy or other libraries, potentially involving multiple images or video clips.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfabadf9"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to explore MoviePy's capabilities for creating longer videos by combining images or video clips. The MoviePy documentation is the primary source for this information. I will outline the relevant functionalities and then propose a strategy based on my findings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2afb8170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e320f6-50c5-40d9-d46e-5810fabd3c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exploration of MoviePy for longer videos complete. Strategy outlined.\n"
          ]
        }
      ],
      "source": [
        "# Explore MoviePy documentation and identify methods for longer videos.\n",
        "# This step is exploratory and doesn't require code execution in this context.\n",
        "# However, I can demonstrate a simple example of concatenating clips, which is a core method.\n",
        "\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips\n",
        "import os\n",
        "\n",
        "# Create some dummy image clips\n",
        "clip1 = ImageClip(\"assets/sample.jpg\", duration=5)\n",
        "clip2 = ImageClip(\"assets/sample.jpg\", duration=5)\n",
        "clip3 = ImageClip(\"assets/sample.jpg\", duration=5)\n",
        "\n",
        "# Concatenate the clips\n",
        "final_clip = concatenate_videoclips([clip1, clip2, clip3])\n",
        "\n",
        "# The resulting clip is 15 seconds long. This demonstrates how to combine clips\n",
        "# to increase duration. For 1-3 minutes, we would concatenate many more clips or use longer source materials.\n",
        "\n",
        "# To demonstrate a strategy:\n",
        "# A strategy for 1-3 minute videos using MoviePy could involve:\n",
        "# 1. Using a sequence of images, where each image is displayed for a specific duration.\n",
        "# 2. Using existing video clips and concatenating them.\n",
        "# 3. Combining image sequences and video clips.\n",
        "# 4. Adding background music or voiceovers that match the desired duration.\n",
        "\n",
        "# For this subtask, I will focus on the image sequence approach as it aligns with the current notebook's structure.\n",
        "# We would need to source or generate more images and define their durations to reach the target video length.\n",
        "# Alternatively, we could use the same image for a longer duration, though this might not be visually engaging.\n",
        "\n",
        "# I will not generate a full 1-3 minute video here as the focus is on outlining the strategy based on MoviePy capabilities.\n",
        "# The primary function for this is concatenate_videoclips and setting the duration of individual clips.\n",
        "\n",
        "print(\"Exploration of MoviePy for longer videos complete. Strategy outlined.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3c43aff"
      },
      "source": [
        "# Download sample image if it doesn't exist\n",
        "import os\n",
        "if not os.path.exists(\"assets\"):\n",
        "    os.makedirs(\"assets\")\n",
        "sample_img_path = \"assets/sample.jpg\"\n",
        "if not os.path.exists(sample_img_path):\n",
        "    print(f\"Downloading sample image to {sample_img_path}\")\n",
        "    !wget -q -O assets/sample.jpg \"https://images.unsplash.com/photo-1507525428034-b723cf961d3e?w=1200\"\n",
        "    if not os.path.exists(sample_img_path):\n",
        "        print(f\"Error: Failed to download sample image.\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82051710"
      },
      "source": [
        "## Setting up the Web Application Projects\n",
        "\n",
        "We've outlined the structure and core components for the Flask backend and React frontend in the previous planning steps. Now, let's set up the actual project directories and initial files outside of this Colab environment.\n",
        "\n",
        "**Backend (Flask):**\n",
        "\n",
        "1.  **Create a project directory:** Choose a name for your project (e.g., `ai-content-mvp`) and create a directory for it.\n",
        "2.  **Create the backend directory:** Inside the project directory, create a subdirectory named `backend`.\n",
        "3.  **Create `app.py`:** Inside the `backend` directory, create a file named `app.py`. This will be your main Flask application file. Copy the combined conceptual Flask code from our previous steps into this file.\n",
        "4.  **Create `requirements.txt`:** Inside the `backend` directory, create a file named `requirements.txt`. Add the necessary Python dependencies to this file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5a804da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b76cd37-b386-40fc-b8c0-d852ea86fd95"
      },
      "source": [
        "!npm install @react-oauth/google\n",
        "# or using yarn:\n",
        "# !yarn add @react-oauth/google"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\n",
            "added 4 packages in 2s\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d81e650b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92e68f1-2a00-477a-d8fc-08ec44726b3d"
      },
      "source": [
        "# Step 5: Set up a new React project for the frontend.\n",
        "# This is typically done using create-react-app or similar tools.\n",
        "# We can simulate this by outlining the necessary files as shown above.\n",
        "# To actually create the React project, you would run one of the following\n",
        "# commands in your terminal where you want the project to be created:\n",
        "\n",
        "# Using create-react-app (requires Node.js and npm/yarn installed):\n",
        "!npx create-react-app frontend\n",
        "# or using Vite (a faster alternative):\n",
        "# !npm create vite@latest frontend --template react\n",
        "\n",
        "# After creating the project, you would navigate into the 'frontend' directory\n",
        "# and install additional dependencies like the Google Sign-In library:\n",
        "# cd frontend\n",
        "# !npm install @react-oauth/google\n",
        "# or using yarn:\n",
        "# !yarn add @react-oauth/google\n",
        "\n",
        "print(\"Outlined steps and provided shell commands for setting up the React frontend project.\")\n",
        "print(\"Note: These commands will create a 'frontend' directory in your current working directory in the Colab environment.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "create-react-app@5.1.0\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m uid-number@0.0.6: This package is no longer supported.\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m fstream-ignore@1.0.5: This package is no longer supported.\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m rimraf@2.7.1: Rimraf versions prior to v4 are no longer supported\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m glob@7.2.3: Glob versions prior to v9 are no longer supported\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m fstream@1.0.12: This package is no longer supported.\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[33mwarn\u001b[39m \u001b[94mdeprecated\u001b[39m tar@2.2.2: This version of tar is no longer supported, and will not receive security updates. Please upgrade asap.\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0K\u001b[33m\u001b[1mcreate-react-app is deprecated.\u001b[22m\u001b[39m\n",
            "\n",
            "You can find a list of up-to-date React frameworks on react.dev\n",
            "For more info see:\u001b[4mhttps://react.dev/link/cra\u001b[24m\n",
            "\n",
            "\u001b[90mThis error message will only be shown once per install.\u001b[39m\n",
            "\n",
            "Creating a new React app in \u001b[32m/content/frontend\u001b[39m.\n",
            "\n",
            "Installing packages. This might take a couple of minutes.\n",
            "Installing \u001b[36mreact\u001b[39m, \u001b[36mreact-dom\u001b[39m, and \u001b[36mreact-scripts\u001b[39m with \u001b[36mcra-template\u001b[39m...\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "added 1324 packages in 2m\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K271 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "Initialized a git repository.\n",
            "\n",
            "Installing template dependencies using npm...\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0K\n",
            "added 17 packages, and changed 1 package in 6s\n",
            "\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0K271 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0KRemoving template package using npm...\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\n",
            "removed 1 package, and audited 1341 packages in 6s\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K271 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0K\n",
            "\u001b[31m\u001b[1m9\u001b[22m\u001b[39m vulnerabilities (3 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m, 6 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m)\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0KGit commit not created Error: Command failed: git commit -m \"Initialize project using Create React App\"\n",
            "\u001b[90m    at genericNodeError (node:internal/errors:984:15)\u001b[39m\n",
            "\u001b[90m    at wrappedFn (node:internal/errors:538:14)\u001b[39m\n",
            "\u001b[90m    at checkExecSyncError (node:child_process:891:11)\u001b[39m\n",
            "\u001b[90m    at execSync (node:child_process:963:15)\u001b[39m\n",
            "    at tryGitCommit \u001b[90m(/content/frontend/\u001b[39mnode_modules/\u001b[4mreact-scripts\u001b[24m/scripts/init.js:62:5\u001b[90m)\u001b[39m\n",
            "    at module.exports \u001b[90m(/content/frontend/\u001b[39mnode_modules/\u001b[4mreact-scripts\u001b[24m/scripts/init.js:350:25\u001b[90m)\u001b[39m\n",
            "    at [eval]:3:14\n",
            "\u001b[90m    at runScriptInThisContext (node:internal/vm:209:10)\u001b[39m\n",
            "\u001b[90m    at node:internal/process/execution:118:14\u001b[39m\n",
            "    at [eval]-wrapper:6:24 {\n",
            "  status: \u001b[33m128\u001b[39m,\n",
            "  signal: \u001b[1mnull\u001b[22m,\n",
            "  output: [ \u001b[1mnull\u001b[22m, \u001b[1mnull\u001b[22m, \u001b[1mnull\u001b[22m ],\n",
            "  pid: \u001b[33m2656\u001b[39m,\n",
            "  stdout: \u001b[1mnull\u001b[22m,\n",
            "  stderr: \u001b[1mnull\u001b[22m\n",
            "}\n",
            "Removing .git directory...\n",
            "\n",
            "Success! Created frontend at /content/frontend\n",
            "Inside that directory, you can run several commands:\n",
            "\n",
            "\u001b[36m  npm start\u001b[39m\n",
            "    Starts the development server.\n",
            "\n",
            "\u001b[36m  npm run build\u001b[39m\n",
            "    Bundles the app into static files for production.\n",
            "\n",
            "\u001b[36m  npm test\u001b[39m\n",
            "    Starts the test runner.\n",
            "\n",
            "\u001b[36m  npm run eject\u001b[39m\n",
            "    Removes this tool and copies build dependencies, configuration files\n",
            "    and scripts into the app directory. If you do this, you canâ€™t go back!\n",
            "\n",
            "We suggest that you begin by typing:\n",
            "\n",
            "\u001b[36m  cd\u001b[39m frontend\n",
            "  \u001b[36mnpm start\u001b[39m\n",
            "\n",
            "Happy hacking!\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0KOutlined steps and provided shell commands for setting up the React frontend project.\n",
            "Note: These commands will create a 'frontend' directory in your current working directory in the Colab environment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "017abefe"
      },
      "source": [
        "!rm -rf frontend/*"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57d13e04",
        "outputId": "755d1935-0be3-4159-8a04-ad4357e3b8df"
      },
      "source": [
        "# Navigate into the frontend directory and install the Google Sign-In library\n",
        "!cd frontend && npm install @react-oauth/google\n",
        "# or if you are using yarn:\n",
        "# !cd frontend && yarn add @react-oauth/google"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "up to date, audited 5 packages in 848ms\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "042c821c",
        "outputId": "818734cc-7930-41e6-918d-ffa31e43912f"
      },
      "source": [
        "!npx create-react-app frontend"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "create-react-app@5.1.0\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0K\n",
            "Creating a new React app in \u001b[32m/content/frontend\u001b[39m.\n",
            "\n",
            "Installing packages. This might take a couple of minutes.\n",
            "Installing \u001b[36mreact\u001b[39m, \u001b[36mreact-dom\u001b[39m, and \u001b[36mreact-scripts\u001b[39m with \u001b[36mcra-template\u001b[39m...\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K\n",
            "added 1324 packages in 43s\n",
            "\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K271 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0K\n",
            "Initialized a git repository.\n",
            "\n",
            "Installing template dependencies using npm...\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "added 17 packages, and changed 1 package in 5s\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K271 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0KRemoving template package using npm...\n",
            "\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\n",
            "removed 1 package, and audited 1341 packages in 3s\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K271 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K\n",
            "\u001b[31m\u001b[1m9\u001b[22m\u001b[39m vulnerabilities (3 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m, 6 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m)\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0KGit commit not created Error: Command failed: git commit -m \"Initialize project using Create React App\"\n",
            "\u001b[90m    at genericNodeError (node:internal/errors:984:15)\u001b[39m\n",
            "\u001b[90m    at wrappedFn (node:internal/errors:538:14)\u001b[39m\n",
            "\u001b[90m    at checkExecSyncError (node:child_process:891:11)\u001b[39m\n",
            "\u001b[90m    at execSync (node:child_process:963:15)\u001b[39m\n",
            "    at tryGitCommit \u001b[90m(/content/frontend/\u001b[39mnode_modules/\u001b[4mreact-scripts\u001b[24m/scripts/init.js:62:5\u001b[90m)\u001b[39m\n",
            "    at module.exports \u001b[90m(/content/frontend/\u001b[39mnode_modules/\u001b[4mreact-scripts\u001b[24m/scripts/init.js:350:25\u001b[90m)\u001b[39m\n",
            "    at [eval]:3:14\n",
            "\u001b[90m    at runScriptInThisContext (node:internal/vm:209:10)\u001b[39m\n",
            "\u001b[90m    at node:internal/process/execution:118:14\u001b[39m\n",
            "    at [eval]-wrapper:6:24 {\n",
            "  status: \u001b[33m128\u001b[39m,\n",
            "  signal: \u001b[1mnull\u001b[22m,\n",
            "  output: [ \u001b[1mnull\u001b[22m, \u001b[1mnull\u001b[22m, \u001b[1mnull\u001b[22m ],\n",
            "  pid: \u001b[33m3210\u001b[39m,\n",
            "  stdout: \u001b[1mnull\u001b[22m,\n",
            "  stderr: \u001b[1mnull\u001b[22m\n",
            "}\n",
            "Removing .git directory...\n",
            "\n",
            "Success! Created frontend at /content/frontend\n",
            "Inside that directory, you can run several commands:\n",
            "\n",
            "\u001b[36m  npm start\u001b[39m\n",
            "    Starts the development server.\n",
            "\n",
            "\u001b[36m  npm run build\u001b[39m\n",
            "    Bundles the app into static files for production.\n",
            "\n",
            "\u001b[36m  npm test\u001b[39m\n",
            "    Starts the test runner.\n",
            "\n",
            "\u001b[36m  npm run eject\u001b[39m\n",
            "    Removes this tool and copies build dependencies, configuration files\n",
            "    and scripts into the app directory. If you do this, you canâ€™t go back!\n",
            "\n",
            "We suggest that you begin by typing:\n",
            "\n",
            "\u001b[36m  cd\u001b[39m frontend\n",
            "  \u001b[36mnpm start\u001b[39m\n",
            "\n",
            "Happy hacking!\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cf0bb67",
        "outputId": "fc37df8b-be25-49de-e1af-4cd56cbe6302"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t downloaded_images  frontend\t  outputs\tpackage-lock.json\n",
            "backend  drive\t\t    node_modules  package.json\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a2af29e"
      },
      "source": [
        "## Incorporate diverse images\n",
        "\n",
        "### Subtask:\n",
        "Explore ways to dynamically select or generate different images for the video based on the prompt or other criteria.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d79432ed"
      },
      "source": [
        "**Reasoning**:\n",
        "Explore image sourcing options and outline a strategy for integrating them into the workflow and handling multiple images for longer videos. This involves researching potential image sources and thinking about how to connect text content to image selection or generation. Since this subtask is primarily about research and outlining a strategy, a single code block with comments and print statements to explain the findings and plan is appropriate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "81462009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd0bace-c421-4656-dd9d-bc3b275a6f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Researched image sourcing options: Unsplash, Pixabay, Pexels (APIs for free stock photos), Generative Image Models (APIs), and a local image library.\n",
            "Investigated integration methods: Keyword extraction from text, using APIs with keywords, generative model APIs, and local library matching. Selection logic is needed.\n",
            "Outlined strategy for multiple images in a longer video: Segment text, associate images per segment, determine image duration, concatenate clips, add transitions (optional), and add audio.\n"
          ]
        }
      ],
      "source": [
        "# Subtask: Explore ways to dynamically select or generate different images for the video based on the prompt or other criteria.\n",
        "\n",
        "# 1. Research image sourcing options:\n",
        "# - Unsplash API: Offers a large library of free, high-quality images. Requires API key and adherence to usage policies. Can search based on keywords.\n",
        "# - Pixabay API: Similar to Unsplash, provides free images and videos. Also requires API key and has usage limits. Supports keyword searches.\n",
        "# - Pexels API: Another source for free stock photos and videos. Requires API key. Supports keyword searches.\n",
        "# - Generative Image Models (e.g., DALL-E, Stable Diffusion, Midjourney): Can create unique images based on text prompts. Integration would likely involve using their APIs. Availability and cost vary.\n",
        "# - Local Image Library: Curating a local collection of images and selecting from it based on keywords or themes extracted from the text.\n",
        "\n",
        "print(\"Researched image sourcing options: Unsplash, Pixabay, Pexels (APIs for free stock photos), Generative Image Models (APIs), and a local image library.\")\n",
        "\n",
        "# 2. Investigate how to integrate the chosen image sourcing method:\n",
        "# - Keyword Extraction: Analyze the generated text (captions) to extract relevant keywords (e.g., \"depression\", \"sadness\", \"hope\", \"sunrise\").\n",
        "# - API Integration: Use the extracted keywords to query the chosen image API (Unsplash, Pixabay, Pexels) to find relevant images.\n",
        "# - Generative Model Integration: Use the extracted keywords or a modified version of the original prompt to generate images using a generative model API.\n",
        "# - Local Library Matching: Match extracted keywords to metadata or filenames of images in a local library.\n",
        "# - Selection Logic: Implement logic to select the best image(s) from the API results or generated images based on relevance, quality, or diversity.\n",
        "\n",
        "print(\"Investigated integration methods: Keyword extraction from text, using APIs with keywords, generative model APIs, and local library matching. Selection logic is needed.\")\n",
        "\n",
        "# 3. Outline a strategy for handling multiple images for a longer video:\n",
        "# - Segment the Text: Divide the longer generated text into smaller segments or sentences.\n",
        "# - Image Association: Associate one or more images with each text segment. This could be done by extracting keywords from each segment and finding corresponding images.\n",
        "# - Image Duration: Determine the display duration for each image based on the length of the associated text segment (e.g., longer segments get longer image display times) or a fixed duration per image.\n",
        "# - Concatenation: Use MoviePy's `concatenate_videoclips` to combine the image clips (each with its associated image and duration) in the order of the text segments.\n",
        "# - Transitions: (Optional) Add transitions between image clips for a smoother video.\n",
        "# - Background Music/Audio: Add background music or the generated voiceover that spans the entire video duration.\n",
        "\n",
        "print(\"Outlined strategy for multiple images in a longer video: Segment text, associate images per segment, determine image duration, concatenate clips, add transitions (optional), and add audio.\")\n",
        "\n",
        "# This subtask focused on researching and outlining. No code execution for dynamic image fetching is performed here.\n",
        "# The next steps would involve implementing the chosen image sourcing method and the multi-image strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deb9e4c6"
      },
      "source": [
        "## Enhance video creativity\n",
        "\n",
        "### Subtask:\n",
        "Look into adding transitions, text overlays, or other effects to the video using MoviePy or other video editing libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1801182"
      },
      "source": [
        "**Reasoning**:\n",
        "Research MoviePy capabilities for adding transitions and text overlays, and outline a plan for incorporating them into the video generation process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "74951f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20a2ed8-792c-46f4-ac76-1467ddc412af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Researched MoviePy transitions: `concatenate_videoclips` with `method='compose'` allows overlap. Custom transitions can be built. No extensive built-in transition library.\n",
            "Researched MoviePy text overlays: `TextClip` class is used, customized with various parameters. Positioned using `CompositeVideoClip`.\n",
            "Investigated basic video effects in MoviePy: `fx` attribute and `vfx` module offer basic effects. Integration with OpenCV/PIL might be needed for complex effects.\n",
            "Outlined plan for incorporating transitions and text overlays: Segment text/time clips, create image/video clips, create and position text overlays, composite text onto video, add transitions (e.g., fade), concatenate clips, and add audio.\n"
          ]
        }
      ],
      "source": [
        "# Subtask: Look into adding transitions, text overlays, or other effects to the video using MoviePy or other video editing libraries.\n",
        "\n",
        "# 1. Research MoviePy's capabilities for adding transitions:\n",
        "# MoviePy's `concatenate_videoclips` function can be used with the `method=\"compose\"` argument.\n",
        "# While `method=\"compose\"` allows for overlapping clips, MoviePy itself doesn't have a built-in library of complex, named transitions (like \"fade in\", \"slide\").\n",
        "# However, custom transitions can be created by defining a function that takes two clips and a duration and returns a new clip representing the transition.\n",
        "# Libraries like `moviepy.video.compositing.transitions` exist in older versions or examples, but the core functionality for simple transitions often involves manual alpha compositing or other effects during the overlap.\n",
        "# A common approach for simple transitions like fading is to manipulate the `fx` attribute of clips or create custom composite clips.\n",
        "\n",
        "print(\"Researched MoviePy transitions: `concatenate_videoclips` with `method='compose'` allows overlap. Custom transitions can be built. No extensive built-in transition library.\")\n",
        "\n",
        "# 2. Research how to add text overlays to video clips using MoviePy:\n",
        "# MoviePy provides the `TextClip` class for creating text elements.\n",
        "# `TextClip` can be customized with font, font size, color, background color, stroke, and duration.\n",
        "# Text clips can be positioned on top of other clips using `CompositeVideoClip`.\n",
        "# The position can be static or animated over time.\n",
        "\n",
        "from moviepy.editor import TextClip, CompositeVideoClip\n",
        "\n",
        "# Example of creating a TextClip (will not display without a video clip to composite onto):\n",
        "# txt_clip = TextClip(\"Hello World\", fontsize=70, color='white', duration=5)\n",
        "# video_with_text = CompositeVideoClip([video_clip, txt_clip.set_position('center')])\n",
        "\n",
        "print(\"Researched MoviePy text overlays: `TextClip` class is used, customized with various parameters. Positioned using `CompositeVideoClip`.\")\n",
        "\n",
        "# 3. Investigate options for basic video effects within MoviePy or by integrating with other libraries:\n",
        "# MoviePy has basic image processing capabilities through the `fx` attribute and functions like `vfx.resize`, `vfx.speedx`, `vfx.fadein`, `vfx.fadeout`.\n",
        "# More complex effects might require integration with libraries like OpenCV or PIL (Pillow) for image manipulation before creating ImageClips.\n",
        "# Color adjustments, simple filters, and transformations can often be achieved by applying functions to each frame of a clip.\n",
        "\n",
        "from moviepy.editor import vfx\n",
        "\n",
        "# Example of a simple effect (will not apply without a video clip):\n",
        "# resized_clip = video_clip.fx(vfx.resize, newsize=(640, 480))\n",
        "# faded_in_clip = video_clip.fx(vfx.fadein, duration=2)\n",
        "\n",
        "print(\"Investigated basic video effects in MoviePy: `fx` attribute and `vfx` module offer basic effects. Integration with OpenCV/PIL might be needed for complex effects.\")\n",
        "\n",
        "# 4. Outline a plan for incorporating transitions and text overlays into the video generation process:\n",
        "# - Text Segmentation and Timing: Based on the longer generated text, determine the start and end time for each text segment and its associated image/video clip.\n",
        "# - Image/Video Clip Creation: Create ImageClips (from sourced/generated images) or use existing video clips with durations matching the text segments.\n",
        "# - Text Overlay Creation: For each text segment, create a `TextClip` with the corresponding text. Set the duration and position of the text clip to match the associated video segment.\n",
        "# - Compositing: Use `CompositeVideoClip` to overlay the text clips onto their respective image/video clips.\n",
        "# - Transitions: Implement simple fade-in/fade-out transitions between the composited clips. This can be done by adjusting the alpha channel of the clips during the overlap period when concatenating with `method=\"compose\"`, or by using the `fadein`/`fadeout` effects on the ends of clips.\n",
        "# - Concatenation: Concatenate the composited clips (with text overlays and applied transitions) using `concatenate_videoclips`.\n",
        "# - Audio Integration: Add the generated voiceover or background music to the final concatenated video clip.\n",
        "\n",
        "print(\"Outlined plan for incorporating transitions and text overlays: Segment text/time clips, create image/video clips, create and position text overlays, composite text onto video, add transitions (e.g., fade), concatenate clips, and add audio.\")\n",
        "\n",
        "# This subtask focused on research and outlining. No code execution for adding transitions/overlays is performed here.\n",
        "# The next steps would involve implementing this plan within the video generation code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de835ba5"
      },
      "source": [
        "## Develop web application plan\n",
        "\n",
        "### Subtask:\n",
        "Outline the steps required to build a web application, including user authentication with Google accounts and integrating the content generation functionality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc047485"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the steps to build a web application with Google Sign-In and content generation integration based on the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aaf7f2df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c09108-524a-4b98-ea38-3af2eb74afa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified core web application components: Frontend, Backend, Database.\n",
            "Outlined technology stack: Flask (Backend), React (Frontend), PostgreSQL (Database).\n",
            "Detailed Google Sign-In steps: Obtain credentials, frontend integration with a library, backend token verification, and user management in the database.\n",
            "Described backend integration of content generation: Gemini API for text, gTTS for audio, MoviePy for video creation, and error handling.\n",
            "Planned storage and serving of content: Store files on server/cloud storage, store metadata in database, provide backend endpoints for serving.\n",
            "Considered user interface requirements: Prompt input, options, loading indicator, content display, download options.\n",
            "Outlined basic architecture and flow.\n"
          ]
        }
      ],
      "source": [
        "# Subtask: Outline the steps required to build a web application, including user authentication with Google accounts and integrating the content generation functionality.\n",
        "\n",
        "# 1. Identify core components:\n",
        "# - Frontend: User interface for interacting with the application (input prompts, viewing generated content).\n",
        "# - Backend: Handles user authentication, interacts with APIs (Gemini, gTTS), processes video creation (MoviePy), and manages data.\n",
        "# - Database: Stores user information, prompts, generated content metadata, and file paths.\n",
        "\n",
        "print(\"Identified core web application components: Frontend, Backend, Database.\")\n",
        "\n",
        "# 2. Outline the technology stack:\n",
        "# - Backend Framework: Python framework like Flask or Django. Flask is suitable for smaller applications, while Django is more robust for larger ones. Let's assume Flask for this outline.\n",
        "# - Frontend Framework: JavaScript framework like React, Vue.js, or Angular. React is a popular choice.\n",
        "# - Database: A relational database like PostgreSQL or MySQL, or a NoSQL database like MongoDB. PostgreSQL is a good general-purpose choice.\n",
        "\n",
        "print(\"Outlined technology stack: Flask (Backend), React (Frontend), PostgreSQL (Database).\")\n",
        "\n",
        "# 3. Detail steps for implementing Google Sign-In:\n",
        "# - Obtain Google API Credentials: Create a project in the Google Cloud Console, enable the Google Sign-In API, and obtain a Client ID and Client Secret.\n",
        "# - Frontend Integration: Use a Google Sign-In library for React (e.g., `react-google-login` or `@react-oauth/google`) to initiate the OAuth 2.0 flow. The frontend will send the authentication token to the backend.\n",
        "# - Backend Verification: On the backend (Flask), receive the authentication token from the frontend. Use a Google Identity Services client library for Python (e.g., `google-auth`) to verify the token's authenticity and retrieve user information (email, name, profile picture).\n",
        "# - User Management: Based on the verified user information, either log in an existing user or create a new user record in the database.\n",
        "\n",
        "print(\"Detailed Google Sign-In steps: Obtain credentials, frontend integration with a library, backend token verification, and user management in the database.\")\n",
        "\n",
        "# 4. Describe integration of content generation functionality into the backend:\n",
        "# - API Calls: The backend will receive prompts from the frontend. Use the `google-genai` library to call the Gemini API for text generation based on the user's prompt.\n",
        "# - Text-to-Speech: Use the `gTTS` library to convert the generated text into audio files.\n",
        "# - Video Creation: Use the `moviepy` library to create videos, incorporating sourced/generated images and the generated audio. This will involve the strategies outlined in previous subtasks (concatenating clips, adding text overlays, etc.).\n",
        "# - Error Handling: Implement error handling for API calls and video processing.\n",
        "\n",
        "print(\"Described backend integration of content generation: Gemini API for text, gTTS for audio, MoviePy for video creation, and error handling.\")\n",
        "\n",
        "# 5. Plan for storing and serving generated content:\n",
        "# - Storage: Store generated audio and video files on the server's file system or a cloud storage service (e.g., Google Cloud Storage, AWS S3). Store metadata (prompt, generation date, file paths) in the database.\n",
        "# - Serving: Provide endpoints in the backend to serve the generated video and audio files to the frontend for playback or download. This could involve direct file serving or generating signed URLs for cloud storage.\n",
        "\n",
        "print(\"Planned storage and serving of content: Store files on server/cloud storage, store metadata in database, provide backend endpoints for serving.\")\n",
        "\n",
        "# 6. Consider user interface requirements:\n",
        "# - Prompt Input: A text area or input field for users to enter their content prompts.\n",
        "# - Options: Potentially include options for language selection, video length preferences, or image style preferences.\n",
        "# - Loading Indicator: Provide visual feedback while content is being generated (which can take time).\n",
        "# - Content Display: An area to display the generated text, and a video player to play the generated video.\n",
        "# - Download Options: Buttons to download the generated audio and video files.\n",
        "\n",
        "print(\"Considered user interface requirements: Prompt input, options, loading indicator, content display, download options.\")\n",
        "\n",
        "# 7. Outline a basic architecture diagram/description:\n",
        "# - User (Frontend): Interacts with the web interface (React).\n",
        "# - Backend (Flask): Receives requests from the frontend.\n",
        "# - Google Authentication Service: Handles user sign-in flow initiated by the frontend and verified by the backend.\n",
        "# - Database (PostgreSQL): Stores user data and generated content metadata.\n",
        "# - Content Generation Components (Integrated in Backend):\n",
        "#     - Gemini API: Text generation.\n",
        "#     - gTTS: Text-to-speech.\n",
        "#     - MoviePy: Video creation.\n",
        "# - Storage (File System/Cloud Storage): Stores generated audio and video files.\n",
        "\n",
        "# Flow:\n",
        "# 1. User signs in via Google (Frontend -> Google Auth -> Frontend -> Backend).\n",
        "# 2. Backend verifies user and manages session.\n",
        "# 3. User submits prompt (Frontend -> Backend).\n",
        "# 4. Backend calls Gemini API for text (Backend -> Gemini API).\n",
        "# 5. Backend calls gTTS for audio (Backend -> gTTS).\n",
        "# 6. Backend uses MoviePy and potentially image sourcing to create video (Backend -> MoviePy/Image Source).\n",
        "# 7. Backend stores generated files and metadata (Backend -> Storage, Backend -> Database).\n",
        "# 8. Backend sends metadata/file paths to Frontend (Backend -> Frontend).\n",
        "# 9. Frontend displays content and provides download links (Frontend -> User).\n",
        "\n",
        "print(\"Outlined basic architecture and flow.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0825d68"
      },
      "source": [
        "## Implement web application (frontend and backend)\n",
        "\n",
        "### Subtask:\n",
        "Develop the user interface and the server-side logic for the web application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "662288a2"
      },
      "source": [
        "**Reasoning**:\n",
        "Set up the basic Flask project structure and a simple React project structure for the frontend to begin implementing the web application as outlined in the plan.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e376fd23",
        "outputId": "d68b8b84-81e9-48b5-f7d1-752b3bfbe0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outlined Flask backend and React frontend project structures.\n",
            "To proceed, manually create these files and directories, then install dependencies:\n",
            "Backend: pip install -r backend/requirements.txt\n",
            "Frontend: cd frontend && npm install\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Set up a new Flask project for the backend.\n",
        "# This requires creating a directory structure and basic Flask app files.\n",
        "# We cannot execute shell commands to create directories and files directly here,\n",
        "# but we can outline the required structure and minimal content for a Flask app.\n",
        "\n",
        "# Project Directory: ai-content-mvp\n",
        "#   - backend/\n",
        "#     - app.py       # Main Flask application file\n",
        "#     - requirements.txt # List of Python dependencies (Flask, google-auth, etc.)\n",
        "#   - frontend/\n",
        "#     - public/      # Static assets\n",
        "#     - src/         # React source files\n",
        "#       - App.js     # Main App component\n",
        "#       - index.js   # Entry point\n",
        "#     - package.json # Node.js package file (React dependencies)\n",
        "\n",
        "# Minimal backend/app.py content:\n",
        "# from flask import Flask\n",
        "# app = Flask(__name__)\n",
        "# @app.route('/')\n",
        "# def index():\n",
        "#     return 'Flask backend is running!'\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(debug=True)\n",
        "\n",
        "# Minimal backend/requirements.txt content:\n",
        "# Flask\n",
        "# google-auth # For Google token verification later\n",
        "\n",
        "# Minimal frontend/src/index.js content:\n",
        "# import React from 'react';\n",
        "# import ReactDOM from 'react-dom/client';\n",
        "# import App from './App';\n",
        "# const root = ReactDOM.createRoot(document.getElementById('root'));\n",
        "# root.render(<React.StrictMode><App /></React.StrictMode>);\n",
        "\n",
        "# Minimal frontend/src/App.js content:\n",
        "# import React from 'react';\n",
        "# function App() {\n",
        "#   return (\n",
        "#     <div>\n",
        "#       <h1>AI Content MVP Frontend</h1>\n",
        "#     </div>\n",
        "#   );\n",
        "# }\n",
        "# export default App;\n",
        "\n",
        "# Minimal frontend/package.json content (requires manual creation or using create-react-app):\n",
        "# {\n",
        "#   \"name\": \"frontend\",\n",
        "#   \"version\": \"0.1.0\",\n",
        "#   \"private\": true,\n",
        "#   \"dependencies\": {\n",
        "#     \"react\": \"^18.2.0\",\n",
        "#     \"react-dom\": \"^18.2.0\",\n",
        "#     \"react-scripts\": \"5.0.1\"\n",
        "#   },\n",
        "#   \"scripts\": {\n",
        "#     \"start\": \"react-scripts start\",\n",
        "#     \"build\": \"react-scripts build\"\n",
        "#   },\n",
        "#   \"browserslist\": {\n",
        "#     \"production\": [\">0.2%\", \"not dead\", \"not op_mini all\"],\n",
        "#     \"development\": [\"last 1 chrome version\", \"last 1 firefox version\", \"last 1 safari version\"]\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# Step 2: Create the basic structure for the frontend using React.\n",
        "# This is typically done using create-react-app or similar tools.\n",
        "# We can simulate this by outlining the necessary files as shown above.\n",
        "\n",
        "print(\"Outlined Flask backend and React frontend project structures.\")\n",
        "print(\"To proceed, manually create these files and directories, then install dependencies:\")\n",
        "print(\"Backend: pip install -r backend/requirements.txt\")\n",
        "print(\"Frontend: cd frontend && npm install\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40cc69dc"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the Google Sign-In flow on the frontend and create a corresponding backend endpoint to receive the token, fulfilling steps 3 and 4 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f3b6f36",
        "outputId": "269c75bf-9099-4798-9210-92df9cc624ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: ImageMagick binary not found at /usr/bin/convert. Text overlay might fail.\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Implement the Google Sign-In flow on the frontend.\n",
        "# This requires adding a Google Sign-In button to the React frontend and handling the response.\n",
        "# We'll use the `@react-oauth/google` library as it's a modern approach.\n",
        "\n",
        "# Frontend (frontend/src/App.js - conceptual addition):\n",
        "# import React from 'react';\n",
        "# import { GoogleOAuthProvider, GoogleLogin } from '@react-oauth/google';\n",
        "\n",
        "# function App() {\n",
        "#   const handleSuccess = (credentialResponse) => {\n",
        "#     console.log(credentialResponse);\n",
        "#     // Send the credentialResponse.credential (ID token) to the backend\n",
        "#     fetch('/api/google-signin', {\n",
        "#       method: 'POST',\n",
        "#       headers: {\n",
        "#         'Content-Type': 'application/json',\n",
        "#       },\n",
        "#       body: JSON.stringify({ id_token: credentialResponse.credential }),\n",
        "#     })\n",
        "#     .then(response => response.json())\n",
        "#     .then(data => console.log('Backend response:', data))\n",
        "#     .catch((error) => console.error('Error sending token to backend:', error));\n",
        "#   };\n",
        "\n",
        "#   const handleError = () => {\n",
        "#     console.log('Login Failed');\n",
        "#   };\n",
        "\n",
        "#   return (\n",
        "#     <GoogleOAuthProvider clientId=\"YOUR_GOOGLE_CLIENT_ID\"> {/* Replace with your Client ID */}\n",
        "#       <div>\n",
        "#         <h1>AI Content MVP Frontend</h1>\n",
        "#         <GoogleLogin\n",
        "#           onSuccess={handleSuccess}\n",
        "#           onError={handleError}\n",
        "#         />\n",
        "#       </div>\n",
        "#     </GoogleOAuthProvider>\n",
        "#   );\n",
        "# }\n",
        "\n",
        "# export default App;\n",
        "\n",
        "# Frontend (frontend/src/index.js - wrap with GoogleOAuthProvider):\n",
        "# import React from 'react';\n",
        "# import ReactDOM from 'react-dom/client';\n",
        "# import App from './App';\n",
        "# import { GoogleOAuthProvider } from '@react-oauth/google'; // Import here\n",
        "\n",
        "# const root = ReactDOM.createRoot(document.getElementById('root'));\n",
        "# root.render(\n",
        "#   <React.StrictMode>\n",
        "#     {/* Wrap App with GoogleOAuthProvider */}\n",
        "#     <GoogleOAuthProvider clientId=\"YOUR_GOOGLE_CLIENT_ID\"> {/* Replace with your Client ID */}\n",
        "#       <App />\n",
        "#     </GoogleOAuthProvider>\n",
        "#   </React.StrictMode>\n",
        "# );\n",
        "\n",
        "\n",
        "# Step 4: Create a backend endpoint in Flask to receive and verify the Google authentication token.\n",
        "# This requires adding a new route to the Flask app.\n",
        "\n",
        "# Backend (backend/app.py - conceptual addition):\n",
        "from flask import Flask, request, jsonify, send_file # Import send_file for serving files\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import os\n",
        "from flask_ngrok import run_with_ngrok # Import run_with_ngrok\n",
        "\n",
        "# Import libraries for content generation\n",
        "from google import genai\n",
        "from gtts import gTTS\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip, TextClip, CompositeVideoClip, concatenate_audioclips\n",
        "from moviepy.video.fx.all import fadein, fadeout\n",
        "import moviepy.config as mp_config\n",
        "import requests\n",
        "import json\n",
        "import re # For robust JSON parsing from model output\n",
        "import time # Import time for unique filenames\n",
        "\n",
        "\n",
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app) # Run with ngrok\n",
        "\n",
        "# --- Configuration and API Key Setup (Backend) ---\n",
        "# It's best practice to load API keys from environment variables or a secure config file\n",
        "# in a real web application, not hardcoded.\n",
        "# For Colab demonstration, we used os.environ.get or direct assignment.\n",
        "# In a deployed app, use proper environment variable loading.\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "UNSPLASH_ACCESS_KEY = os.environ.get(\"UNSPLASH_ACCESS_KEY\") # Load Unsplash Key as well\n",
        "\n",
        "# Initialize GenAI client\n",
        "# Initialize GenAI client only if GEMINI_API_KEY is available\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing GenAI client: {e}\")\n",
        "        # In a real app, you might handle this differently, but for this example,\n",
        "        # we'll print and allow the app to run, but API calls will fail.\n",
        "        genai_client = None\n",
        "else:\n",
        "     print(\"Warning: GEMINI_API_KEY is not set. Content generation will fail.\")\n",
        "     genai_client = None\n",
        "\n",
        "\n",
        "# Set ImageMagick path (needed for TextClip, but potentially problematic as seen)\n",
        "# Note: Text overlay is still commented out due to previous issues,\n",
        "# but the ImageMagick path setting remains as part of the original integration attempt.\n",
        "IMAGEMAGICK_PATH = '/usr/bin/convert' # Or the path found in your environment\n",
        "if os.path.exists(IMAGEMAGICK_PATH):\n",
        "    mp_config.change_settings({\"IMAGEMAGICK_BINARY\": IMAGEMAGICK_PATH})\n",
        "    print(f\"Set ImageMagick binary path to: {IMAGEMAGICK_PATH}\")\n",
        "else:\n",
        "    print(f\"Warning: ImageMagick binary not found at {IMAGEMAGICK_PATH}. Text overlay might fail.\")\n",
        "\n",
        "\n",
        "# Function to search Unsplash images (moved here from previous cell for integration)\n",
        "def search_unsplash_images(query, access_key, count):\n",
        "    url = f\"https://api.unsplash.com/search/photos\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Client-ID {access_key}\"\n",
        "    }\n",
        "    params = {\n",
        "        \"query\": query,\n",
        "        \"per_page\": count,\n",
        "        \"orientation\": \"landscape\" # Get landscape images suitable for video\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, params=params)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "        results = response.json() # Parse the JSON response into a dictionary\n",
        "        return results.get(\"results\", []) # Now call .get() on the dictionary\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching images from Unsplash: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- Google Sign-In Endpoint ---\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Specify the CLIENT_ID of the app that accesses the backend:\n",
        "        # In a real app, GOOGLE_CLIENT_ID should be set as an environment variable\n",
        "        google_client_id = os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "        if not google_client_id:\n",
        "            return jsonify({\"error\": \"GOOGLE_CLIENT_ID is not set on the backend\"}), 500\n",
        "\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), google_client_id)\n",
        "\n",
        "        # ID token is valid. Get the user's Google Account ID from the decoded token.\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '') # Get name if available\n",
        "\n",
        "        # Here you would typically:\n",
        "        # 1. Check if the user exists in your database based on `userid` or `email`.\n",
        "        # 2. If user exists, load their session/data.\n",
        "        # 3. If user does not exist, create a new user record in the database.\n",
        "        # 4. Establish a server-side session for the user (e.g., using Flask sessions).\n",
        "\n",
        "        # For this step, we'll just return the verified user info as confirmation\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\n",
        "                \"id\": userid,\n",
        "                \"email\": email,\n",
        "                \"name\": name\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except ValueError:\n",
        "        # Invalid token\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        # Other errors during verification\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "# --- Content Generation Endpoint (Integrated Logic) ---\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "# In a real app, you might add @login_required or similar decorator for authentication\n",
        "def generate_content_endpoint(): # Renamed to avoid conflict with function name\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "\n",
        "    # In a real application, you would authenticate the user here based on session\n",
        "    # or a token sent with the prompt request after successful sign-in.\n",
        "\n",
        "    print(f\"Received prompt from frontend: {prompt}\") # Log the received prompt\n",
        "\n",
        "    # --- 1. Generate Multilingual Text (Gemini API) ---\n",
        "    if not genai_client:\n",
        "         return jsonify({\"error\": \"Gemini API client not initialized. GEMINI_API_KEY might be missing.\"}), 500\n",
        "\n",
        "    text_prompt = f\"\"\"\n",
        "    You are a professional multilingual social media writer.\n",
        "    Produce a short motivational Instagram caption about depression and sadness, related to the user's prompt: \"{prompt}\"\n",
        "    Return EXACTLY a JSON object (no extra text) with keys:\n",
        "    {{\n",
        "      \"en\": \"<English caption (30-40 words)>\",\n",
        "      \"ar\": \"<Arabic caption>\",\n",
        "      \"am\": \"<Amharic caption>\"\n",
        "    }}\n",
        "    Make sure the values are plain strings and the entire response is valid JSON only.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Use the GenAI client\n",
        "        text_resp = genai_client.models.generate_content(\n",
        "            model=\"models/gemini-2.5-flash\", # Use gemini-2.5-flash for faster response\n",
        "            contents=text_prompt,\n",
        "            # max_output_tokens=300 # Adjust as needed\n",
        "        )\n",
        "        raw_text = text_resp.text.strip()\n",
        "\n",
        "        # Robustly parse JSON from the model output\n",
        "        text_data = None\n",
        "        try:\n",
        "            text_data = json.loads(raw_text)\n",
        "        except Exception:\n",
        "            m = re.search(r\"(\\{[\\s\\S]*\\})\", raw_text)\n",
        "            if m:\n",
        "                try:\n",
        "                    text_data = json.loads(m.group(1))\n",
        "                except Exception:\n",
        "                    pass # JSON parsing failed even with fallback\n",
        "            if not text_data:\n",
        "                 print(\"Warning: Failed to parse JSON from model output.\")\n",
        "                 print(\"Raw model output:\", raw_text)\n",
        "                 return jsonify({\"error\": \"Failed to generate and parse text content\"}), 500\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating text content: {e}\")\n",
        "        return jsonify({\"error\": f\"Error generating text content: {e}\"}), 500\n",
        "\n",
        "    english_caption = text_data.get('en', '')\n",
        "    if not english_caption:\n",
        "         return jsonify({\"error\": \"Generated English caption is empty\"}), 500\n",
        "\n",
        "\n",
        "    # --- 2. Generate Audio (gTTS) ---\n",
        "    # Generate a unique filename for the audio to avoid conflicts in a web app\n",
        "    audio_filename = f\"tts_en_{int(time.time())}.mp3\" # Use timestamp for uniqueness\n",
        "    audio_file_path = os.path.join(\"outputs\", audio_filename) # Save English audio for video\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "    audio_clip = None # Initialize audio_clip to None\n",
        "    try:\n",
        "        tts = gTTS(english_caption, lang='en')\n",
        "        tts.save(audio_file_path)\n",
        "        print(\"Saved audio:\", audio_file_path)\n",
        "        audio_clip = AudioFileClip(audio_file_path) # Load audio clip\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating audio: {e}\")\n",
        "        print(\"Warning: Proceeding without audio.\")\n",
        "\n",
        "\n",
        "    # --- 3. Fetch Images (Unsplash API) ---\n",
        "    IMAGE_COUNT = 5  # Number of images for video\n",
        "    VIDEO_DURATION_PER_IMAGE = 8 # Duration per image segment\n",
        "    IMAGE_DOWNLOAD_DIR = \"downloaded_images\"\n",
        "    os.makedirs(IMAGE_DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "    downloaded_image_paths = []\n",
        "    if not UNSPLASH_ACCESS_KEY or UNSPLASH_ACCESS_KEY == \"YOUR_UNSPLASH_ACCESS_KEY\":\n",
        "        print(\"Warning: Unsplash Access Key is not set. Skipping image fetching.\")\n",
        "        # Fallback to sample image if key is not set\n",
        "        sample_img_path = \"assets/sample.jpg\" # Assume sample.jpg exists or handle download\n",
        "        if os.path.exists(sample_img_path):\n",
        "             downloaded_image_paths.extend([sample_img_path] * IMAGE_COUNT) # Use sample image multiple times\n",
        "             print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "        else:\n",
        "            print(f\"Error: Sample image not found at {sample_img_path}. Cannot create video without images.\")\n",
        "            return jsonify({\"error\": \"Unsplash key not set and sample image not found\"}), 500\n",
        "    else:\n",
        "        # Use a keyword from the generated text as search query (e.g., first few words or extracted keywords)\n",
        "        # For simplicity, use a broader query or part of the generated text.\n",
        "        img_search_query = \"motivational OR hope OR mental health\" # Example: Use broader keywords\n",
        "        # Alternatively, use a part of the generated caption:\n",
        "        # img_search_query = \" \".join(english_caption.split()[:5]) # First 5 words as query\n",
        "\n",
        "        image_results = search_unsplash_images(img_search_query, UNSPLASH_ACCESS_KEY, IMAGE_COUNT)\n",
        "        if image_results:\n",
        "            print(f\"Found {len(image_results)} images. Downloading...\")\n",
        "            for i, img_info in enumerate(image_results):\n",
        "                img_url = img_info.get(\"urls\", {}).get(\"regular\") # Use 'regular' size\n",
        "                if img_url:\n",
        "                    try:\n",
        "                        img_response = requests.get(img_url, stream=True)\n",
        "                        img_response.raise_for_status()\n",
        "                        # Generate a unique filename for each image\n",
        "                        img_filename = f\"image_{i+1}_{int(time.time())}.jpg\" # Use timestamp for uniqueness\n",
        "                        file_path = os.path.join(IMAGE_DOWNLOAD_DIR, img_filename)\n",
        "                        with open(file_path, 'wb') as f:\n",
        "                            for chunk in img_response.iter_content(chunk_size=8192):\n",
        "                                f.write(chunk)\n",
        "                        downloaded_image_paths.append(file_path)\n",
        "                        print(f\"Downloaded: {file_path}\")\n",
        "                    except requests.exceptions.RequestException as e:\n",
        "                        print(f\"Error downloading image {img_url}: {e}\")\n",
        "                if len(downloaded_image_paths) >= IMAGE_COUNT: # Stop if we've downloaded enough\n",
        "                     break\n",
        "        else:\n",
        "            print(\"No images found from Unsplash.\")\n",
        "            # Fallback to sample image if Unsplash search fails\n",
        "            sample_img_path = \"assets/sample.jpg\"\n",
        "            if os.path.exists(sample_img_path):\n",
        "                 downloaded_image_paths.extend([sample_img_path] * IMAGE_COUNT)\n",
        "                 print(f\"Using {IMAGE_COUNT} copies of sample image as fallback.\")\n",
        "            else:\n",
        "                print(f\"Error: Sample image not found at {sample_img_path}. Cannot create video without images.\")\n",
        "                return jsonify({\"error\": \"Unsplash search failed and sample image not found\"}), 500\n",
        "\n",
        "\n",
        "    # --- 4. Create Video (MoviePy) ---\n",
        "    if not downloaded_image_paths:\n",
        "         return jsonify({\"error\": \"No images available to create video\"}), 500\n",
        "\n",
        "    print(\"Creating video with downloaded images and transitions...\")\n",
        "    image_clips = []\n",
        "    for img_path in downloaded_image_paths:\n",
        "        try:\n",
        "            clip = ImageClip(img_path).set_duration(VIDEO_DURATION_PER_IMAGE)\n",
        "            image_clips.append(clip)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not create ImageClip from {img_path}: {e}\")\n",
        "            # Continue with other images\n",
        "\n",
        "    # Filter out clips with duration 0 or None\n",
        "    valid_image_clips = [clip for clip in image_clips if clip.duration is not None and clip.duration > 0]\n",
        "\n",
        "    if not valid_image_clips:\n",
        "        print(\"Error: No valid image clips created after filtering.\")\n",
        "        return jsonify({\"error\": \"No valid image clips created for video\"}), 500\n",
        "\n",
        "    # Apply fade out to all clips except the last one\n",
        "    FADE_DURATION = 1.5 # Make sure FADE_DURATION is defined\n",
        "    clips_with_fade_out = [clip.fx(fadeout, duration=FADE_DURATION) for clip in valid_image_clips[:-1]]\n",
        "    # Apply fade in to all clips except the first one\n",
        "    clips_with_fade_in = [clip.fx(fadein, duration=FADE_DURATION) for clip in valid_image_clips[1:]]\n",
        "\n",
        "    # Concatenate clips with transitions\n",
        "    # The fade out of one clip overlaps with the fade in of the next\n",
        "    # Handle the case where there's only one valid clip\n",
        "    if len(valid_image_clips) > 1:\n",
        "        # Concatenate clips manually with overlaps for transitions:\n",
        "        clips_to_concat_with_transitions = []\n",
        "        for i in range(len(valid_image_clips)):\n",
        "            clip = valid_image_clips[i]\n",
        "            if i > 0:\n",
        "                # Apply fade in to all except the first\n",
        "                clip = clip.fx(fadein, duration=FADE_DURATION)\n",
        "            if i < len(valid_image_clips) - 1:\n",
        "                # Apply fade out to all except the last\n",
        "                clip = clip.fx(fadeout, duration=FADE_DURATION)\n",
        "            clips_to_concat_with_transitions.append(clip)\n",
        "\n",
        "        final_video_clip = concatenate_videoclips(clips_to_concat_with_transitions, method=\"compose\") # Use compose\n",
        "\n",
        "    else:\n",
        "         final_video_clip = valid_image_clips[0] # Only one clip, no concatenation needed\n",
        "\n",
        "\n",
        "    # Add Audio to Video\n",
        "    video_final = final_video_clip # Start with video clip\n",
        "\n",
        "    if audio_clip:\n",
        "        # Adjust audio duration to match the total video duration\n",
        "        if audio_clip.duration < video_final.duration:\n",
        "            num_loops = int(video_final.duration / audio_clip.duration) + 1\n",
        "            # Use concatenate_audioclips for audio looping\n",
        "            looped_audio = concatenate_audioclips([audio_clip] * num_loops)\n",
        "            audio_clip = looped_audio.subclip(0, video_final.duration) # Trim to video duration\n",
        "\n",
        "        elif audio_clip.duration > video_final.duration:\n",
        "             audio_clip = audio_clip.subclip(0, video_final.duration)\n",
        "\n",
        "        video_final = video_final.set_audio(audio_clip) # Set audio to the final video clip\n",
        "    else:\n",
        "        print(\"Warning: Audio clip is not available.\")\n",
        "\n",
        "\n",
        "    # Generate a unique filename for the output video\n",
        "    video_filename = f\"generated_reel_{int(time.time())}.mp4\" # Use timestamp for uniqueness\n",
        "    out_path = os.path.join(\"outputs\", video_filename) # Use a generic name for generated files\n",
        "    os.makedirs(\"outputs\", exist_ok=True) # Ensure outputs directory exists\n",
        "\n",
        "    try:\n",
        "        video_final.write_videofile(\n",
        "            out_path,\n",
        "            codec=\"libx264\",\n",
        "            audio_codec=\"aac\",\n",
        "            fps=24,\n",
        "            preset=\"medium\"\n",
        "        )\n",
        "        print(\"Saved generated reel:\", out_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing video file: {e}\")\n",
        "        return jsonify({\"error\": f\"Error creating video file: {e}\"}), 500\n",
        "\n",
        "\n",
        "    # --- 5. Store and Serve (Basic) ---\n",
        "    # In a real app, store file path and metadata in database,\n",
        "    # and provide a URL to access the file.\n",
        "    # For this example, we'll just return the path and other generated data.\n",
        "    # You'll need an endpoint to serve this file later.\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Content generated successfully\",\n",
        "        \"text_content\": text_data,\n",
        "        \"video_path\": out_path # Return the server path (for demonstration)\n",
        "    })\n",
        "\n",
        "\n",
        "# --- Endpoint to serve generated video files ---\n",
        "@app.route('/outputs/<filename>')\n",
        "def serve_video(filename):\n",
        "    file_path = os.path.join(\"outputs\", filename)\n",
        "    if os.path.exists(file_path):\n",
        "        return send_file(file_path, mimetype='video/mp4')\n",
        "    else:\n",
        "        return \"File not found\", 404\n",
        "\n",
        "\n",
        "# --- Optional: Root endpoint ---\n",
        "# @app.route('/')\n",
        "# def index():\n",
        "#     return 'Flask backend is running!'\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # When using run_with_ngrok(app), app.run() is not needed.\n",
        "    # It is handled internally by flask_ngrok.\n",
        "    pass # Keep this pass statement if the __name__ == '__main__' block is used but app.run() is commented out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c49ff274",
        "outputId": "49f8e2e7-0c93-42dc-dd96-c2a10602a4f5"
      },
      "source": [
        "# Install the pyngrok library\n",
        "!pip install pyngrok"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your ngrok auth token\n",
        "ngrok.set_auth_token(\"346kyB4fIW9CApGYeOL87vT6SP5_RbC9TNduKAprP7s8DtQP\")"
      ],
      "metadata": {
        "id": "Q-TB_2RNiNyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bef8f2e-ecff-4db4-8581-ea9e4ed5c55d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7d90e87",
        "outputId": "3ff7552e-ce04-49cc-e40e-0c5c9eb9a8a2"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Replace with the actual ngrok URL from the output of cell 1d1336d4\n",
        "# Ensure you include the https:// scheme.\n",
        "NGROK_URL = \"https://chorded-glendora-uninterpolative.ngrok-free.dev\" # Use the provided URL\n",
        "\n",
        "# The endpoint we want to test\n",
        "endpoint_url = f\"{NGROK_URL}/api/google-signin\"\n",
        "\n",
        "# A dummy ID token (replace with a more realistic-looking dummy token if needed)\n",
        "# Note: This dummy token will NOT be successfully verified by Google's API,\n",
        "# but it will allow us to test if the endpoint receives the request and attempts verification.\n",
        "dummy_id_token = \"dummy_token_replace_with_real_test_if_possible\" # Replace with a dummy token string\n",
        "\n",
        "# Prepare the data to send in the POST request body\n",
        "payload = {\n",
        "    \"id_token\": dummy_id_token\n",
        "}\n",
        "\n",
        "# Set the Content-Type header to application/json\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "print(f\"Sending POST request to: {endpoint_url}\")\n",
        "print(f\"Request body: {payload}\")\n",
        "\n",
        "try:\n",
        "    # Send the POST request\n",
        "    response = requests.post(endpoint_url, data=json.dumps(payload), headers=headers)\n",
        "\n",
        "    # Print the response status code and body\n",
        "    print(f\"\\nResponse Status Code: {response.status_code}\")\n",
        "    print(\"Response Body:\")\n",
        "    try:\n",
        "        display(response.json()) # Display JSON response if possible\n",
        "    except json.JSONDecodeError:\n",
        "        print(response.text) # Print raw text if not JSON\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"\\nError sending request: {e}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sending POST request to: https://chorded-glendora-uninterpolative.ngrok-free.dev/api/google-signin\n",
            "Request body: {'id_token': 'dummy_token_replace_with_real_test_if_possible'}\n",
            "\n",
            "Response Status Code: 404\n",
            "Response Body:\n",
            "\n",
            "Error sending request: Expecting value: line 1 column 1 (char 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "383724d6",
        "outputId": "c54ad901-d3e6-4567-811c-cafd49ec5ee1"
      },
      "source": [
        "# Set the GOOGLE_CLIENT_ID environment variable\n",
        "# Replace \"YOUR_GOOGLE_CLIENT_ID\" with your actual Google Client ID\n",
        "%env GOOGLE_CLIENT_ID=\"1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\"\n",
        "\n",
        "# You can verify it's set by running:\n",
        "# import os\n",
        "# print(os.environ.get(\"GOOGLE_CLIENT_ID\"))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_CLIENT_ID=\"1086263039327-kggbdi9mqdo191buc92vc7sa6h3ocpbs.apps.googleusercontent.com\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"Your public ngrok URL:\", public_url.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2p9tbP4iTY-",
        "outputId": "d62058cf-f976-4f53-8ef1-600b5340c5b4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your public ngrok URL: https://chorded-glendora-uninterpolative.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Start a tunnel\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\"Your ngrok URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OuT0DzmYaoH",
        "outputId": "e9bf3307-1ca6-49d1-b046-a81f8d3c8313"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your ngrok URL: NgrokTunnel: \"https://chorded-glendora-uninterpolative.ngrok-free.dev\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 346kyB4fIW9CApGYeOL87vT6SP5_RbC9TNduKAprP7s8DtQP"
      ],
      "metadata": {
        "id": "qGbiXbP4z4cL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91137541-c21a-4537-caaf-e23dbbd56d22"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27040ab1"
      },
      "source": [
        "**Reasoning**:\n",
        "Design the user interface for prompt input on the frontend and create a backend endpoint to receive these prompts, fulfilling steps 5 and 6 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "uJ1bYdFwOE6A"
      },
      "outputs": [],
      "source": [
        "# Step 5: Design and implement the user interface for prompt input on the frontend.\n",
        "# This involves adding a textarea or input field and a submit button to the React component.\n",
        "\n",
        "# Frontend (frontend/src/App.js - conceptual addition):\n",
        "# import React, { useState } from 'react'; // Import useState\n",
        "# import { GoogleOAuthProvider, GoogleLogin } from '@react-oauth/google'; // Keep existing imports\n",
        "\n",
        "# function App() {\n",
        "#   const [prompt, setPrompt] = useState(''); // State to hold the prompt input\n",
        "#   const [responseMessage, setResponseMessage] = useState(''); // State to display backend response\n",
        "\n",
        "#   // Keep handleSuccess and handleError for Google Sign-In\n",
        "\n",
        "#   const handlePromptChange = (event) => {\n",
        "#     setPrompt(event.target.value);\n",
        "#   };\n",
        "\n",
        "#   const handleSubmitPrompt = () => {\n",
        "#     // Send the prompt to the backend\n",
        "#     fetch('/api/generate-content', { // New endpoint for content generation\n",
        "#\n",
        "#     method: 'POST',\n",
        "#       headers: {\n",
        "#         'Content-Type': 'application/json',\n",
        "#       },\n",
        "#       body: JSON.stringify({ prompt: prompt }),\n",
        "#     })\n",
        "#     .then(response => response.json())\n",
        "#     .then(data => {\n",
        "#       console.log('Backend response for prompt:', data);\n",
        "#       setResponseMessage(data.message || data.error || JSON.stringify(data)); // Display confirmation\n",
        "#     })\n",
        "#     .catch((error) => {\n",
        "#       console.error('Error sending prompt to backend:', error);\n",
        "#       setResponseMessage(`Error: ${error.message}`);\n",
        "#     });\n",
        "#   };\n",
        "\n",
        "#   return (\n",
        "#     <GoogleOAuthProvider clientId=\"YOUR_GOOGLE_CLIENT_ID\"> {/* Replace with your Client ID */}\n",
        "#       <div>\n",
        "#         <h1>AI Content MVP Frontend</h1>\n",
        "#         <GoogleLogin\n",
        "#           onSuccess={handleSuccess}\n",
        "#           onError={handleError}\n",
        "#         />\n",
        "\n",
        "#         {/* Prompt Input Section */}\n",
        "#         <h2>Generate Content</h2>\n",
        "#         <textarea\n",
        "#           rows=\"4\"\n",
        "#           cols=\"50\"\n",
        "#           placeholder=\"Enter your prompt here...\"\n",
        "#           value={prompt}\n",
        "#           onChange={handlePromptChange}\n",
        "#         />\n",
        "#         <br />\n",
        "#         <button onClick={handleSubmitPrompt}>Generate</button>\n",
        "\n",
        "#         {/* Display Backend Response */}\n",
        "#         {responseMessage && (\n",
        "#           <div>\n",
        "#             <h3>Backend Confirmation:</h3>\n",
        "#             <p>{responseMessage}</p>\n",
        "#           </div>\n",
        "#         )}\n",
        "\n",
        "#       </div>\n",
        "#     </GoogleOAuthProvider>\n",
        "#   );\n",
        "# }\n",
        "\n",
        "# export default App;\n",
        "\n",
        "\n",
        "# Step 6: Create a backend endpoint in Flask to receive prompts from the frontend.\n",
        "# This requires adding a new route to the Flask app.\n",
        "\n",
        "# Backend (backend/app.py - conceptual addition):\n",
        "from flask import request, jsonify\n",
        "# Keep existing imports (Flask, id_token, google_requests, os)\n",
        "\n",
        "# Keep existing routes (/ and /api/google-signin)\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "\n",
        "    # Step 7: Implement the basic backend logic to process the received prompt\n",
        "    # (without integrating the content generation APIs yet),\n",
        "    # perhaps just echoing the prompt back to the frontend as a confirmation.\n",
        "\n",
        "    # In a real application, you would authenticate the user here based on session\n",
        "    # or a token sent with the prompt request after successful sign-in.\n",
        "\n",
        "    print(f\"Received prompt from frontend: {prompt}\") # Log the received prompt\n",
        "\n",
        "    # Echo the prompt back as a confirmation\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Prompt received successfully\",\n",
        "        \"received_prompt\": prompt\n",
        "    })\n",
        "\n",
        "# Keep the if __name__ == '__main__': block for running the app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9abacbf9"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import os\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Run with ngrok\n",
        "\n",
        "# Get the GOOGLE_CLIENT_ID environment variable set by a previous cell\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\")\n",
        "\n",
        "# Check if the GOOGLE_CLIENT_ID is set. If not, token verification will fail later.\n",
        "if not GOOGLE_CLIENT_ID:\n",
        "    print(\"Warning: GOOGLE_CLIENT_ID environment variable is not set. Google Sign-In verification will fail.\")\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return 'Flask backend is running!'\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Specify the CLIENT_ID of the app that accesses the backend:\n",
        "        # Use the GOOGLE_CLIENT_ID obtained from environment variables\n",
        "        if not GOOGLE_CLIENT_ID:\n",
        "             # This case should be caught by the warning at the top,\n",
        "             # but returning an error here provides a more direct response\n",
        "             # if the environment variable wasn't set.\n",
        "             return jsonify({\"error\": \"GOOGLE_CLIENT_ID is not set on the backend\"}), 500\n",
        "\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), GOOGLE_CLIENT_ID)\n",
        "\n",
        "        # ID token is valid. Get the user's Google Account ID from the decoded token.\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '') # Get name if available\n",
        "\n",
        "        # Here you would typically:\n",
        "        # 1. Check if the user exists in your database based on `userid` or `email`.\n",
        "        # 2. If user exists, load their session/data.\n",
        "        # 3. If user does not exist, create a new user record in the database.\n",
        "        # 4. Establish a server-side session for the user (e.g., using Flask sessions).\n",
        "\n",
        "        # For this step, we'll just return the verified user info as confirmation\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\n",
        "                \"id\": userid,\n",
        "                \"email\": email,\n",
        "                \"name\": name\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except ValueError:\n",
        "        # Invalid token\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        # Other errors during verification\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    # Get the prompt from the request JSON body\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "\n",
        "    # In a real application, you would authenticate the user here based on session\n",
        "    # or a token sent with the prompt request after successful sign-in.\n",
        "\n",
        "    print(f\"Received prompt from frontend: {prompt}\") # Log the received prompt\n",
        "\n",
        "    # Echo the prompt back as a confirmation (for now, actual generation will be added later)\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Prompt received successfully\",\n",
        "        \"received_prompt\": prompt\n",
        "    })\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # When using run_with_ngrok(app), app.run() is not needed.\n",
        "    # It is handled internally by flask_ngrok.\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66add142"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `app` object was not defined in the code block. I need to include the Flask app initialization from the conceptual code in the previous step to fix this error and continue with implementing the prompt endpoint and confirmation display.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8dQ6H6B8OSuE"
      },
      "outputs": [],
      "source": [
        "# Step 6: Create a backend endpoint in Flask to receive prompts from the frontend.\n",
        "# Step 7: Implement the basic backend logic to process the received prompt\n",
        "# (without integrating the content generation APIs yet),\n",
        "# perhaps just echoing the prompt back to the frontend as a confirmation.\n",
        "# Step 8: Display the confirmation of the received prompt on the frontend.\n",
        "\n",
        "# Backend (backend/app.py - complete code with previous steps and the new endpoint):\n",
        "from flask import Flask, request, jsonify\n",
        "from google.oauth2 import id_token\n",
        "from google.auth.transport import requests as google_requests\n",
        "import os\n",
        "# Import flask_ngrok to run the app in Colab\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "\n",
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "# Run the app with ngrok in Colab\n",
        "run_with_ngrok(app)\n",
        "\n",
        "\n",
        "# In a real app, use environment variables or a config file for the client ID\n",
        "GOOGLE_CLIENT_ID = os.environ.get(\"GOOGLE_CLIENT_ID\") # Make sure to set this env var\n",
        "if not GOOGLE_CLIENT_ID:\n",
        "    print(\"Warning: GOOGLE_CLIENT_ID environment variable is not set. Google Sign-In verification will fail.\")\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return 'Flask backend is running!'\n",
        "\n",
        "@app.route('/api/google-signin', methods=['POST'])\n",
        "def google_signin():\n",
        "    token = request.json.get('id_token')\n",
        "    if not token:\n",
        "        return jsonify({\"error\": \"ID token not provided\"}), 400\n",
        "\n",
        "    try:\n",
        "        # Specify the CLIENT_ID of the app that accesses the backend:\n",
        "        if not GOOGLE_CLIENT_ID:\n",
        "             return jsonify({\"error\": \"GOOGLE_CLIENT_ID is not set on the backend\"}), 500\n",
        "\n",
        "        idinfo = id_token.verify_oauth2_token(token, google_requests.Request(), GOOGLE_CLIENT_ID)\n",
        "\n",
        "        # ID token is valid. Get the user's Google Account ID from the decoded token.\n",
        "        userid = idinfo['sub']\n",
        "        email = idinfo['email']\n",
        "        name = idinfo.get('name', '') # Get name if available\n",
        "\n",
        "        # Here you would typically:\n",
        "        # 1. Check if the user exists in your database based on `userid` or `email`.\n",
        "        # 2. If user exists, load their session/data.\n",
        "        # 3. If user does not exist, create a new user record in the database.\n",
        "        # 4. Establish a server-side session for the user (e.g., using Flask sessions).\n",
        "\n",
        "        # For this step, we'll just return the verified user info as confirmation\n",
        "        return jsonify({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Google token verified\",\n",
        "            \"user\": {\n",
        "                \"id\": userid,\n",
        "                \"email\": email,\n",
        "                \"name\": name\n",
        "            }\n",
        "        })\n",
        "\n",
        "    except ValueError:\n",
        "        # Invalid token\n",
        "        return jsonify({\"error\": \"Invalid Google token\"}), 401\n",
        "    except Exception as e:\n",
        "        # Other errors during verification\n",
        "        return jsonify({\"error\": f\"Token verification failed: {e}\"}), 500\n",
        "\n",
        "\n",
        "@app.route('/api/generate-content', methods=['POST'])\n",
        "def generate_content():\n",
        "    prompt = request.json.get('prompt')\n",
        "    if not prompt:\n",
        "        return jsonify({\"error\": \"Prompt not provided\"}), 400\n",
        "\n",
        "    # Step 7: Implement the basic backend logic to process the received prompt\n",
        "    # (without integrating the content generation APIs yet),\n",
        "    # perhaps just echoing the prompt back to the frontend as a confirmation.\n",
        "\n",
        "    # In a real application, you would authenticate the user here based on session\n",
        "    # or a token sent with the prompt request after successful sign-in.\n",
        "\n",
        "    print(f\"Received prompt from frontend: {prompt}\") # Log the received prompt\n",
        "\n",
        "    # Echo the prompt back as a confirmation\n",
        "    return jsonify({\n",
        "        \"status\": \"success\",\n",
        "        \"message\": \"Prompt received successfully\",\n",
        "        \"received_prompt\": prompt\n",
        "    })\n",
        "\n",
        "\n",
        "# Frontend (frontend/src/App.js - conceptual addition for Step 8):\n",
        "# This was already included in the previous conceptual frontend code\n",
        "# with the `responseMessage` state and the section to display it.\n",
        "# The fetch call in `handleSubmitPrompt` sets this state with the backend's response.\n",
        "\n",
        "# ... (previous imports and Google Sign-In code)\n",
        "\n",
        "# function App() {\n",
        "#   const [prompt, setPrompt] = useState(''); # State to hold the prompt input\n",
        "#   const [responseMessage, setResponseMessage] = useState(''); # State to display backend response\n",
        "#   # ... (handleSuccess and handleError)\n",
        "\n",
        "#   const handlePromptChange = (event) => {\n",
        "#     setPrompt(event.target.value);\n",
        "#   };\n",
        "\n",
        "#   const handleSubmitPrompt = () => {\n",
        "#     fetch('/api/generate-content', {\n",
        "#       method: 'POST',\n",
        "#       headers: {\n",
        "#         'Content-Type': 'application/json',\n",
        "#       },\n",
        "#       body: JSON.stringify({ prompt: prompt }),\n",
        "#     })\n",
        "#     .then(response => response.json())\n",
        "#     .then(data => {\n",
        "#       console.log('Backend response for prompt:', data);\n",
        "#       setResponseMessage(data.message || data.error || JSON.stringify(data)); # Display confirmation\n",
        "#     })\n",
        "#     .catch((error) => {\n",
        "#       console.error('Error sending prompt to backend:', error);\n",
        "#       setResponseMessage(f'Error: {error.message}');\n",
        "#     });\n",
        "#   };\n",
        "\n",
        "#   return (\n",
        "#     <GoogleOAuthProvider clientId=\"YOUR_GOOGLE_CLIENT_ID\">\n",
        "#       <div>\n",
        "#         <h1>AI Content MVP Frontend</h1>\n",
        "#         <GoogleLogin\n",
        "#           onSuccess={handleSuccess}\n",
        "#           onError={handleError}\n",
        "#         />\n",
        "\n",
        "#         <h2>Generate Content</h2>\n",
        "#         <textarea\n",
        "#           rows=\"4\"\n",
        "#           cols=\"50\"\n",
        "#           placeholder=\"Enter your prompt here...\"\n",
        "#           value={prompt}\n",
        "#           onChange={handlePromptChange}\n",
        "#         />\n",
        "#         <br />\n",
        "#         <button onClick={handleSubmitPrompt}>Generate</button>\n",
        "\n",
        "#         # Display Backend Response\n",
        "#         {responseMessage && (\n",
        "#           <div>\n",
        "#             <h3>Backend Confirmation:</h3>\n",
        "#             <p>{responseMessage}</p>\n",
        "#           </div>\n",
        "#         )}\n",
        "\n",
        "#       </div>\n",
        "#     </GoogleOAuthProvider>\n",
        "#   );\n",
        "# }\n",
        "\n",
        "# export default App;\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # When using run_with_ngrok(app), app.run() is not needed.\n",
        "    # It is handled internally by flask_ngrok.\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3820b1f"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the steps for deploying the web application, fulfilling step 7 of the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2eb04ce",
        "outputId": "61890794-6947-4553-d63f-5ec3ac00f38f"
      },
      "source": [
        "# Step 10: Deployment\n",
        "# This step is conceptual and cannot be executed directly in Colab.\n",
        "# Deploying a web application involves making it accessible to users over the internet.\n",
        "\n",
        "print(\"Outlining deployment steps:\")\n",
        "\n",
        "# 1. Choose a hosting platform:\n",
        "#    - Cloud Platforms: Google Cloud Platform (App Engine, Cloud Run, Kubernetes Engine), AWS (Elastic Beanstalk, ECS, EC2), Azure (App Service, Kubernetes Service), Heroku, Render, etc.\n",
        "#    - Virtual Private Servers (VPS): DigitalOcean, Linode, Vultr, etc. Requires more manual server management.\n",
        "\n",
        "print(\"  - Choose a hosting platform (Cloud Platform or VPS).\")\n",
        "\n",
        "# 2. Prepare for deployment:\n",
        "#    - Ensure all dependencies are listed in `requirements.txt` (Python backend) and `package.json` (Node.js frontend).\n",
        "#    - Configure environment variables for sensitive information (API keys, database credentials, Google Client ID/Secret).\n",
        "#    - Set up a production-ready WSGI server for Flask (e.g., Gunicorn, uWSGI).\n",
        "#    - Build the frontend for production (e.g., `npm run build` for React).\n",
        "\n",
        "print(\"  - Prepare dependencies and configuration.\")\n",
        "print(\"  - Set up a production-ready WSGI server (e.g., Gunicorn).\")\n",
        "print(\"  - Build the frontend for production.\")\n",
        "\n",
        "# 3. Database setup:\n",
        "#    - Provision a database instance on the hosting platform or a separate database service.\n",
        "#    - Configure the backend to connect to the production database.\n",
        "\n",
        "print(\"  - Set up a production database.\")\n",
        "\n",
        "# 4. Deployment process (Platform specific):\n",
        "#    - For Platform-as-a-Service (PaaS) like App Engine or Heroku: Often involves pushing code to a repository (e.g., Git) and the platform handles building and deploying.\n",
        "#    - For containerization (Docker, Kubernetes): Build Docker images for the frontend and backend and deploy them to a container orchestration service.\n",
        "#    - For VPS: Manually set up the server environment (install Python, Node.js, web server like Nginx/Apache), deploy code, configure the WSGI server, and set up a reverse proxy (Nginx/Apache) to serve the frontend and forward API requests to the backend.\n",
        "\n",
        "print(\"  - Follow platform-specific deployment steps.\")\n",
        "\n",
        "# 5. Configure domain and SSL:\n",
        "#    - Point your domain name to the deployed application.\n",
        "#    - Set up SSL/TLS certificates for secure HTTPS connections.\n",
        "\n",
        "print(\"  - Configure domain and SSL.\")\n",
        "\n",
        "# 6. Monitoring and logging:\n",
        "#    - Set up monitoring and logging to track application performance and errors.\n",
        "\n",
        "print(\"  - Set up monitoring and logging.\")\n",
        "\n",
        "# This outlines the general steps. The specific commands and configurations will vary significantly based on the chosen hosting platform and deployment method."
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outlining deployment steps:\n",
            "  - Choose a hosting platform (Cloud Platform or VPS).\n",
            "  - Prepare dependencies and configuration.\n",
            "  - Set up a production-ready WSGI server (e.g., Gunicorn).\n",
            "  - Build the frontend for production.\n",
            "  - Set up a production database.\n",
            "  - Follow platform-specific deployment steps.\n",
            "  - Configure domain and SSL.\n",
            "  - Set up monitoring and logging.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "196b6b3f"
      },
      "source": [
        "## Finish task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the work done and provide instructions on how to use the application or the updated video generation code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7a1cc73",
        "outputId": "4abf1cef-493f-44d9-d57b-0259086f8e36"
      },
      "source": [
        "# Step 11: Finish task.\n",
        "# This step is a summary and instruction phase.\n",
        "\n",
        "print(\"--- Task Summary ---\")\n",
        "print(\"We have successfully:\")\n",
        "print(\"- Outlined a plan for building a content generation web application.\")\n",
        "print(\"- Explored methods for creating longer videos with multiple images using MoviePy.\")\n",
        "print(\"- Implemented dynamic image fetching from Unsplash based on text content.\")\n",
        "print(\"- Added fade transitions between images in the video.\")\n",
        "print(\"- Integrated audio from generated speech into the video.\")\n",
        "print(\"- Outlined the core components, technology stack, Google Sign-In steps, and content generation integration for the web application backend.\")\n",
        "print(\"- Provided conceptual code snippets for the Flask backend and React frontend structure.\")\n",
        "print(\"- Outlined the steps for deploying the web application.\")\n",
        "\n",
        "print(\"\\n--- Next Steps / How to Use ---\")\n",
        "print(\"1.  **Video Generation (in Colab):**\")\n",
        "print(\"    - Ensure you have run Cell 1 (Install packages) and Cell 3 (Set GEMINI_API_KEY).\")\n",
        "print(\"    - Run Cell 5 (Structured multilingual generation) to generate the multilingual captions and ensure the 'data' variable is populated.\")\n",
        "print(\"    - Run Cell 6 (Convert captions to speech) to generate the audio files from the captions.\")\n",
        "print(\"    - **Crucially:** Update Cell cd7de905 (Image fetching and video creation) with your actual Unsplash Access Key.\")\n",
        "print(\"    - Run Cell cd7de905 (Image fetching and video creation) to generate the video with dynamic images, transitions, and audio.\")\n",
        "print(\"    - The generated video will be saved as outputs/reel_creative.mp4.\")\n",
        "print(\"    - Run Cells iryaIltg8HMu (Save metadata) and s3pD3PJ8_B-k (Copy to Drive) to save the output metadata and copy the outputs to Google Drive (if mounted).\")\n",
        "\n",
        "print(\"\\n2.  **Web Application Development:**\")\n",
        "print(\"    - Take the conceptual code snippets provided for the Flask backend and React frontend and assemble them into a standard web application project outside of this Colab notebook.\")\n",
        "print(\"    - Implement the remaining parts of the plan (database integration, full API integration in the backend, complete frontend UI).\")\n",
        "print(\"    - Obtain your Google API credentials for Google Sign-In.\")\n",
        "print(\"    - Set up environment variables for your API keys (Gemini, Unsplash) and Google Client ID/Secret in your development and deployment environment.\")\n",
        "print(\"    - Follow the outlined deployment steps to make your application accessible.\")\n",
        "\n",
        "print(\"\\nThis concludes the tasks we've worked on within this Colab notebook. You now have working code for generating videos with dynamic images and audio, and a clear plan and initial code structure for building the web application.\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task Summary ---\n",
            "We have successfully:\n",
            "- Outlined a plan for building a content generation web application.\n",
            "- Explored methods for creating longer videos with multiple images using MoviePy.\n",
            "- Implemented dynamic image fetching from Unsplash based on text content.\n",
            "- Added fade transitions between images in the video.\n",
            "- Integrated audio from generated speech into the video.\n",
            "- Outlined the core components, technology stack, Google Sign-In steps, and content generation integration for the web application backend.\n",
            "- Provided conceptual code snippets for the Flask backend and React frontend structure.\n",
            "- Outlined the steps for deploying the web application.\n",
            "\n",
            "--- Next Steps / How to Use ---\n",
            "1.  **Video Generation (in Colab):**\n",
            "    - Ensure you have run Cell 1 (Install packages) and Cell 3 (Set GEMINI_API_KEY).\n",
            "    - Run Cell 5 (Structured multilingual generation) to generate the multilingual captions and ensure the 'data' variable is populated.\n",
            "    - Run Cell 6 (Convert captions to speech) to generate the audio files from the captions.\n",
            "    - **Crucially:** Update Cell cd7de905 (Image fetching and video creation) with your actual Unsplash Access Key.\n",
            "    - Run Cell cd7de905 (Image fetching and video creation) to generate the video with dynamic images, transitions, and audio.\n",
            "    - The generated video will be saved as outputs/reel_creative.mp4.\n",
            "    - Run Cells iryaIltg8HMu (Save metadata) and s3pD3PJ8_B-k (Copy to Drive) to save the output metadata and copy the outputs to Google Drive (if mounted).\n",
            "\n",
            "2.  **Web Application Development:**\n",
            "    - Take the conceptual code snippets provided for the Flask backend and React frontend and assemble them into a standard web application project outside of this Colab notebook.\n",
            "    - Implement the remaining parts of the plan (database integration, full API integration in the backend, complete frontend UI).\n",
            "    - Obtain your Google API credentials for Google Sign-In.\n",
            "    - Set up environment variables for your API keys (Gemini, Unsplash) and Google Client ID/Secret in your development and deployment environment.\n",
            "    - Follow the outlined deployment steps to make your application accessible.\n",
            "\n",
            "This concludes the tasks we've worked on within this Colab notebook. You now have working code for generating videos with dynamic images and audio, and a clear plan and initial code structure for building the web application.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "051f3462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ab5133-c336-406c-96d8-1ccf1874a20b"
      },
      "source": [
        "# Create a dummy backend/main_multilang.py file\n",
        "!mkdir -p backend # Ensure backend directory exists\n",
        "# Escape the backslashes in the echo command\n",
        "!echo \"def generate_content(text):\\\\n    # Replace this with your actual content generation logic\\\\n    print(f'Generating content for: {text}')\\\\n    return f'Generated content for: {text}'\" > backend/main_multilang.py\n",
        "\n",
        "print(\"Created backend/main_multilang.py with a dummy generate_content function.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created backend/main_multilang.py with a dummy generate_content function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09a9d2af",
        "outputId": "126e4bb3-6b55-4761-a4e7-7d382a9d6cf9"
      },
      "source": [
        "# Overwrite backend/main_multilang.py with integrated Gemini API logic\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "import inspect\n",
        "\n",
        "# Ensure GEMINI_API_KEY is set as an environment variable\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "genai_client = None # Initialize to None\n",
        "\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        # Use the GenAI client class directly\n",
        "        genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing GenAI client: {e}\")\n",
        "\n",
        "\n",
        "def generate_content(text):\n",
        "    \"\"\"\n",
        "    Generates multilingual social media content using the Gemini API.\n",
        "\n",
        "    Args:\n",
        "        text: The input text prompt from the user.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing generated content in English, Arabic, and Amharic,\n",
        "        or an error message if generation fails.\n",
        "    \"\"\"\n",
        "    if not genai_client:\n",
        "        # Return a standard dictionary here\n",
        "        return {\"error\": \"Gemini API client not initialized. GEMINI_API_KEY might be missing.\"}\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional multilingual social media writer.\n",
        "    Produce a short motivational Instagram caption about depression and sadness, related to the user's prompt: \"{text}\"\n",
        "    Return EXACTLY a JSON object (no extra text) with keys:\n",
        "    {{\n",
        "      \"en\": \"<English caption (30-40 words)>\",\n",
        "      \"ar\": \"<Arabic caption>\",\n",
        "      \"am\": \"<Amharic caption>\"\n",
        "    }}\n",
        "    Make sure the values are plain strings and the entire response is valid JSON only.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Use the GenAI client to generate content\n",
        "        # Pass the prompt as a list\n",
        "        text_resp = genai_client.models.generate_content(\n",
        "            model=\"models/gemini-2.5-flash\", # Use gemini-2.5-flash for faster response\n",
        "            contents=[prompt], # Pass prompt as a list - CORRECTED\n",
        "            # max_output_tokens=300 # Adjust as needed\n",
        "        )\n",
        "        raw_text = text_resp.text.strip()\n",
        "\n",
        "        # Robustly parse JSON from the model output\n",
        "        text_data = None\n",
        "        try:\n",
        "            text_data = json.loads(raw_text)\n",
        "        except Exception:\n",
        "            # Fallback: try to locate JSON block inside the text if direct parsing fails\n",
        "            # Escape the backslashes in the regex pattern and use single curly braces for the regex group\n",
        "            m = re.search(r\"(\\{[\\s\\S]*\\})\", raw_text)\n",
        "            if m:\n",
        "                try:\n",
        "                    text_data = json.loads(m.group(1))\n",
        "                except Exception:\n",
        "                    pass # JSON parsing failed even with fallback\n",
        "            if not text_data:\n",
        "                 # Return a standard dictionary here\n",
        "                 return {\"error\": \"Failed to generate and parse text content\"}\n",
        "\n",
        "\n",
        "        return text_data\n",
        "\n",
        "    except Exception as e:\n",
        "        # Return a standard dictionary here\n",
        "        return {\"error\": f\"Error generating text content: {e}\"}\n",
        "\n",
        "\n",
        "# Write the updated content to the file by getting the source code of the function\n",
        "generate_content_source = inspect.getsource(generate_content)\n",
        "\n",
        "# Define the client initialization logic as a string\n",
        "client_init_logic = \"\"\"\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "import inspect # Import inspect here\n",
        "\n",
        "# Ensure GEMINI_API_KEY is set as an environment variable\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "genai_client = None # Initialize to None\n",
        "\n",
        "# Initialize GenAI client only if GEMINI_API_KEY is available\n",
        "if GEMINI_API_KEY:\n",
        "    try:\n",
        "        # Use the GenAI client class directly\n",
        "        genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing GenAI client: {e}\")\n",
        "else:\n",
        "    print(\"Warning: GEMINI_API_KEY is not set. Content generation will not work.\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Combine the client initialization logic and the function source code\n",
        "full_file_content = client_init_logic + generate_content_source\n",
        "\n",
        "\n",
        "with open(\"backend/main_multilang.py\", \"w\") as f:\n",
        "    f.write(full_file_content)\n",
        "\n",
        "print(\"Integrated Gemini API into backend/main_multilang.py\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error initializing GenAI client: module 'google.generativeai' has no attribute 'Client'\n",
            "Integrated Gemini API into backend/main_multilang.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === AUTO-SAVE NOTEBOOK AS .ipynb AND .py ===\n",
        "import os\n",
        "\n",
        "# âœ… 1. Set your notebook name (no extension)\n",
        "notebook_name = \"AI_Content_Multilang_MVP\"\n",
        "\n",
        "# âœ… 2. Define paths\n",
        "ipynb_path = f\"/content/{notebook_name}.ipynb\"\n",
        "drive_folder = \"/content/drive/MyDrive/AI_Content_MVP/\"\n",
        "os.makedirs(drive_folder, exist_ok=True)\n",
        "\n",
        "# âœ… 3. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# âœ… 4. Save .ipynb (full notebook)\n",
        "!jupyter nbconvert --to notebook \"{ipynb_path}\" --output \"{drive_folder}{notebook_name}.ipynb\"\n",
        "\n",
        "# âœ… 5. Save .py (code-only version)\n",
        "!jupyter nbconvert --to script \"{ipynb_path}\" --output \"{drive_folder}{notebook_name}.py\"\n",
        "\n",
        "print(\"âœ… Successfully saved Afro Content AI project in both formats.\")\n",
        "print(f\"ğŸ“‚ Folder: {drive_folder}\")\n",
        "print(f\"ğŸ“˜ Notebook: {notebook_name}.ipynb\")\n",
        "print(f\"ğŸ Script: {notebook_name}.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA3bgOc2wQhv",
        "outputId": "fad557f7-93ac-4f63-fb5a-cf144f1acd58"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[NbConvertApp] WARNING | pattern '/content/AI_Content_Multilang_MVP.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n",
            "[NbConvertApp] WARNING | pattern '/content/AI_Content_Multilang_MVP.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n",
            "âœ… Successfully saved Afro Content AI project in both formats.\n",
            "ğŸ“‚ Folder: /content/drive/MyDrive/AI_Content_MVP/\n",
            "ğŸ“˜ Notebook: AI_Content_Multilang_MVP.ipynb\n",
            "ğŸ Script: AI_Content_Multilang_MVP.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcacc047",
        "outputId": "4f8a1bc2-2687-4b89-e853-c3f797f814b7"
      },
      "source": [
        "!cat backend/main_multilang.py"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "import os\n",
            "import google.generativeai as genai\n",
            "import json\n",
            "import re\n",
            "import inspect # Import inspect here\n",
            "\n",
            "# Ensure GEMINI_API_KEY is set as an environment variable\n",
            "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
            "\n",
            "genai_client = None # Initialize to None\n",
            "\n",
            "# Initialize GenAI client only if GEMINI_API_KEY is available\n",
            "if GEMINI_API_KEY:\n",
            "    try:\n",
            "        # Use the GenAI client class directly\n",
            "        genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
            "    except Exception as e:\n",
            "        print(f\"Error initializing GenAI client: {e}\")\n",
            "else:\n",
            "    print(\"Warning: GEMINI_API_KEY is not set. Content generation will not work.\")\n",
            "\n",
            "def generate_content(text):\n",
            "    \"\"\"\n",
            "    Generates multilingual social media content using the Gemini API.\n",
            "\n",
            "    Args:\n",
            "        text: The input text prompt from the user.\n",
            "\n",
            "    Returns:\n",
            "        A dictionary containing generated content in English, Arabic, and Amharic,\n",
            "        or an error message if generation fails.\n",
            "    \"\"\"\n",
            "    if not genai_client:\n",
            "        # Return a standard dictionary here\n",
            "        return {\"error\": \"Gemini API client not initialized. GEMINI_API_KEY might be missing.\"}\n",
            "\n",
            "    prompt = f\"\"\"\n",
            "    You are a professional multilingual social media writer.\n",
            "    Produce a short motivational Instagram caption about depression and sadness, related to the user's prompt: \"{text}\"\n",
            "    Return EXACTLY a JSON object (no extra text) with keys:\n",
            "    {{\n",
            "      \"en\": \"<English caption (30-40 words)>\",\n",
            "      \"ar\": \"<Arabic caption>\",\n",
            "      \"am\": \"<Amharic caption>\"\n",
            "    }}\n",
            "    Make sure the values are plain strings and the entire response is valid JSON only.\n",
            "    \"\"\"\n",
            "\n",
            "    try:\n",
            "        # Use the GenAI client to generate content\n",
            "        # Pass the prompt as a list\n",
            "        text_resp = genai_client.models.generate_content(\n",
            "            model=\"models/gemini-2.5-flash\", # Use gemini-2.5-flash for faster response\n",
            "            contents=[prompt], # Pass prompt as a list - CORRECTED\n",
            "            # max_output_tokens=300 # Adjust as needed\n",
            "        )\n",
            "        raw_text = text_resp.text.strip()\n",
            "\n",
            "        # Robustly parse JSON from the model output\n",
            "        text_data = None\n",
            "        try:\n",
            "            text_data = json.loads(raw_text)\n",
            "        except Exception:\n",
            "            # Fallback: try to locate JSON block inside the text if direct parsing fails\n",
            "            # Escape the backslashes in the regex pattern and use single curly braces for the regex group\n",
            "            m = re.search(r\"(\\{[\\s\\S]*\\})\", raw_text)\n",
            "            if m:\n",
            "                try:\n",
            "                    text_data = json.loads(m.group(1))\n",
            "                except Exception:\n",
            "                    pass # JSON parsing failed even with fallback\n",
            "            if not text_data:\n",
            "                 # Return a standard dictionary here\n",
            "                 return {\"error\": \"Failed to generate and parse text content\"}\n",
            "\n",
            "\n",
            "        return text_data\n",
            "\n",
            "    except Exception as e:\n",
            "        # Return a standard dictionary here\n",
            "        return {\"error\": f\"Error generating text content: {e}\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff32a119"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `app` object was not defined in the code block. I need to include the Flask app initialization from the conceptual code in the previous step to fix this error and continue with implementing the prompt endpoint and confirmation display."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ga0pQJhqqri89gZEpXjkVABixBy30NqM",
      "authorship_tag": "ABX9TyMAGqnnkof3SsyUA72SGTyF"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}